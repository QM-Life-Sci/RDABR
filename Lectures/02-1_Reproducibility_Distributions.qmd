---
title: "Unit 2: Reproducibility and Distributions"
subtitle: "Data analysis workflow"
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
format:
  clean-revealjs:
    self-contained: false
    chalkboard: true
    standalone: true
    slide-number: true
    show-slide-number: print
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

```{r}
#| label: setup
#| echo: false

library(tidyverse)
theme_set(theme_classic(base_size = 20))
```


# How is science verified? {background-color="#40666e"}

## October 14, 2020

![](images/BCS_1.png)


## September 26, 2022

![](images/BCS_2.png)


## 12 years to retraction

![](images/MMR_Lancet.png)


## CRISPR-Cas9 (2012)

![](images/CRISPR.png)


## Nobel Prize (2020)

![](images/CRISPR_Nobel.png)


## What information would you need to follow an experiments?

:::{.alert}
In what context have you tried to do this before?
:::


# Reproducibility {background-color="#40666e"}


## Reproducible vs. replicable research

1. *Reproducible* - Given only 1) the raw data and 2) the scripts (i.e., code), one can produce the same set of results and figures. Not almost the same set, the **SAME SET**.
1. *Replicable* - Can one repeat the same experiment and reach the same conclusion?

Often these terms are often used more generally or interchangeably. 


## "Replication crisis" in science

![](images/Replication_crisis.png)

- [New Scientist](https://www.newscientist.com/article/mg25433810-400-the-replication-crisis-has-spread-through-science-can-it-be-fixed/)
- Korbmacher et al. [-@Korbmacher2023-de] - Psychology


## "Replication crisis" in cancer biology

![](images/Cancer_Replicability_1.png)

- 1/4 of 193 experiments could be replicated
- Effect sizes in those that were replicated were 85% smaller than reported

:::{.right}
Errington et al. [-@Errington2021-as]
:::


## "Replication crisis" in science

![](images/Cancer_Replicability_2.png){fig-align="center" width="50%"}

![](images/Cancer_Replicability_3.png){fig-align="center" width="80%"}

:::{.right}
Errington et al. [-@Errington2021-as]
:::


## What is reproducible research?

> "By reproducible, I mean that your work can be repeated by other researchers and they can arrive at the same results. For this to be the case, your work must be well documented, and your methods, code, and data all need to be available so that other researchers have the materials to reproduce everything." 

:::{.right}
Buffalo [-@Buffalo2015-ah]
:::

:::{.alert}
Reproducible data analysis is a step toward reproducible research.
:::


## R Markdown (`Rmd`) / Quarto (`qmd`)

- Text-based markup languages (i.e., HTML)
- Variant of [markdown](https://www.markdownguide.org/)
- Render to different formats (PDF, HTML, Word)
- Inline code
    - Your text and analysis coexist together in one file
- Resources
    - Markdown information
    - Guides and Tutorials
    

## Markdown-based analyses

- More than just comments
- Add context to your analysis
- Narrative, figures, tables, etc. all in one document
    - Your micropublication project


# What constitutes "data" {background-color="#40666e"}


## Role of data in science

**Data**: The raw material for doing statistics are data, which come in a variety of forms.

**Information**: The goal of statistics is to gain information, make a decision, or explain (*using data*).


## Foundational principles of data management

FAIR Guidelines [@Wilkinson2016-tf]

1. **F**indability
2. **A**ccessibility
3. **I**nteroperability
4. **R**eusability (Reproducibility)

Essential for long term data use, sharing, and curation.


## FAIR principles for image data

![](images/Prigent.png){fig-align="center"}


:::{.right}
Prigent et al. [-@Prigent2022-iq]
:::


# Data analysis workflow {background-color="#40666e"}

## Analysis workflow

1. Enter data (e.g., Excel) or save data from equipment
1. Load raw data and perform manipulations
    * Create categorical variables where applicable
    * Combine and transform variables
1. Plot raw data to look for mistakes, extreme values, etc.
    * Fix errors
    * Explore your data
1. Statistical analysis
1. Interpretation
    * More analysis
1. Make tables and figures for publication


## Analysis workflow

![](../images/Workflow.drawio.png){fig-align="center" width="80%"}


# Clean coding practices {background-color="#40666e"}


## Writing clean code

Code should be understandable by others (and your future self)

- Clean
- Readable
- Well annotated

How would you format a document that someone else would read?


## Whitespace makes code readable

Difficult to read:

```{r}
#| eval: false
#| echo: true

tvtest<-lmer(sqrt(tv)~Region*log(DD5_TOT)+(1|Population/Sample_ID)+
(1|Year),data=tvdat)
summary(tvtest)
ggplot(tvdat,aes(x=log(DD5_TOT),y=sqrt(tv),col=Region))+
geom_point(shape=1,size=3,alpha=1/3)+ geom_smooth(aes(col=Region),method='lm')+
xlab(bquote('log(Degree Days above' ~5^o~C*')'))+ylab('sqrt(Terminal Velocity (m/s))')
```


## Whitespace makes code readable

Easier to read:

```{r}
#| echo: true
#| eval: false

tvtest <- lmer(sqrt(tv) ~ Region * log(DD5_TOT) +
                          (1 | Population/Sample_ID) + 
                          (1 | Year),
               data = tvdat)

summary(tvtest)

ggplot(tvdat, aes(x = log(DD5_TOT), y = sqrt(tv), col = Region)) +
  geom_point(shape = 1, size = 3, alpha = 1/3) +
  geom_smooth(aes(col = Region), method = 'lm') + 
  xlab(bquote('log(Degree Days above' ~5^o~C*')')) +
  ylab('sqrt(Terminal Velocity (m/s))')
```


## Whitespace makes code readable

- Separate elements and processes with spaces and line breaks
- Limit line length
- Use indenting to group code 
    - Ctrl/Cmd - I to auto-correct indent in RStudio


## Comments are messages to your future self

- Explain the reason and functionality of the code
- Any useful messages

```{r}
#| echo: true
#| eval: false

# Fit a hierarchical linear model
# Random effects: Sample nested in Population and Year
tvtest <- lmer(sqrt(tv) ~ Region * log(DD5_TOT) +
                 (1 | Population / Sample_ID) + 
                 (1 | Year),
               data = tvdat)

# Summarize output of the model
summary(tvtest)

# Plot tv vs. dd5_tot colored by Region
# alpha = transparency, smaller is more transparent
ggplot(tvdat, aes(x = log(DD5_TOT), y = sqrt(tv), col = Region)) +
  geom_point(shape = 1, size = 3, alpha = 1/3) +
  geom_smooth(aes(col = Region), method = 'lm') + 
  xlab(bquote('log(Degree Days above' ~5^o~C*')')) +
  ylab('sqrt(Terminal Velocity (m/s))')
```


## Examples

[Hard to understand](https://github.com/Middleton-Lab/EDMA/blob/main/Ch_4_pt1.R)

[Easier to understand](https://github.com/Middleton-Lab/binning/blob/master/R/bin.running.R)


# Questions {background-color="#f8c471"}


# Sampling to learn about the world {background-color="#40666e"}


## Randomness and sampling

- Randomness is inherent to repeatable processes
    - Almost nothing is deterministic in the biological world
- *Sampling* lets us learn *information* about the world despite the *uncertainty*


## {background-video="images/earth.mp4" background-video-loop="true" background-video-muted="true"}


## How much of the Earth is covered by water?

:::{.alert}
How can we *estimate* the proportion of water?
:::

![](images/earth.jpg){fig-align="center"}

:::{.center}
What are your ideas?
:::


## Collecting data: Sampling from the globe

- Do all observations have the same set of possible outcomes?
- Do all observations have an equal chance of being included?
- Are observations independent of one another?

![](images/earth.jpg){fig-align="center"}


## Binomial distributions

- Water / Land
- Yes / No
- Affected / Unaffected
- Success / Failure
- Alive / Dead
- 0 / 1

Summarized by counts and converted to proportions


## Simulate data to test your intuition

1. Define the question *and* the expected answer
2. Simulate data following the question
3. Check that your answer agrees

Simulation is how we know that statistical tests "work" and are not biased (conservative or anticonservative).


## Simulating from binomial distributions: `rbinom()`

10 samples of 1 "trial", where the probability is 0.5

```{r}
#| echo: true

# Set the seed for the RNG to make the simulation reproducible
set.seed(234626)

# Generate 10 trials from a binomial (Bernoulli) distribution
# Probability = 0.5
x <- rbinom(n = 10, size = 1, prob = 0.5)
x
```

. . .

Calculate the mean of the 10 trials

```{r}
#| echo: true

mean(x)
```


## Simulating from binomial distributions: `rbinom()`

10 samples of 10 "trials", where the probability is 0.5

- Each sample is the count of "successes"

```{r}
#| echo: true

set.seed(32463)
x <- rbinom(n = 10, size = 10, prob = 0.5)
x
```

. . .

Calculate the mean of the 10 trials.

:::{.alert}
What is your prediction for the mean?
:::

. . .

```{r}
#| echo: true

mean(x / 10)
```


## Many trials

10,000 trials of 10 samples...

```{r}
#| echo: true

set.seed(234627)
x <- rbinom(n = 10000, size = 10, prob = 0.5)
```

- What will be the *most* frequent number?
- What will be the *least* frequent numbers?

. . .

```{r}
#| echo: true

x[1:100]
```


## Many trials

Sum the counts of each value with `table()`

```{r}
#| echo: true

x_tab <- table(x)
x_tab
```


## Summarizing counts with a histogram

```{r}
ggplot(data = tibble(Count = as.numeric(x_tab),
                     Successes = 0:10),
       aes(x = Successes, y = Count)) +
  geom_bar(stat = "identity", fill = "navy") +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "n Successes in 10 Trials")
```


## Summarizing sampling from the globe

![](images/earth.jpg){fig-align="center"}


## Normal distribution

![](images/Heights.png)


:::{.right}
Schilling et al. [-@Schilling2002-mm]
:::


## National Health and Nutrition Examination Survey (NHANES)

- Assess the health and nutrition status of a broad cross-section of the United States population
- [Many measured variables](https://wwwn.cdc.gov/nchs/nhanes/Default.aspx)
- Started in 1960s
- Most recently in 2-year batches


## Heights for 6,465 individuals

- Assigned male at birth

```{r}
NHANES <- read_csv("../data/NHANES.csv", show_col_types = FALSE) |> 
  filter(Sex == "Male") |> 
  select(-Sex) |> 
  arrange(Height)
NHANES$Height
```


## Heights for 6,465 individuals

```{r}
ggplot(NHANES, aes(x = Age, y = Height)) +
  geom_point(size = 1, show.legend = FALSE, alpha = 0.25,
             position = position_jitter(width = 0.25, seed = 3847293),
             color = "firebrick4") +
  scale_x_continuous(breaks = seq(0, 80, by = 5)) +
  labs(x = "Age (y)", y = "Height (cm)")
```


## Distribution of heights (age > 20)

```{r}
NHANES_20 <- NHANES |> filter(Age > 20)

ggplot(NHANES_20, aes(Height)) +
  geom_histogram(bins = 30, show.legend = FALSE,
                 fill = "firebrick4") +
  labs(x = "Height (cm)", y = "Count") +
  scale_x_continuous(breaks = seq(140, 200, by = 10))
```


## Extremes of heights (age > 20)

:::: {.columns}

::: {.column width="40%"}
```{r}
head(NHANES_20) |> knitr::kable()
```
:::

::: {.column width="60%"}
```{r}
tail(NHANES_20) |> knitr::kable()
```
:::

::::


## Heights (mostly) follow a normal distribution

```{r}
ggplot(NHANES_20, aes(Height)) +
  geom_histogram(aes(y = after_stat(density)),
                 fill = "firebrick4", 
                 alpha = 0.5,
                 bins = 30) +
  geom_line(data = tibble(
    Height = seq(min(NHANES_20$Height),
                 max(NHANES_20$Height),
                 length.out = 100),
    y = dnorm(Height, mean = mean(NHANES_20$Height),
              sd = sd(NHANES_20$Height))),
    aes(Height, y), linewidth = 1.5, color = "#2D5DA1") +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank()) +
  scale_x_continuous(breaks = seq(140, 200, by = 10))
```


## References

::: {#refs}
:::

