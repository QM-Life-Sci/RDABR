---
title: "Unit 3: Univariate Summaries"
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
format:
  clean-revealjs:
    self-contained: false
    chalkboard: true
    standalone: true
    slide-number: true
    show-slide-number: print
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

```{r}
#| label: setup
#| echo: false

library(tidyverse)

theme_set(theme_classic(base_size = 20))
```


# Housekeeping {background-color="#40666e"}

- Three-week check in (link on Canvas)
- PS 2 due sometime soon
- Start PS 3 today
- Any other questions?


# Distributions {background-color="#40666e"}


## Distributions

- All observations can be thought of as coming from a population that can be represented as a distribution
- Flip a coin 6 times and get HHTTHT: one observation in a distribution of possible outcomes (THTHTH, HHHTTT, etc.)
- Catch a rodent in my swimming pool and test its endurance: that data point is one value in the larger distribution of all endurance measures for all rodents


## Distributions most commonly encountered

1. Frequency distribution
    - Shows the number of times each measurement occurs in a sample (possibly "binned")
    - Counts of Heads, Water, Taller SNPs, etc.
1. Probability distribution:
    - A probability distribution shows the probability that measurement occurs in a sample.


## Probability distributions

Mathematical function for *probabilities* of *possible outcomes*

- *Probabilities*: between 0 and 1
- *Possible outcomes*: real number, integer, binomial (0/1), etc.

Normal distribution ($x$, $\mu$, $\sigma$):

$$
Pr\left[x\right] = \frac{1}{\sqrt{2\pi\sigma^{2}}}e^{\frac{-\left(x-\mu\right)^{2}}{2\sigma^{2}}}
$$


## Normal distribution

$$
Pr\left[x\right] = \frac{1}{\sqrt{2\pi\sigma^{2}}}e^{\frac{-\left(x-\mu\right)^{2}}{2\sigma^{2}}}
$$

```{r}
#| echo: true

Normal <- function(x, mu, sigma) {
  (1 / (sqrt(2 * pi * sigma^2))) * exp((-1 * (x - mu)^2) / (2 * sigma^2))
}

Normal(x = 1, mu = 0, sigma = 1)
```

. . .

R has built-in functions for probability distributions ("densities"):

```{r}
#| echo: true

dnorm(x = 1, mean = 0, sd = 1)
```


## Normal distribution

Calculate the probability across the range $-3$ to $3$ for $\mu = 0$ and $\sigma = 1$:

```{r}
#| echo: true
Std_Normal <- tibble(x = seq(-3, 3, length.out = 100),
                     Probability = dnorm(x, mean = 0, sd = 1))
```

Plot the probability as a line:

```{r}
#| echo: true
#| eval: false

ggplot() +
  geom_line(data = Std_Normal,
            aes(x, Probability),
            color = "darkgreen",
            linewidth = 1.5) +
  geom_point(aes(x = 1, y = dnorm(x = 1, mean = 0, sd = 1)),
             size = 4,
             color = "salmon") +
  scale_y_continuous(limits = c(0, 0.4), breaks = seq(0, 0.4, by = 0.05)) +
  scale_x_continuous(breaks = seq(-3, 3, by = 0.5))
```


## Normal distribution

```{r}
#| echo: false

ggplot() +
  geom_line(data = Std_Normal,
            aes(x, Probability),
            color = "darkgreen",
            linewidth = 1.5) +
  geom_point(aes(x = 1, y = dnorm(x = 1, mean = 0, sd = 1)),
             size = 5,
             color = "salmon") +
  scale_y_continuous(limits = c(0, 0.4), breaks = seq(0, 0.4, by = 0.05)) +
  scale_x_continuous(breaks = seq(-3, 3, by = 0.5))
```

Area under the curve = 1 integrating $Pr[x]$ for $-\infty < x < \infty$


## Try `dnorm()`

- Pick a value for $x$
- Choose `mean` and `sd`

See what probabilities you find.


## Many distributions

![](images/distributions.png){fig-align="center" width="80%"}


# Exploring Variation {background-color="#40666e"}

:::{.center}
Normal distribution
:::


## Describing a normal distribution

Central tendency

- Mean
- Median
- Mode (most common value)

Spread

- Standard deviation
- Interquartile range


## Sample (arithmetic) mean

$$\bar{x} = \frac{\sum^n_{i=1}x_i}{n}$$

. . .

- "From $i = 1$ to $i = n$, sum ($\Sigma$) each observation ($x_i$), where $n$ is the count of observations."
- "Mean" is preferred to "average".
    - Most of the time they are synonymous. 


## Median

- The central observations of a sample
- The 50th percentile
- The 0.50 quantile).
- If $n$ is even, then the median is the mean of the two middle observations.

```{r}
#| echo: true

1:10
median(1:10)
quantile(1:10, prob = 0.5)
```


## Mean vs. Median

Number of lateral plates (plates) in threespine sticklebacks (*Gasterosteus aculeatus*) with three different *Ectodysplasin* genotypes (*mm*, *Mm*, and *MM*).

![](https://i.imgur.com/Xr68AKa.jpg){fig-align="center"}


## Mean vs. Median

```{r}
SticklebackPlates <- read_csv("../data/Stickleback_Plates.csv",
                              show_col_types = FALSE)
```

```{r}
#| echo: true

glimpse(SticklebackPlates)
```


## Mean vs. Median

```{r}
ggplot(SticklebackPlates, aes(x = plates)) +
  geom_histogram(bins = 30, fill = "gray75") +
  facet_grid(genotype ~ .) +
  labs(x = "Number of Lateral Body Plates", y = "Count") +
  theme(strip.text = element_text(face = "italic"))
```


## Mean vs. Median

```{r}
#| echo: true

SticklebackPlates |> 
  summarize(mean_plate = mean(plates),
            median_plate = median(plates),
            .by = genotype)
```


## Mean is sensitive to extreme values

```{r}
M <- SticklebackPlates |> 
  group_by(genotype) |> 
  summarize(Mean = mean(plates),
            Median = median(plates),
            .groups = "drop") |> 
  gather(Value, x, -genotype)

ggplot(SticklebackPlates, aes(x = plates, group = genotype)) +
  geom_histogram(bins = 30, fill = "gray75") +
  geom_vline(data = M, aes(xintercept = x, color = Value),
             linewidth = 2) +
  scale_color_manual(values = c("firebrick4", "navyblue")) +
  facet_grid(genotype ~ .) +
  labs(x = "Number of Lateral Body Plates", y = "Count") +
  theme(strip.text = element_text(face = "italic"))
```


# Questions {background-color="#f8c471"}


# Sampling from Distributions {background-color="#40666e"}

[Kingfisher fish-sampling demo](https://www.zoology.ubc.ca/~whitlock/Kingfisher/SamplingNormal.htm){target="_blank"}


## Means of samples

Law of Large Numbers

- The mean of repeated samples from a population will converge on the true value
- Long-run means are very predictable
- Water/land sampling from inflatable globes


## Programming Loops


# Moving Data {background-color="#40666e"}


## Import / export


# Questions {background-color="#f8c471"}


## References

::: {#refs}
:::

