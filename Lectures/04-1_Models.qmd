---
title: "Unit 4: Scientific Questions and Statistical Models"
subtitle: "Correlation and Bivariate Regression"
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
format:
  clean-revealjs:
    self-contained: true
    chalkboard: false
    standalone: true
    slide-number: true
    show-slide-number: print
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

```{r}
#| label: setup
#| echo: false

library(tidyverse)
library(ggtext)
library(patchwork)
library(ggExtra)

theme_set(theme_classic(base_size = 20))

ssPlot <- function(X, Y, b, do.plot = TRUE, do.labels = TRUE) {
    require(latex2exp)
    n <- length(X)
    pred <- (X * b + (mean(Y) - b * mean(X)))
    SSy <- sum((Y - pred)^2)

    M <- tibble(X, Y, pred)

    if (do.plot) {
        p <- ggplot() +
            geom_point(
                data = tibble(X = mean(X), Y = mean(Y)),
                aes(X, Y),
                color = "navy",
                size = 7,
                pch = 1
            ) +
            geom_abline(
                slope = b,
                intercept = mean(Y) - b * mean(X),
                color = "navy",
                linewidth = 1
            ) +
            geom_segment(
                data = M,
                aes(x = X, xend = X, y = Y, yend = pred),
                color = "firebrick",
                linewidth = 1
            ) +
            geom_point(data = M, aes(x = X, y = Y), size = 3)

        v1 <- round(b, 2)
        v2 <- round(SSy, 2)

        ll1 <- glue::glue("$\\theta_1 = {v1}$")
        ll2 <- glue::glue("$\\SS = {v2}$")

        xpos <- min(X) + 0.15 * diff(range(X))
        ypos <- min(Y) + 0.8 * diff(range(Y))

        if (do.labels) {
            p <- p +
                annotate(
                    geom = "text",
                    label = TeX(ll1, output = "character"),
                    x = xpos,
                    y = ypos,
                    parse = TRUE,
                    hjust = 0,
                    size = 9
                ) +
                annotate(
                    geom = "text",
                    label = TeX(ll2, output = "character"),
                    x = xpos,
                    y = ypos * 0.96,
                    parse = TRUE,
                    hjust = 0,
                    size = 9
                )
        }
        print(p)
    }
    return(SSy)
}

```


# Housekeeping {background-color="#40666e"}

- Review problem set keys
- Three-week Check In: complete before Thursday (if you choose to)
- PS 2
- PS 3 due Thursday
    - PS keys available on Canvas
- Progress Check 1 next week
    - Tuesday: Questions and review (feel free to submit ahead)
    - Thursday: In class working time


# Questions {background-color="#f8c471"}


# What kinds of questions do we want to answer as scientists? {background-color="#40666e"}


## Scientific questions

- Is there an effect (e.g., mean differences)?
- How large is the effect?
- (How large) is the association?
- (How well) can I predict a quantity, group, or classification of interest?
- Many others


## Remember the Goal of Statistics

> "a way of taming **uncertainty**, of turning raw **data** into arguments that can resolve profound questions" [@Amabile1989-pf]

- The statistical analyses that you carry out are *models*.
- Inference depends on evaluating the relative support for different models.
    - Model where there is *no* effect ("Null")
    - Model where there is an effect ("Alternative(s)")
- Uncertainty is always present


## Example: Species richness in Missouri lakes

> Does the number of phytoplankton species change with agricultural intensity around lakes?

:::: {.columns}

::: {.column width="40%"}
![](https://i.imgur.com/GoOM9bb.png){fig-align="center" fig-alt=""}
:::

::: {.column width="60%"}
- There is no relationship between species richness and agricultural intensity
- There is a positive relationship
- There is a negative relationship
:::

::::


## Example: Genetics of corn oil content

> Which set of loci best predicts oil content in corn kernels?

:::: {.columns}

::: {.column width="40%"}
![](https://i.imgur.com/w6z5m2e.jpg){fig-align="center" fig-alt=""}
:::

::: {.column width="60%"}
- Heritability of corn oil content is 0
- Different possible combinations of SNPs
- All additive
- Gene-gene interactions
:::

::::


## Example: Canid relationships

> What are the phylogenetic relationships between dog breeds & other canids?

:::: {.columns}

::: {.column width="60%"}
![](https://i.imgur.com/spdaSkP.jpg){fig-align="center" fig-alt=""}
:::

::: {.column width="40%"}
- Simultaneous & rapid radiation
- Single origin of dogs
- Multiple origins
- Ancient breeds are monophyletic
- Every possible tree....
:::

::::


## Example: Predict the species of a fossil

> Is this bone more like a chimpanzee, australopith, Neandertal, or modern human?

:::: {.columns}

::: {.column width="40%"}
![](https://i.imgur.com/cQ1Kl1v.png){fig-align="center" fig-alt=""}
:::

::: {.column width="60%"}
- What is the percent correct classification of known fossils?
- What are the relative probabilities of new fossil being in one of four taxonomic groups?
:::

::::


## Example: Growth models in Alligators?

![](https://i.imgur.com/scZSjNE.png){fig-align="center" fig-alt="Femur length plotted against Age for alligators from five different treatment groups."}

$$Determinate:~Length \left(Age\right) = \frac{\theta_1}{1 + \exp((\theta_2 - Age) / \theta_3)}$$

$$Indeterminate:~Length\left(Age\right) = \theta_0 + \theta_1 Age + \theta_2 Age^2$$


## Your Own Experiences


## Models and Inference

- You want to use data to answer questions.
- Make *inferences* using *models* with data.

The method you use for inference is part of the model.

- Different sets of assumptions
- Many will give very similar answers

:::{.center}
"clarifying the mapping from assumptions to inference to decision"^[https://statmodeling.stat.columbia.edu/2024/12/28/bayesian-inference-isnt-just-about-getting-the-answer-its-also-about-clarifying-the-mapping-from-assumptions-to-inference-to-decision/]
:::


## {background-image="https://i.imgur.com/kgPmw0b.jpg" background-size="100%"  fig-alt="Image of two different morphs of crickets."}


## Example: Wing Dimorphic Crickets

> Do long-winged crickets have a higher resting metabolic rate than short-winged crickets?

:::: {.columns}

::: {.column width="40%"}

![](https://i.imgur.com/kgPmw0b.jpg){fig-align="center" fig-alt="Image of two different morphs of crickets."}

:::

::: {.column width="60%"}

Controlling for body mass,

- Metabolic rates do not differ
- Average metabolic rate of long-wings is higher
- Average  metabolic rate of long-wings is lower

:::

::::


## Observe some data

```{r}
CD <- read_csv(
    "https://raw.githubusercontent.com/QM-Life-Sci/RDABR/refs/heads/main/data/Cricket_Metabolic_MassCor.csv",
    show_col_types = FALSE
) |>
    mutate(Wing_Morph = if_else(Wing_Morph == "LW", "Long Wing", "Short Wing"))
```

```{r}
#| echo: true

glimpse(CD)

CD |>
    group_by(Wing_Morph) |>
    summarize(mean = mean(CO2_resid))
```


## Observe data

```{r}
#| fig-alt: "Scatterplot of Mass-specific CO2 plotted for each of the long wing and short wing groups of crickets. The mean for each group is plotted as a single red dot."

P <- CD |>
    ggplot(aes(Wing_Morph, CO2_resid)) +
    geom_point(position = position_jitter(width = 0.3), alpha = 0.25) +
    stat_summary(fun = mean, geom = "point", size = 4, color = "firebrick4") +
    labs(x = "Wing Morph", y = "Mass-Specific CO<sub>2</sub>") +
    theme(axis.title.y = element_markdown())
print(P)
```


## Do long-winged crickets have a higher resting metabolic rate than short-winged crickets?

- What is the probability the two groups have the same mean?
- What is the probability of observing a difference like this from sampling error only?
- What is the probability these are two samples from the same distribution?
- How well can you predict metabolic rate from wing morph?


## Could the observed difference be sampling error?

```{r}
#| fig-alt: "Scatterplot of Mass-specific CO2 plotted for each of the long wing and short wing groups of crickets. The mean for each group is plotted as a single red dot."

print(P)
```


## How large a difference do you get from sampling error?

1. Assume long-winged and short-winged crickets share a distribution
2. Put all values from both morphs in one group
3. Randomly assign Long Wing and Short Wing labels to observed values of `CO2_resid`
4. Repeat over and over


## How large a difference do you get from sampling error?

```{r}
#| fig-alt: "Scatterplot of Mass-specific CO2 plotted for both morph groups pooled together. The mean for all points is plotted as a single red dot."

CD$Group <- "ALL"

CD |>
    ggplot(aes(Group, CO2_resid)) +
    geom_point(position = position_jitter(width = 0.3), alpha = 0.25) +
    stat_summary(fun = mean, geom = "point", size = 4, color = "firebrick4") +
    labs(x = "Wing Morph", y = "Mass-Specific CO~2~") +
    theme(axis.title.y = element_markdown())

```


## How large a difference do you get from sampling error?

```{r}
#| fig-align: center
#| fig-alt: "Scatterplot of Mass-specific CO2 plotted for randomized groups of long wing and short wing crickets. The mean for each shuffled group is plotted as a single red dot."

CD$WM_Shuffle <- sample(CD$Wing_Morph)

CD |>
    group_by(WM_Shuffle) |>
    summarize(Mean = mean(CO2_resid))

CD |>
    ggplot(aes(WM_Shuffle, CO2_resid)) +
    geom_point(position = position_jitter(width = 0.3), alpha = 0.25) +
    stat_summary(fun = mean, geom = "point", size = 4, color = "firebrick4") +
    labs(x = "Wing Morph", y = "Mass-Specific CO~2~") +
    theme(axis.title.y = element_markdown())
```


## How big of a difference do you get from sampling error?

```{r}
#| fig-align: center
#| fig-alt: "Scatterplot of Mass-specific CO2 plotted for randomized groups of long wing and short wing crickets. The mean for each shuffled group is plotted as a single red dot."

CD$WM_Shuffle <- sample(CD$Wing_Morph)

CD |>
    group_by(WM_Shuffle) |>
    summarize(Mean = mean(CO2_resid))

CD |>
    ggplot(aes(WM_Shuffle, CO2_resid)) +
    geom_point(position = position_jitter(width = 0.3), alpha = 0.25) +
    stat_summary(fun = mean, geom = "point", size = 4, color = "firebrick4") +
    labs(x = "Wing Morph", y = "Mass-Specific CO~2~") +
    theme(axis.title.y = element_markdown())
```


## What do we expect to see when there is a meaningful difference between wing morphs?

```{r}
print(P)
```


## What do we expect to see when there is a meaningful difference between wing morphs?

1. Assume corrected metabolic rate is normally distributed
2. Draw random values for long wings from a normal distribution with a *higher* mean
3. Draw random values for short wings from a normal distribution with a *lower* mean
4. Repeat over and over


## Simulate a difference using distributions

```{r}
#| echo: true

n.sw <- sum(CD$Wing_Morph == "Short Wing")
n.lw <- sum(CD$Wing_Morph == "Long Wing")

mean.sw <- -1
mean.lw <- 2

SS <- tibble(
    Wing_Morph = c(rep("Short Wing", n.sw), rep("Long Wing", n.lw)),
    Sim_CO2 = c(rnorm(n.sw, mean.sw), rnorm(n.lw, mean.lw))
)

SS |> group_by(Wing_Morph) |> summarise(Mean = mean(Sim_CO2))
```


## Simulate a difference using distributions

```{r}
#| echo: false
#| fig-alt: "Scatterplot of Mass-specific CO2 plotted for simulated groups of long wing and short wing crickets. The mean for each simulated group is plotted as a single red dot."

SS |> group_by(Wing_Morph) |> summarise(Mean = mean(Sim_CO2))

SS |>
    ggplot(aes(Wing_Morph, Sim_CO2)) +
    geom_point(position = position_jitter(width = 0.3), alpha = 0.25) +
    stat_summary(fun = mean, geom = "point", size = 4, color = "firebrick4") +
    labs(x = "Wing Morph", y = "Mass-Specific CO~2~") +
    theme(axis.title.y = element_markdown())

```


## Simulate a difference using distributions

```{r}
#| fig-alt: "Scatterplot of Mass-specific CO2 plotted for simulated groups of long wing and short wing crickets. The mean for each simulated group is plotted as a single red dot."

mean.sw <- -1
mean.lw <- 2

SS <- tibble(
    Wing_Morph = c(rep("Short Wing", n.sw), rep("Long Wing", n.lw)),
    Sim_CO2 = c(rnorm(n.sw, mean.sw), rnorm(n.lw, mean.lw))
)

SS |> group_by(Wing_Morph) |> summarise(Mean = mean(Sim_CO2))

SS |>
    ggplot(aes(Wing_Morph, Sim_CO2)) +
    geom_point(position = position_jitter(width = 0.3), alpha = 0.25) +
    stat_summary(fun = mean, geom = "point", size = 4, color = "firebrick4") +
    labs(x = "Wing Morph", y = "Mass-Specific CO~2~") +
    theme(axis.title.y = element_markdown())
```


# Models {background-color="#40666e"}


## Models and Inference

> All models are wrong, but some are useful.

:::{.right}
George Box (1976; attributed)
:::

- If we knew the process exactly we would not need a model (e.g., points exactly on a line).

$$y = mx + b$$

- Often not a single unequivocally correct model.
- Some very wrong and some less wrong.
- Your role is to choose and defend a model, given your questions and the assumptions of the model.


## Types of data

*Continuous*

- Real number line (rounding okay)
- Bone lengths, age, oil content of corn
- Counts of species

*Categorical*

- Binomial: 0/1, land/water, etc.
- Treatment or observation groups (Ag/Non-Ag land use)
- Genotypes (Sticklebacks: *MM*, *Mm*, *mm*)


# Strength of Association {background-color="#40666e"}

Pairs of continuous variables


## Coloration of lion noses

:::: {.columns}

::: {.column width="30%"}

![](images/lion_nose.png){fig-alt="Photograph of a line nose with black coloration."}

:::

::: {.column width="70%"}

```{r}
#| fig-height: 8
#| fig-alt: "Scatterplot of proportion black plotted against Age for a sample of lions."

LA <- read_csv(
    "https://raw.githubusercontent.com/Middleton-Lab/abdData/refs/heads/main/inst/extdata/datasets/17/17e1LionAges.csv",
    show_col_types = FALSE
) |>
    rename(Age = age, `Proportion Black` = proportion.black)

ggplot(LA, aes(Age, `Proportion Black`)) +
    geom_point(size = 6, color = "navy") +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(breaks = 1:14) +
    theme_classic(base_size = 30)
```

:::

::::


## Coloration of lion noses

```{r}
#| fig-alt: "Scatterplot of proportion black plotted against age for a sample of lions and scatterplot of age plotted against proportion black for a sample of lions."

p1 <- ggplot(
    LA,
    aes(
        x = Age,
        y = `Proportion Black`
    )
) +
    geom_point(size = 4, color = "navy") +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(breaks = 1:14) +
    theme_classic(base_size = 20)

p2 <- ggplot(
    LA,
    aes(
        y = Age,
        x = `Proportion Black`
    )
) +
    geom_point(size = 4, color = "navy") +
    scale_x_continuous(limits = c(0, 1)) +
    scale_y_continuous(breaks = 1:14) +
    theme_classic(base_size = 20)
p1 + p2
```

:::{.center}
Which plot is more informative?
:::


## (Pearson's) Correlation ($r$)

Strength and direction of association between two variables

- Equally true:
    - How does $x$ change as $y$ changes?
    - How does $y$ change as $x$ changes?
- Range: $-1 \leq r \leq 1$
- Null hypothesis: $r = 0$


## (Pearson's) Correlation ($r$)

Strength of association between two variables:

\begin{align*}
r &= \frac{{}\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}
{\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2  \sum_{i=1}^{n}(y_i - \bar{y})^2}}\\
    &= \frac{1}{n - 1} \sum_{i=1}^n \frac{x_i - \bar{x}}{s_x} \frac{y_i - \bar{y}}{s_y}\\
\end{align*}

where

- $(x_i - \bar{x})$ and $(y_i - \bar{y})$ are deviations from the mean
- $s_x$ and $s_y$ are standard deviations


## Assumptions

- $x$ and $y$ are paired
- Observations are independent
- Bivariate normality
    - Separately, $x$ and $y$ are normally distributed


## Bivariate normality

```{r}
#| echo: true
#| output-location: slide
#| fig-alt: "Scatterplot of y vs. x drawn from a bivariate normal distribution with marginal histograms showing that each is normal."

library(ggExtra)
set.seed(43237497)

BVN <- tibble(
    x = rnorm(1e4, mean = 0, sd = 1),
    y = rnorm(1e4, mean = 0, sd = 1)
)

P <- ggplot(BVN, aes(x, y)) +
    geom_point(alpha = 0.25, color = "firebrick") +
    coord_equal()

ggMarginal(P, type = "histogram", fill = "firebrick")
```


## Correlation in R: `cor()`

Random bivariate normal data:

```{r}
#| echo: true

cor(BVN$x, BVN$y)
```

Lion nose coloration:

```{r}
#| echo: true

cor(LA$Age, LA$`Proportion Black`)

cor(LA$`Proportion Black`, LA$Age)
```


# Questions {background-color="#f8c471"}


# Non-causal correlations {background-color="#40666e"}

Enjoy: [Spurious Correlations](https://www.tylervigen.com/spurious-correlations){target="_blank"}


## Non-causal correlations

![](images/vinyl.png){fig-align="center" fig-alt="Line plot of sales of albums and Costco's stock price plotted against year, showing that both appear to change together."}


## Non-causal correlations

![](images/UFO.png){fig-align="center" fig-alt="Line plot of name Annabelle and UFO sightings plotted against year, showing that both appear to change together."}


## Spurious correlations

::: {.callout-note}
## Correlation $\neq$ Causation

What else could be *separately* causing the patterns I observe?
:::

- Not restricted to correlation
- Think deeply about the processes you are studying
- Controlled experiments can help


# Bivariate regression {background-color="#40666e"}

## Coloration of lion noses

:::: {.columns}

::: {.column width="30%"}
![](images/lion_nose.png){fig-alt="Photograph of a line nose with black coloration."}

```{r}
LA <- read_csv(
    "https://raw.githubusercontent.com/Middleton-Lab/abdData/refs/heads/main/inst/extdata/datasets/17/17e1LionAges.csv",
    show_col_types = FALSE
) |>
    rename(
        Age = age,
        `Proportion Black` = proportion.black
    )

r <- round(
    cor(
        LA$Age,
        LA$`Proportion Black`
    ),
    digits = 2
)
```

Correlation: $r$ = `r r`

:::

::: {.column width="70%"}

```{r}
#| fig-height: 8
#| fig-alt: "Scatterplot of proportion black plotted against Age for a sample of lions."

ggplot(
    LA,
    aes(
        Age,
        `Proportion Black`
    )
) +
    geom_point(size = 6, color = "navy") +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(breaks = 1:14) +
    theme_classic(base_size = 30)
```

:::

::::


## Bivariate regression

*Predict* observed values of $y$ for observed values of $x$

```{r}
#| fig-alt: "Scatterplot of proportion black plotted against age for a sample of lions and scatterplot of age plotted against proportion black for a sample of lions."

p1 <- ggplot(LA, aes(x = Age, y = `Proportion Black`)) +
    geom_point(size = 4, color = "navy") +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(breaks = 1:14) +
    theme_classic(base_size = 20)

p2 <- ggplot(LA, aes(y = Age, x = `Proportion Black`)) +
    geom_point(size = 4, color = "navy") +
    scale_x_continuous(limits = c(0, 1)) +
    scale_y_continuous(breaks = 1:14) +
    theme_classic(base_size = 20)

p1 + p2
```


## For example...

1. Calibration curves (Absorption vs. Concentration)
2. Metabolic rate vs. Body mass
3. Leaf area vs. Total rainfall
4. Lion age vs. nose proportion black

Continuous variable predicted ("modeled") by one continuous variable


## Also known as

- Least squares regression
- Ordinary least squares regression
- OLS regression
- Linear regression
- "Regression"


## Simulate data

Generate $n = 30$ random data points:

- $X \sim Normal(\mu = 10, \sigma = 1)$
- $Y = 2.3 X + \epsilon$ ("functional relationship")
- where $\epsilon \sim Normal(1, 1)$ ("noise")

```{r}
#| echo: true

set.seed(4)
n <- 30

X <- rnorm(n, mean = 10, sd = 1)
Y <- 2.3 * X + rnorm(n, mean = 1, sd = 1)

M <- tibble(X, Y)
```


## Plot data

```{r}
#| fig-alt: "Scatterplot of Y plotted against X, showing a moderate positive relationship."

p <- ggplot(M, aes(X, Y)) +
    geom_point(size = 4, color = "navy")
p
```


## Goal

What values of $\theta_0$ (intercept) and $\theta_1$ (slope) provide the best fit line through $Y$ as a function of $X$?

$$Y = \theta_0 + \theta_1 X$$

- How do we estimate $\theta_0$ and $\theta_1$ (or $\beta_0$ and $\beta_1$)?
- What defines "best fit"?


## Model properties

An infinite set of possible slopes ($\theta_1$) and intercepts ($\theta_0$)

1. Slopes and intercepts are tied together
    - Change the slope and the intercept must change
1. All lines must pass through $\left(\bar{X}, \bar{Y}\right)$.
1. Sum of the squared deviations will vary continuously.
1. **Only one** value of $\theta_1$ will minimize the sum of squares.
    - The *Ordinary Least Squares* estimate


## Assumptions of OLS

:::: {.columns}

::: {.column width="50%"}

Few assumptions are made about $X$

- *Is* measured without error
- *Not* that it is normal or that it is randomly sampled
- Think about calibration curves. The $X$ observations are fixed.

:::

::: {.column width="50%"}

```{r}
#| fig-height: 5
#| fig-width: 5
#| fig-alt: "Scatterplot of absorbance plotted against concentration, showing a strong positive relationship."

set.seed(86)
cc <- tibble("Concentration" = seq(from = 10, to = 110, by = 10))
cc$Absorbance = cc$Concentration * 0.025 + rnorm(nrow(cc), 0, 0.15)

ggplot(cc, aes(Concentration, Absorbance)) +
    geom_point(size = 3) +
    scale_x_continuous(n.breaks = 10) +
    scale_y_continuous(limits = c(0, 3), breaks = seq(0, 3, by = 0.5))
```

:::

::::


## Minimizing Sums of Squares

```{r}
#| fig-alt: "Scatterplot of Y plotted against X, showing a moderate positive relationship."

p
```


## Minimizing Sums of Squares

```{r}
#| fig-alt: "Scatterplot of Y plotted against X, showing a moderate positive relationship. The mean of X and Y is plotted as an open circle."

y_bar <- paste("bar(Y)==", round(mean(Y), 2))
x_bar <- paste("bar(X)==", round(mean(X), 2))

p +
    geom_point(
        data = tibble(X = mean(X), Y = mean(Y)),
        aes(X, Y),
        color = "navy",
        size = 7,
        pch = 1
    ) +
    annotate("text", x = 9.25, y = 28, label = y_bar, parse = TRUE, size = 7) +
    annotate("text", x = 9.25, y = 27, label = x_bar, parse = TRUE, size = 7)
```


## Deviates (residuals)

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The theoretical line with no slope is plotted through the mean of Y. Vertical lines connect the points to the line."

# b = 0
ss <- ssPlot(X, Y, 0, do.labels = FALSE)
```


## $\theta_1 = 0$

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The theoretical line with no slope is plotted through the mean of Y. Vertical lines connect the points to the line."

# b = 0
ss <- ssPlot(X, Y, 0)
```


## $\theta_1 = 0.5$

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The theoretical line with slope of 0.5 is plotted through the mean of Y. Vertical lines connect the points to the line."

ss <- ssPlot(X, Y, 0.5)
```


## $\theta_1 = 1$

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The theoretical line with slope of 1 is plotted through the mean of Y. Vertical lines connect the points to the line."

ss <- ssPlot(X, Y, 1)
```


## $\theta_1 = 1.5$

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The theoretical line with slope of 1.5 is plotted through the mean of Y. Vertical lines connect the points to the line."

ss <- ssPlot(X, Y, 1.5)
```


## $\theta_1 = 2$

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The theoretical line with slope of 2 is plotted through the mean of Y. Vertical lines connect the points to the line."

ss <- ssPlot(X, Y, 2)
```


## $\theta_1 = 2.1$

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The theoretical line with slope of 2.1 is plotted through the mean of Y. Vertical lines connect the points to the line."

ss <- ssPlot(X, Y, 2.1)
```


## $\theta_1 = 2.6$

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The theoretical line with slope of 2.6 is plotted through the mean of Y. Vertical lines connect the points to the line."

ss <- ssPlot(X, Y, 2.6)
```


## Minimizing Sums of Squares

- Search a range of values for $\theta_1$

```{r}
#| echo: true

# To hold output
SumSq <- tibble(
    theta_1 = seq(-10, 10, by = 0.01),
    SS = numeric(length(theta_1))
)
head(SumSq)
```


## Minimizing Sums of Squares

```{r}
#| echo: true

# Iterate through slopes
for (ii in 1:nrow(SumSq)) {
    theta_1 <- SumSq$theta_1[ii]
    SumSq$SS[ii] <- ssPlot(X, Y, theta_1, do.plot = FALSE)
}

# Location of minimum SS
minSS.theta_1 <- SumSq$theta_1[which.min(SumSq$SS)]
minSS.SS <- SumSq$SS[which.min(SumSq$SS)]
```


## Minimizing Sums of Squares

```{r}
#| fig-alt: "Plot of the sums of squares for a range of values for the slope. The parabolic relationship has a minimum at slope of 2.4."

xpos <- min(SumSq$theta_1) + 0.55 * diff(range(SumSq$theta_1))
ypos <- min(SumSq$SS) + 0.3 * diff(range(SumSq$SS))

v1 <- round(minSS.theta_1, 2)
v2 <- round(minSS.SS, 2)
ll1 <- glue::glue("$\\theta_1 = {v1}$")
ll2 <- glue::glue("$\\SS = {v2}$")

ggplot() +
    geom_line(data = SumSq, aes(x = theta_1, y = SS), linewidth = 1.25) +
    geom_point(
        data = tibble(x = minSS.theta_1, y = minSS.SS),
        aes(x, y),
        color = "coral",
        size = 5
    ) +
    labs(x = TeX("$\\theta_1$"), y = "Sum of Squares") +
    annotate(
        geom = "text",
        label = TeX(ll1, output = "character"),
        x = xpos,
        y = ypos,
        parse = TRUE,
        hjust = 0,
        size = 9
    ) +
    annotate(
        geom = "text",
        label = TeX(ll2, output = "character"),
        x = xpos,
        y = ypos * 0.70,
        parse = TRUE,
        hjust = 0,
        size = 9
    )
```


## Direct calculation of $\theta_1$ and $\theta_0$

$$\theta_1 = \frac{\sum\left(X_{i}-\bar{X}\right)\left(Y_{i}-\bar{Y}\right)}{\sum\left(X_{i}-\bar{X}\right)^{2}}$$

Numerator:  Sum of the products of *X* and *Y*

Denominator: Sum of squares of *X*

$$\theta_0 = \bar{Y} - \theta_1 \bar{X}$$


## Bivariate regression as a linear model

- Don't have to manually search for values of intercept ($\theta_0$) and slope ($\theta_1$)
    - Although we can
- Want to solve the equation directly
    - Matrix algebra

R has a function to do this: `lm()`


## Linear models: `lm()`

```{r}
#| echo: true

my_model <- lm(Y ~ X + 1, data = M)

my_model

```

- `+ 1` includes an intercept (default, optional)
- For each 1 unit increase in $X$, $Y$ increases $2.39525$
- $Y = -0.03541$ when $X = 0$


## Model formulas: `Y ~ X`

:::{.center}
"Y *is modeled by* X"
:::

- Response (outcome) variable: $Y$
- Predictor variable: $X$
- Equivalent to: $Y = \theta_0 + \theta_1 X$
- Intercept (`1`) is assumed
    - `Y ~ X + 1`


## $\theta_1 = 2.39525$

```{r}
#| fig-alt: "Scatterplot of Y plotted against X. The exact line with slope of 2.39525 is plotted through the mean of Y. Vertical lines connect the points to the line."

ss <- ssPlot(X, Y, 2.39525)
```


# Questions {background-color="#f8c471"}


## References

::: {#refs}
:::
