@ARTICLE{Lindenmayer1995-tx,
  title        = {Morphological variation among populations of the mountain
                  brushtail possum, Trichosurus-caninus Ogilby (phalangeridae,
                  marsupialia)},
  author       = {Lindenmayer, D B and Viggers, K L and Cunningham, R B and
                  Donnelly, C F},
  journaltitle = {Aust. J. Zool.},
  publisher    = {CSIRO Publishing},
  volume       = {43},
  issue        = {5},
  pages        = {449},
  date         = {1995},
  doi          = {10.1071/zo9950449},
  issn         = {0004-959X,1446-5698},
  abstract     = {The results are described of a study of morphometric variation
                  among populations of the mountain brushtail possum,
                  Trichosurus caninus Ogilby. Trapping surveys were completed at
                  seven sites from southern Victoria to central Queensland. The
                  variables measured from each of the 102 animals captured
                  included head length, skull width, total body length, tail
                  length, pes length, length of the ear conch, body girth, belly
                  girth and the pelage colour. Canonical variate analysis
                  highlighted the existence of a marked separation between
                  populations in Victoria and those in New South Wales and
                  Queensland. The first canonical variate accounted for 89\% of
                  the variation between the populations and was dominated by the
                  length of the ear conch, tail length and pes length. There
                  also were differences between the populations for several
                  other morphometric measures including the head and body
                  length. We recorded considerable variation in the fur colour
                  of T. caninus both within and between the populations
                  surveyed. However, no consistent pattern in the geographic
                  variation of fur coloration was evident. We do not know the
                  ecological or evolutionary causes underlying the observed
                  differences in morphological characteristics amongst the
                  populations of T. caninus. Further work is planned to examine
                  the genetic variability of the populations and to assess the
                  taxonomic significance of our findings.},
  url          = {https://www.publish.csiro.au/zo/zo9950449},
  language     = {en}
}

@ARTICLE{Korbmacher2023-de,
  title        = {The replication crisis has led to positive structural,
                  procedural, and community changes},
  author       = {Korbmacher, Max and Azevedo, Flavio and Pennington, Charlotte
                  R and Hartmann, Helena and Pownall, Madeleine and Schmidt,
                  Kathleen and Elsherif, Mahmoud and Breznau, Nate and
                  Robertson, Olly and Kalandadze, Tamara and Yu, Shijun and
                  Baker, Bradley J and O'Mahony, Aoife and Olsnes, Jørgen Ø-S
                  and Shaw, John J and Gjoneska, Biljana and Yamada, Yuki and
                  Röer, Jan P and Murphy, Jennifer and Alzahawi, Shilaan and
                  Grinschgl, Sandra and Oliveira, Catia M and Wingen, Tobias and
                  Yeung, Siu Kit and Liu, Meng and König, Laura M and
                  Albayrak-Aydemir, Nihan and Lecuona, Oscar and Micheli,
                  Leticia and Evans, Thomas},
  journaltitle = {Commun Psychol},
  publisher    = {Springer Science and Business Media LLC},
  volume       = {1},
  issue        = {1},
  pages        = {3},
  date         = {2023-07-25},
  doi          = {10.1038/s44271-023-00003-2},
  pmc          = {PMC11290608},
  pmid         = {39242883},
  issn         = {2731-9121,2731-9121},
  abstract     = {The emergence of large-scale replication projects yielding
                  successful rates substantially lower than expected caused the
                  behavioural, cognitive, and social sciences to experience a
                  so-called 'replication crisis'. In this Perspective, we
                  reframe this 'crisis' through the lens of a credibility
                  revolution, focusing on positive structural, procedural and
                  community-driven changes. Second, we outline a path to expand
                  ongoing advances and improvements. The credibility revolution
                  has been an impetus to several substantive changes which will
                  have a positive, long-term impact on our research environment.},
  url          = {https://www.nature.com/articles/s44271-023-00003-2},
  urldate      = {2025-01-25},
  language     = {en}
}

@ARTICLE{Errington2021-as,
  title        = {Challenges for assessing replicability in preclinical cancer
                  biology},
  author       = {Errington, Timothy M and Denis, Alexandria and Perfito, Nicole
                  and Iorns, Elizabeth and Nosek, Brian A},
  journaltitle = {Elife},
  publisher    = {eLife Sciences Publications, Ltd},
  volume       = {10},
  date         = {2021-12-07},
  doi          = {10.7554/eLife.67995},
  pmc          = {PMC8651289},
  pmid         = {34874008},
  issn         = {2050-084X},
  abstract     = {We conducted the Reproducibility Project: Cancer Biology to
                  investigate the replicability of preclinical research in
                  cancer biology. The initial aim of the project was to repeat
                  193 experiments from 53 high-impact papers, using an approach
                  in which the experimental protocols and plans for data
                  analysis had to be peer reviewed and accepted for publication
                  before experimental work could begin. However, the various
                  barriers and challenges we encountered while designing and
                  conducting the experiments meant that we were only able to
                  repeat 50 experiments from 23 papers. Here we report these
                  barriers and challenges. First, many original papers failed to
                  report key descriptive and inferential statistics: the data
                  needed to compute effect sizes and conduct power analyses was
                  publicly accessible for just 4 of 193 experiments. Moreover,
                  despite contacting the authors of the original papers, we were
                  unable to obtain these data for 68\% of the experiments.
                  Second, none of the 193 experiments were described in
                  sufficient detail in the original paper to enable us to design
                  protocols to repeat the experiments, so we had to seek
                  clarifications from the original authors. While authors were
                  extremely or very helpful for 41\% of experiments, they were
                  minimally helpful for 9\% of experiments, and not at all
                  helpful (or did not respond to us) for 32\% of experiments.
                  Third, once experimental work started, 67\% of the
                  peer-reviewed protocols required modifications to complete the
                  research and just 41\% of those modifications could be
                  implemented. Cumulatively, these three factors limited the
                  number of experiments that could be repeated. This experience
                  draws attention to a basic and fundamental concern about
                  replication - it is hard to assess whether reported findings
                  are credible.},
  url          = {https://elifesciences.org/articles/67995},
  urldate      = {2025-01-22},
  keywords     = {Reproducibility Project: Cancer Biology; cancer biology;
                  human; mouse; open data; open science; preregistration;
                  replication; reproducibility},
  language     = {en}
}

@ARTICLE{Schilling2002-mm,
  title        = {Is human height bimodal?},
  author       = {Schilling, Mark F and Watkins, Ann E and Watkins, William},
  journaltitle = {Am. Stat.},
  publisher    = {Informa UK Limited},
  volume       = {56},
  issue        = {3},
  pages        = {223--229},
  date         = {2002-08-01},
  doi          = {10.1198/00031300265},
  issn         = {0003-1305,1537-2731},
  abstract     = {The combined distribution of heights of men and women has
                  become the canonical illustration of bimodality when teaching
                  introductory statistics. But is this example appropriate? This
                  article investigates the conditions under which a mixture of
                  two normal distributions is bimodal. A simple justification is
                  presented that a mixture of equally weighted normal
                  distributions with common standard deviation σ is bimodal if
                  and only if the difference between the means of the
                  distributions is greater than 2σ. More generally, a mixture of
                  two normal distributions with similar variability cannot be
                  bimodal unless their means differ by more than approximately
                  the sum oftheirstandard deviations. Examination of national
                  survey data on young adults shows that the separation between
                  the distributions of men's and women's heights is not wide
                  enough to produce bimodality. We suggest reasons why
                  histograms of height nevertheless often appear bimodal.},
  url          = {https://www.csun.edu/~hcmth031/ihhb.pdf},
  language     = {en}
}

@BOOK{Iverson1962-ot,
  title     = {A Programming Language},
  author    = {Iverson, Kenneth E},
  publisher = {John Wiley \& Sons Inc.},
  date      = {1962},
  url       = {https://archive.org/details/aprogramminglanguage1962},
  urldate   = {2025-01-19},
  language  = {en}
}

@ARTICLE{Prigent2022-iq,
  title        = {{BioImageIT}: Open-source framework for integration of image
                  data management with analysis},
  author       = {Prigent, Sylvain and Valades-Cruz, Cesar Augusto and Leconte,
                  Ludovic and Maury, Léo and Salamero, Jean and Kervrann,
                  Charles},
  journaltitle = {Nat. Methods},
  publisher    = {Springer Science and Business Media LLC},
  volume       = {19},
  issue        = {11},
  pages        = {1328--1330},
  date         = {2022-11},
  doi          = {10.1038/s41592-022-01642-9},
  pmid         = {36207445},
  issn         = {1548-7105,1548-7091},
  abstract     = {BioImageIT: Open-source framework for integration of image
                  data management with analysis},
  url          = {https://pubmed.ncbi.nlm.nih.gov/36207445/},
  urldate      = {2025-01-17},
  language     = {en}
}

@BOOK{Kernighan1984-au,
  title     = {The {UNIX} programming environment},
  author    = {Kernighan, Brian W and Pike, Rob},
  publisher = {Pearson},
  location  = {Upper Saddle River, NJ},
  date      = {1984},
  pagetotal = {372},
  isbn      = {9780139376818},
  abstract  = {In their Preface, the authors explain, "This book is meant to
               help the reader learn how to program in C. It contains a tutorial
               introduction to get new users started as soon as possible,
               separate chapters on each major feature, and a reference manual.
               Most of the treatment is based on reading, writing, and revising
               examples, rather than on mere statements of rules. For the most
               part, the examples are complete, real programs, rather than
               isolated fragments. All examples have been tested directly from
               the text, which is in machine-readable form. Besides showing how
               to make effective use of the language, we have also tried where
               possible to illustrate useful algorithms and principles of good
               style and sound design... Book jacket.},
  language  = {en}
}

@BOOK{Martin2024-ie,
  title     = {Bayesian Analysis with Python: A practical guide to probabilistic
               modeling},
  author    = {Martin, Osvaldo},
  publisher = {Packt Publishing},
  location  = {Birmingham, England},
  edition   = {3rd},
  date      = {2024-01-22},
  isbn      = {9781805127161},
  language  = {en}
}

@ARTICLE{Wilkinson2016-tf,
  title        = {The {FAIR} Guiding Principles for scientific data management
                  and stewardship},
  author       = {Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, I
                  Jsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak,
                  Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva
                  Santos, Luiz Bonino and Bourne, Philip E and Bouwman, Jildau
                  and Brookes, Anthony J and Clark, Tim and Crosas, Mercè and
                  Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo,
                  Chris T and Finkers, Richard and Gonzalez-Beltran, Alejandra
                  and Gray, Alasdair J G and Groth, Paul and Goble, Carole and
                  Grethe, Jeffrey S and Heringa, Jaap and 't Hoen, Peter A C and
                  Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and
                  Lusher, Scott J and Martone, Maryann E and Mons, Albert and
                  Packer, Abel L and Persson, Bengt and Rocca-Serra, Philippe
                  and Roos, Marco and van Schaik, Rene and Sansone,
                  Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and
                  Slater, Ted and Strawn, George and Swertz, Morris A and
                  Thompson, Mark and van der Lei, Johan and van Mulligen, Erik
                  and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter
                  and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  journaltitle = {Sci. Data},
  publisher    = {Nature Publishing Group},
  volume       = {3},
  issue        = {1},
  pages        = {160018},
  date         = {2016-03-15},
  doi          = {10.1038/sdata.2016.18},
  pmc          = {PMC4792175},
  pmid         = {26978244},
  issn         = {2052-4463,2052-4463},
  abstract     = {There is an urgent need to improve the infrastructure
                  supporting the reuse of scholarly data. A diverse set of
                  stakeholders-representing academia, industry, funding
                  agencies, and scholarly publishers-have come together to
                  design and jointly endorse a concise and measureable set of
                  principles that we refer to as the FAIR Data Principles. The
                  intent is that these may act as a guideline for those wishing
                  to enhance the reusability of their data holdings. Distinct
                  from peer initiatives that focus on the human scholar, the
                  FAIR Principles put specific emphasis on enhancing the ability
                  of machines to automatically find and use the data, in
                  addition to supporting its reuse by individuals. This Comment
                  is the first formal publication of the FAIR Principles, and
                  includes the rationale behind them, and some exemplar
                  implementations in the community.},
  url          = {https://www.nature.com/articles/sdata201618},
  urldate      = {2024-10-08},
  language     = {en}
}

@BOOK{Gandrud2018-nf,
  title     = {Reproducible research with {R} and {RStudio}},
  author    = {Gandrud, Christopher},
  publisher = {Chapman and Hall/CRC},
  edition   = {2nd},
  date      = {2018-09-03},
  doi       = {10.1201/9781315382548},
  isbn      = {9781315382548},
  abstract  = {… The tools of reproducible research have developed rapidly since
               the first edition of this book … • The rmarkdown package, which
               allows you to create reproducible research documents in …},
  url       = {https://api.taylorfrancis.com/content/books/mono/download?identifierName=doi&identifierValue=10.1201/9781315382548&type=googlepdf}
}

@ARTICLE{DeBruine2021-cz,
  title        = {Understanding Mixed-Effects Models Through Data Simulation},
  author       = {DeBruine, Lisa M and Barr, Dale J},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  publisher    = {SAGE Publications Inc},
  volume       = {4},
  issue        = {1},
  pages        = {2515245920965119},
  date         = {2021-01-01},
  doi          = {10.1177/2515245920965119},
  issn         = {2515-2459},
  abstract     = {Experimental designs that sample both subjects and stimuli
                  from a larger population need to account for random effects of
                  both subjects and stimuli using mixed-effects models. However,
                  much of this research is analyzed using analysis of variance
                  on aggregated responses because researchers are not confident
                  specifying and interpreting mixed-effects models. This
                  Tutorial explains how to simulate data with random-effects
                  structure and analyze the data using linear mixed-effects
                  regression (with the lme4 R package), with a focus on
                  interpreting the output in light of the simulated parameters.
                  Data simulation not only can enhance understanding of how
                  these models work, but also enables researchers to perform
                  power calculations for complex designs. All materials
                  associated with this article can be accessed at
                  https://osf.io/3cz2e/.},
  url          = {https://doi.org/10.1177/2515245920965119}
}

@ARTICLE{Yengo2018-gk,
  title        = {Meta-analysis of genome-wide association studies for height
                  and body mass index in ∼700000 individuals of European
                  ancestry},
  author       = {Yengo, Loic and Sidorenko, Julia and Kemper, Kathryn E and
                  Zheng, Zhili and Wood, Andrew R and Weedon, Michael N and
                  Frayling, Timothy M and Hirschhorn, Joel and Yang, Jian and
                  Visscher, Peter M and {GIANT Consortium}},
  journaltitle = {Hum. Mol. Genet.},
  publisher    = {Oxford University Press (OUP)},
  volume       = {27},
  issue        = {20},
  pages        = {3641--3649},
  date         = {2018-10-15},
  doi          = {10.1093/hmg/ddy271},
  pmc          = {PMC6488973},
  pmid         = {30124842},
  issn         = {0964-6906,1460-2083},
  abstract     = {Recent genome-wide association studies (GWAS) of height and
                  body mass index (BMI) in ∼250000 European participants have
                  led to the discovery of ∼700 and ∼100 nearly independent
                  single nucleotide polymorphisms (SNPs) associated with these
                  traits, respectively. Here we combine summary statistics from
                  those two studies with GWAS of height and BMI performed in
                  ∼450000 UK Biobank participants of European ancestry. Overall,
                  our combined GWAS meta-analysis reaches N ∼700000 individuals
                  and substantially increases the number of GWAS signals
                  associated with these traits. We identified 3290 and 941
                  near-independent SNPs associated with height and BMI,
                  respectively (at a revised genome-wide significance threshold
                  of P < 1 × 10-8), including 1185 height-associated SNPs and
                  751 BMI-associated SNPs located within loci not previously
                  identified by these two GWAS. The near-independent genome-wide
                  significant SNPs explain ∼24.6\% of the variance of height and
                  ∼6.0\% of the variance of BMI in an independent sample from
                  the Health and Retirement Study (HRS). Correlations between
                  polygenic scores based upon these SNPs with actual height and
                  BMI in HRS participants were ∼0.44 and ∼0.22, respectively.
                  From analyses of integrating GWAS and expression quantitative
                  trait loci (eQTL) data by summary-data-based Mendelian
                  randomization, we identified an enrichment of eQTLs among lead
                  height and BMI signals, prioritizing 610 and 138 genes,
                  respectively. Our study demonstrates that, as previously
                  predicted, increasing GWAS sample sizes continues to deliver,
                  by the discovery of new loci, increasing prediction accuracy
                  and providing additional data to achieve deeper insight into
                  complex trait biology. All summary statistics are made
                  available for follow-up studies.},
  url          = {https://academic.oup.com/hmg/article-abstract/27/20/3641/5067845},
  keywords     = {body mass index procedure; single nucleotide polymorphism;
                  genome-wide association study; genes; genome},
  language     = {en}
}

@ARTICLE{Kline2010-yk,
  title        = {Population size predicts technological complexity in Oceania},
  author       = {Kline, Michelle A and Boyd, Robert},
  journaltitle = {Proc. Biol. Sci.},
  volume       = {277},
  issue        = {1693},
  pages        = {2559--2564},
  date         = {2010-08-22},
  doi          = {10.1098/rspb.2010.0452},
  pmc          = {PMC2894932},
  pmid         = {20392733},
  issn         = {0962-8452,1471-2954},
  abstract     = {Much human adaptation depends on the gradual accumulation of
                  culturally transmitted knowledge and technology. Recent models
                  of this process predict that large, well-connected populations
                  will have more diverse and complex tool kits than small,
                  isolated populations. While several examples of the loss of
                  technology in small populations are consistent with this
                  prediction, it found no support in two systematic quantitative
                  tests. Both studies were based on data from continental
                  populations in which contact rates were not available, and
                  therefore these studies do not provide a test of the models.
                  Here, we show that in Oceania, around the time of early
                  European contact, islands with small populations had less
                  complicated marine foraging technology. This finding suggests
                  that explanations of existing cultural variation based on
                  optimality models alone are incomplete because demography
                  plays an important role in generating cumulative cultural
                  adaptation. It also indicates that hominin populations with
                  similar cognitive abilities may leave very different
                  archaeological records, a conclusion that has important
                  implications for our understanding of the origin of
                  anatomically modern humans and their evolved psychology.},
  url          = {http://dx.doi.org/10.1098/rspb.2010.0452},
  language     = {en}
}

@BOOK{Tabachnick2019-tl,
  title     = {Using Multivariate Statistics},
  author    = {Tabachnick, Barbara and Fidell, Linda},
  publisher = {Pearson},
  location  = {New York, NY},
  edition   = {7th},
  date      = {2019},
  isbn      = {9780134790541},
  url       = {https://www.pearson.com/en-us/subject-catalog/p/using-multivariate-statistics/P200000003097/9780137526543}
}

@ARTICLE{Potthoff1964-cc,
  title        = {A Generalized Multivariate Analysis of Variance Model Useful
                  Especially for Growth Curve Problems},
  author       = {Potthoff, Richard F and Roy, S N},
  journaltitle = {Biometrika},
  publisher    = {[Oxford University Press, Biometrika Trust]},
  volume       = {51},
  issue        = {3/4},
  pages        = {313--326},
  date         = {1964},
  doi          = {10.2307/2334137},
  issn         = {0006-3444},
  abstract     = {[The usual MANOVA (multivariate analysis of variance) model
                  (see equation (1)) may be generalized (equation (3)) by
                  allowing for the appending of a post-matrix in the expectation
                  equation. As explained in $\S 1$, this generalized model (3)
                  is applicable particularly to many kinds of growth curve
                  problems, as well as to other problems. Section 2 is
                  theoretical, and develops techniques of analysis under the
                  generalized model. A numerical example involving growth curves
                  is worked out in $\S 3$.]},
  url          = {http://www.jstor.org/stable/2334137}
}

@ARTICLE{Vatcheva2016-tr,
  title        = {Multicollinearity in Regression Analyses Conducted in
                  Epidemiologic Studies},
  author       = {Vatcheva, Kristina P and Lee, Minjae and McCormick, Joseph B
                  and Rahbar, Mohammad H},
  journaltitle = {Epidemiology},
  volume       = {6},
  issue        = {2},
  pages        = {227},
  date         = {2016-04},
  doi          = {10.4172/2161-1165.1000227},
  pmc          = {PMC4888898},
  pmid         = {27274911},
  issn         = {1044-3983},
  abstract     = {The adverse impact of ignoring multicollinearity on findings
                  and data interpretation in regression analysis is very well
                  documented in the statistical literature. The failure to
                  identify and report multicollinearity could result in
                  misleading interpretations of the results. A review of
                  epidemiological literature in PubMed from January 2004 to
                  December 2013, illustrated the need for a greater attention to
                  identifying and minimizing the effect of multicollinearity in
                  analysis of data from epidemiologic studies. We used simulated
                  datasets and real life data from the Cameron County Hispanic
                  Cohort to demonstrate the adverse effects of multicollinearity
                  in the regression analysis and encourage researchers to
                  consider the diagnostic for multicollinearity as one of the
                  steps in regression analysis.},
  url          = {http://dx.doi.org/10.4172/2161-1165.1000227},
  keywords     = {BMI; Multicollinearity; Regression analysis; Simulation; Waist
                  circumference},
  language     = {en}
}

@ARTICLE{Farrar1967-mn,
  title        = {Multicollinearity in Regression Analysis: The Problem
                  Revisited},
  author       = {Farrar, Donald E and Glauber, Robert R},
  journaltitle = {Rev. Econ. Stat.},
  volume       = {49},
  issue        = {1},
  pages        = {92--107},
  date         = {1967},
  doi          = {10.2307/1937887},
  issn         = {0034-6535,1530-9142},
  url          = {http://www.jstor.org/stable/1937887}
}

@ARTICLE{Tu2004-va,
  title        = {Collinearity in linear regression is a serious problem in oral
                  health research},
  author       = {Tu, Yu-Kang and Clerehugh, Valerie and Gilthorpe, Mark S},
  journaltitle = {Eur. J. Oral Sci.},
  volume       = {112},
  issue        = {5},
  pages        = {389--397},
  date         = {2004-10},
  doi          = {10.1111/j.1600-0722.2004.00160.x},
  pmid         = {15458496},
  issn         = {0909-8836},
  abstract     = {The aim of this article is to encourage good practice in the
                  statistical analysis of dental research data. Our objective is
                  to highlight the statistical problems of collinearity and
                  multicollinearity. These are among the most common statistical
                  pitfalls in oral health research when exploring the
                  relationship between clinical variables using multiple
                  regression analysis. We hope that this article will show why
                  these problems arise and how they can be avoided and overcome.
                  Examples from the periodontal literature will be used to
                  illustrate how collinearity and multicollinearity can
                  seriously distort the model development process as a result of
                  the phenomenon of mathematical coupling. Knowledge of these
                  problems can help to eliminate misleading results and improve
                  any subsequent interpretations. Regression analyses are useful
                  tools in oral health research when their limitations are
                  recognized. However, care is required in planning and it is
                  worthwhile seeking statistical advice when formulating the
                  study's research questions.},
  url          = {http://dx.doi.org/10.1111/j.1600-0722.2004.00160.x},
  language     = {en}
}

@ARTICLE{Stewart1987-hd,
  title        = {Collinearity and Least Squares Regression},
  author       = {Stewart, G W},
  journaltitle = {Statistical Science},
  publisher    = {Institute of Mathematical Statistics},
  volume       = {2},
  issue        = {1},
  pages        = {68--84},
  date         = {1987-02},
  doi          = {10.1214/ss/1177013439},
  issn         = {0036-7702},
  abstract     = {In this paper we introduce certain numbers, called
                  collinearity indices, which are useful in detecting near
                  collinearities in regression problems. The coefficients enter
                  adversely into formulas concerning significance testing and
                  the effects of errors in the regression variables. Thus they
                  provide simple regression diagnostics, suitable for
                  incorporation in regression packages.},
  url          = {https://projecteuclid.org/journals/statistical-science/volume-2/issue-1/Collinearity-and-Least-Squares-Regression/10.1214/ss/1177013439.short},
  urldate      = {2023-11-30},
  keywords     = {collinearity; errors in the variables; ill-conditioning;
                  Linear regression; regression diagnostics;},
  language     = {en}
}

@ARTICLE{Moller2001-uw,
  title        = {Testing and adjusting for publication bias},
  author       = {Møller, Anders Pape and Jennions, Michael D},
  journaltitle = {Trends Ecol. Evol.},
  publisher    = {Elsevier BV},
  volume       = {16},
  issue        = {10},
  pages        = {580--586},
  date         = {2001-10},
  doi          = {10.1016/s0169-5347(01)02235-2},
  issn         = {0169-5347,1872-8383},
  url          = {https://bizturnell.files.wordpress.com/2021/01/moller-jennions-2001.pdf},
  language     = {en}
}

@ARTICLE{Rosenthal1979-wa,
  title        = {The file drawer problem and tolerance for null results},
  author       = {Rosenthal, Robert},
  journaltitle = {Psychol. Bull.},
  volume       = {86},
  issue        = {3},
  pages        = {638--641},
  date         = {1979-05},
  doi          = {10.1037/0033-2909.86.3.638},
  issn         = {0033-2909},
  abstract     = {For any given research area, one cannot tell how many studies
                  have been conducted but never reported. The extreme view of
                  the "file drawer problem" is that journals are filled with the
                  5\% of the studies that show Type I errors, while the file
                  drawers are filled with the 95\% of the studies that show
                  nonsignificant results. Quantitative procedures for computing
                  the tolerance for filed and future null results are reported
                  and illustrated, and the implications are discussed. (15 ref)
                  (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  url          = {https://psycnet.apa.org/fulltext/1979-27602-001.pdf},
  urldate      = {2023-10-24}
}

@BOOK{Stone2013-xa,
  title     = {Bayes' Rule: A Tutorial Introduction to Bayesian Analysis},
  author    = {Stone, James V},
  publisher = {Sebtel Press},
  location  = {[Erscheinungsort nicht ermittelbar]},
  edition   = {1},
  date      = {2013},
  pagetotal = {182},
  isbn      = {9780956372895},
  url       = {https://www.amazon.com/dp/0956372899/ref=as_li_qf_sp_asin_mfw?&linkCode=wey&tag=httwwwsheacuk-20}
}

@ARTICLE{Gigerenzer2004-aw,
  title        = {Mindless statistics},
  author       = {Gigerenzer, Gerd},
  journaltitle = {J. Socio Econ.},
  volume       = {33},
  issue        = {5},
  pages        = {587--606},
  date         = {2004-11-01},
  doi          = {10.1016/j.socec.2004.09.033},
  issn         = {1053-5357},
  abstract     = {Statistical rituals largely eliminate statistical thinking in
                  the social sciences. Rituals are indispensable for
                  identification with social groups, but they should be the
                  subject rather than the procedure of science. What I call the
                  “null ritual” consists of three steps: (1) set up a
                  statistical null hypothesis, but do not specify your own
                  hypothesis nor any alternative hypothesis, (2) use the 5\%
                  significance level for rejecting the null and accepting your
                  hypothesis, and (3) always perform this procedure. I report
                  evidence of the resulting collective confusion and fears about
                  sanctions on the part of students and teachers, researchers
                  and editors, as well as textbook writers.},
  url          = {https://www.sciencedirect.com/science/article/pii/S1053535704000927},
  keywords     = {Rituals; Collective illusions; Statistical significance;
                  Editors; Textbooks}
}

@BOOK{Kutner2004-hz,
  title     = {Applied Linear Statistical Models},
  author    = {Kutner, Michael H and Nachtsheim, Christopher J and Neter, John
               and Li, William},
  publisher = {McGraw-Hill/Irwin},
  location  = {Boston},
  edition   = {5th edition},
  date      = {2004-08-10},
  pagetotal = {1396},
  isbn      = {9780073108742},
  abstract  = {Applied Linear Statistical Models 5e is the long established
               leading authoritative text and reference on statistical modeling,
               analysis of variance, and the design of experiments. For students
               in most any discipline where statistical analysis or
               interpretation is used, ALSM serves as the standard work. The
               text proceeds through linear and nonlinear regression and
               modeling for the first half, and through ANOVA and Experimental
               Design in the second half. All topics are presented in a precise
               and clear style supported with solved examples, numbered
               formulae, graphic illustrations, and "Comments" to provide depth
               and statistical accuracy and precision. Applications used within
               the text and the hallmark problems, exercises, projects, and case
               studies are drawn from virtually all disciplines and fields
               providing motivation for students in virtually any college. The
               Fifth edition provides an increased use of computing and
               graphical analysis throughout, without sacrificing concepts or
               rigor. In general, the 5e uses larger data sets in examples and
               exercises, and the use of automated software without loss of
               understanding.},
  url       = {http://www.amazon.com/Applied-Linear-Statistical-Models-Michael/dp/007310874X/ref=sr_1_1?ie=UTF8&qid=1425319377&sr=8-1&keywords=applied+linear+statistical+models},
  language  = {English}
}

@ARTICLE{Midway2020-uu,
  title        = {Comparing multiple comparisons: practical guidance for
                  choosing the best multiple comparisons test},
  author       = {Midway, Stephen and Robertson, Matthew and Flinn, Shane and
                  Kaller, Michael},
  journaltitle = {PeerJ},
  volume       = {8},
  pages        = {e10387},
  date         = {2020-12-04},
  doi          = {10.7717/peerj.10387},
  pmc          = {PMC7720730},
  pmid         = {33335808},
  issn         = {2167-8359},
  abstract     = {Multiple comparisons tests (MCTs) include the statistical
                  tests used to compare groups (treatments) often following a
                  significant effect reported in one of many types of linear
                  models. Due to a variety of data and statistical
                  considerations, several dozen MCTs have been developed over
                  the decades, with tests ranging from very similar to each
                  other to very different from each other. Many scientific
                  disciplines use MCTs, including >40,000 reports of their use
                  in ecological journals in the last 60 years. Despite the
                  ubiquity and utility of MCTs, several issues remain in terms
                  of their correct use and reporting. In this study, we
                  evaluated 17 different MCTs. We first reviewed the published
                  literature for recommendations on their correct use. Second,
                  we created a simulation that evaluated the performance of nine
                  common MCTs. The tests examined in the simulation were those
                  that often overlapped in usage, meaning the selection of the
                  test based on fit to the data is not unique and that the
                  simulations could inform the selection of one or more tests
                  when a researcher has choices. Based on the literature review
                  and recommendations: planned comparisons are overwhelmingly
                  recommended over unplanned comparisons, for planned
                  non-parametric comparisons the Mann-Whitney-Wilcoxon U test is
                  recommended, Scheffé's S test is recommended for any linear
                  combination of (unplanned) means, Tukey's HSD and the
                  Bonferroni or the Dunn-Sidak tests are recommended for
                  pairwise comparisons of groups, and that many other tests
                  exist for particular types of data. All code and data used to
                  generate this paper are available at:
                  https://github.com/stevemidway/MultipleComparisons.},
  url          = {http://dx.doi.org/10.7717/peerj.10387},
  keywords     = {ANOVA; Bonferroni; Contrasts; Multiple comparisons; Scheffé;
                  Tukey HSD},
  language     = {en}
}

@ARTICLE{Miller2019-pw,
  title        = {The quest for an optimal alpha},
  author       = {Miller, Jeff and Ulrich, Rolf},
  journaltitle = {PLoS One},
  volume       = {14},
  issue        = {1},
  pages        = {e0208631},
  date         = {2019-01-02},
  doi          = {10.1371/journal.pone.0208631},
  pmc          = {PMC6314595},
  pmid         = {30601826},
  issn         = {1932-6203},
  abstract     = {Researchers who analyze data within the framework of null
                  hypothesis significance testing must choose a critical "alpha"
                  level, α, to use as a cutoff for deciding whether a given set
                  of data demonstrates the presence of a particular effect. In
                  most fields, α = 0.05 has traditionally been used as the
                  standard cutoff. Many researchers have recently argued for a
                  change to a more stringent evidence cutoff such as α = 0.01,
                  0.005, or 0.001, noting that this change would tend to reduce
                  the rate of false positives, which are of growing concern in
                  many research areas. Other researchers oppose this proposed
                  change, however, because it would correspondingly tend to
                  increase the rate of false negatives. We show how a simple
                  statistical model can be used to explore the quantitative
                  tradeoff between reducing false positives and increasing false
                  negatives. In particular, the model shows how the optimal α
                  level depends on numerous characteristics of the research
                  area, and it reveals that although α = 0.05 would indeed be
                  approximately the optimal value in some realistic situations,
                  the optimal α could actually be substantially larger or
                  smaller in other situations. The importance of the model lies
                  in making it clear what characteristics of the research area
                  have to be specified to make a principled argument for using
                  one α level rather than another, and the model thereby
                  provides a blueprint for researchers seeking to justify a
                  particular α level.},
  url          = {http://dx.doi.org/10.1371/journal.pone.0208631},
  language     = {en}
}

@ARTICLE{Kruschke2010-wi,
  title        = {What to believe: Bayesian methods for data analysis},
  author       = {Kruschke, John K},
  journaltitle = {Trends Cogn. Sci.},
  volume       = {14},
  issue        = {7},
  pages        = {293--300},
  date         = {2010-07},
  doi          = {10.1016/j.tics.2010.05.001},
  pmid         = {20542462},
  issn         = {1364-6613,1879-307X},
  abstract     = {Although Bayesian models of mind have attracted great interest
                  from cognitive scientists, Bayesian methods for data analysis
                  have not. This article reviews several advantages of Bayesian
                  data analysis over traditional null-hypothesis significance
                  testing. Bayesian methods provide tremendous flexibility for
                  data analytic models and yield rich information about
                  parameters that can be used cumulatively across progressive
                  experiments. Because Bayesian statistical methods can be
                  applied to any data, regardless of the type of cognitive model
                  (Bayesian or otherwise) that motivated the data collection,
                  Bayesian methods for data analysis will continue to be
                  appropriate even if Bayesian models of mind lose their appeal.},
  url          = {http://dx.doi.org/10.1016/j.tics.2010.05.001},
  language     = {en}
}

@ARTICLE{Kruschke2012-sb,
  title        = {The Time Has Come: Bayesian Methods for Data Analysis in the
                  Organizational Sciences},
  author       = {Kruschke, John K and Aguinis, Herman and Joo, Harry},
  journaltitle = {Organizational Research Methods},
  publisher    = {SAGE Publications Inc},
  volume       = {15},
  issue        = {4},
  pages        = {722--752},
  date         = {2012-10-01},
  doi          = {10.1177/1094428112457829},
  issn         = {1094-4281},
  abstract     = {The use of Bayesian methods for data analysis is creating a
                  revolution in fields ranging from genetics to marketing. Yet,
                  results of our literature review, including more than 10,000
                  articles published in 15 journals from January 2001 and
                  December 2010, indicate that Bayesian approaches are
                  essentially absent from the organizational sciences. Our
                  article introduces organizational science researchers to
                  Bayesian methods and describes why and how they should be
                  used. We use multiple linear regression as the framework to
                  offer a step-by-step demonstration, including the use of
                  software, regarding how to implement Bayesian methods. We
                  explain and illustrate how to determine the prior
                  distribution, compute the posterior distribution, possibly
                  accept the null value, and produce a write-up describing the
                  entire Bayesian process, including graphs, results, and their
                  interpretation. We also offer a summary of the advantages of
                  using Bayesian analysis and examples of how specific published
                  research based on frequentist analysis-based approaches failed
                  to benefit from the advantages offered by a Bayesian approach
                  and how using Bayesian analyses would have led to richer and,
                  in some cases, different substantive conclusions. We hope that
                  our article will serve as a catalyst for the adoption of
                  Bayesian methods in organizational science research.},
  url          = {https://doi.org/10.1177/1094428112457829},
  urldate      = {2016-01-19}
}

@ARTICLE{Lever2015-mi,
  title        = {Videofluoroscopic Validation of a Translational Murine Model
                  of Presbyphagia},
  author       = {Lever, Teresa E and Brooks, Ryan T and Thombs, Lori A and
                  Littrell, Loren L and Harris, Rebecca A and Allen, Mitchell J
                  and Kadosh, Matan D and Robbins, Kate L},
  journaltitle = {Dysphagia},
  volume       = {30},
  issue        = {3},
  pages        = {328--342},
  date         = {2015-06},
  doi          = {10.1007/s00455-015-9604-7},
  pmid         = {25783697},
  issn         = {0179-051X,1432-0460},
  abstract     = {Presbyphagia affects approximately 40\% of otherwise healthy
                  people over 60 years of age. Hence, it is a condition of
                  primary aging rather than a consequence of primary disease.
                  This distinction warrants systematic investigations to
                  understand the causal mechanisms of aging versus disease
                  specifically on the structure and function of the swallowing
                  mechanism. Toward this goal, we have been studying healthy
                  aging C57BL/6 mice (also called B6), the most popular
                  laboratory rodent for biomedical research. The goal of this
                  study was to validate this strain as a model of presbyphagia
                  for translational research purposes. We tested two age groups
                  of B6 mice: young (4-7 months; n = 16) and old (18-21 months;
                  n = 11). Mice underwent a freely behaving videofluoroscopic
                  swallow study (VFSS) protocol developed in our lab. VFSS
                  videos (recorded at 30 frames per second) were analyzed
                  frame-by-frame to quantify 15 swallow metrics. Six of the 15
                  swallow metrics were significantly different between young and
                  old mice. Compared to young mice, old mice had significantly
                  longer pharyngeal and esophageal transit times (p = 0.038 and
                  p = 0.022, respectively), swallowed larger boluses (p =
                  0.032), and had a significantly higher percentage of
                  ineffective primary esophageal swallows (p = 0.0405). In
                  addition, lick rate was significantly slower for old mice,
                  measured using tongue cycle rate (p = 0.0034) and jaw cycle
                  rate (p = 0.0020). This study provides novel evidence that
                  otherwise healthy aging B6 mice indeed develop age-related
                  changes in swallow function resembling presbyphagia in humans.
                  Specifically, aging B6 mice have a generally slow swallow that
                  spans all stages of swallowing: oral, pharyngeal, and
                  esophageal. The next step is to build upon this foundational
                  work by exploring the responsible mechanisms of presbyphagia
                  in B6 mice.},
  url          = {http://dx.doi.org/10.1007/s00455-015-9604-7},
  language     = {en}
}

@ARTICLE{Choi2015-im,
  title        = {Elucidating the {Foundations} of {Statistical} {Inference}
                  with 2 x 2 {Tables}},
  author       = {Choi, Leena and Blume, Jeffrey D and Dupont, William D},
  journaltitle = {PLoS One},
  volume       = {10},
  issue        = {4},
  pages        = {e0121263+},
  date         = {2015-04-07},
  doi          = {10.1371/journal.pone.0121263},
  pmc          = {PMC4388855},
  pmid         = {25849515},
  issn         = {1932-6203},
  abstract     = {To many, the foundations of statistical inference are cryptic
                  and irrelevant to routine statistical practice. The analysis
                  of 2 x 2 contingency tables, omnipresent in the scientific
                  literature, is a case in point. Fisher's exact test is
                  routinely used even though it has been fraught with
                  controversy for over 70 years. The problem, not widely
                  acknowledged, is that several different p-values can be
                  associated with a single table, making scientific inference
                  inconsistent. The root cause of this controversy lies in the
                  table's origins and the manner in which nuisance parameters
                  are eliminated. However, fundamental statistical principles
                  (e.g., sufficiency, ancillarity, conditionality, and
                  likelihood) can shed light on the controversy and guide our
                  approach in using this test. In this paper, we use these
                  fundamental principles to show how much information is lost
                  when the tables origins are ignored and when various
                  approaches are used to eliminate unknown nuisance parameters.
                  We present novel likelihood contours to aid in the
                  visualization of information loss and show that the
                  information loss is often virtually non-existent. We find that
                  problems arising from the discreteness of the sample space are
                  exacerbated by p-value-based inference. Accordingly, methods
                  that are less sensitive to this discreteness - likelihood
                  ratios, posterior probabilities and mid-p-values - lead to
                  more consistent inferences.},
  url          = {http://dx.doi.org/10.1371/journal.pone.0121263},
  note         = {tex.citeulike-article-id= 14033215 tex.citeulike-linkout-0=
                  http://dx.doi.org/10.1371/journal.pone.0121263 tex.day= 7
                  tex.posted-at= 2016-05-11 12:50:32 tex.priority= 2
                  tex.publisher= Public Library of Science},
  keywords     = {2x2-table, ctsafac, fishers-exact-test},
  language     = {en}
}

@ARTICLE{Berner2022-qa,
  title        = {Why and how we should join the shift from significance testing
                  to estimation},
  author       = {Berner, Daniel and Amrhein, Valentin},
  journaltitle = {J. Evol. Biol.},
  volume       = {35},
  issue        = {6},
  pages        = {777--787},
  date         = {2022-06},
  doi          = {10.1111/jeb.14009},
  pmid         = {35582935},
  issn         = {1010-061X,1420-9101},
  abstract     = {A paradigm shift away from null hypothesis significance
                  testing seems in progress. Based on simulations, we illustrate
                  some of the underlying motivations. First, p-values vary
                  strongly from study to study, hence dichotomous inference
                  using significance thresholds is usually unjustified. Second,
                  'statistically significant' results have overestimated effect
                  sizes, a bias declining with increasing statistical power.
                  Third, 'statistically non-significant' results have
                  underestimated effect sizes, and this bias gets stronger with
                  higher statistical power. Fourth, the tested statistical
                  hypotheses usually lack biological justification and are often
                  uninformative. Despite these problems, a screen of 48 papers
                  from the 2020 volume of the Journal of Evolutionary Biology
                  exemplifies that significance testing is still used almost
                  universally in evolutionary biology. All screened studies
                  tested default null hypotheses of zero effect with the default
                  significance threshold of p = 0.05, none presented a
                  pre-specified alternative hypothesis, pre-study power
                  calculation and the probability of 'false negatives' (beta
                  error rate). The results sections of the papers presented 49
                  significance tests on average (median 23, range 0-390). Of 41
                  studies that contained verbal descriptions of a 'statistically
                  non-significant' result, 26 (63\%) falsely claimed the absence
                  of an effect. We conclude that studies in ecology and
                  evolutionary biology are mostly exploratory and descriptive.
                  We should thus shift from claiming to 'test' specific
                  hypotheses statistically to describing and discussing many
                  hypotheses (possible true effect sizes) that are most
                  compatible with our data, given our statistical model. We
                  already have the means for doing so, because we routinely
                  present compatibility ('confidence') intervals covering these
                  hypotheses.},
  url          = {http://dx.doi.org/10.1111/jeb.14009},
  keywords     = {compatibility interval; effect size; null hypothesis; p-value;
                  scientific method; statistical inference},
  language     = {en}
}

@INBOOK{Elwert2013-rn,
  title     = {Graphical causal models},
  author    = {Elwert, Felix},
  editor    = {Morgan, S L},
  booktitle = {Handbook of Causal Analysis for Social Research},
  publisher = {Springer Netherlands},
  pages     = {245--273},
  date      = {2013},
  doi       = {10.1007/978-94-007-6094-3},
  url       = {https://link.springer.com/book/10.1007/978-94-007-6094-3},
  urldate   = {2022-05-31}
}

@ARTICLE{Elwert2014-mn,
  title        = {Endogenous Selection Bias: The Problem of Conditioning on a
                  Collider Variable},
  author       = {Elwert, Felix and Winship, Christopher},
  journaltitle = {Annu. Rev. Sociol.},
  volume       = {40},
  pages        = {31--53},
  date         = {2014-07},
  doi          = {10.1146/annurev-soc-071913-043455},
  pmc          = {PMC6089543},
  pmid         = {30111904},
  issn         = {0360-0572},
  abstract     = {Endogenous selection bias is a central problem for causal
                  inference. Recognizing the problem, however, can be difficult
                  in practice. This article introduces a purely graphical way of
                  characterizing endogenous selection bias and of understanding
                  its consequences (Hernán et al. 2004). We use causal graphs
                  (direct acyclic graphs, or DAGs) to highlight that endogenous
                  selection bias stems from conditioning (e.g., controlling,
                  stratifying, or selecting) on a so-called collider variable,
                  i.e., a variable that is itself caused by two other variables,
                  one that is (or is associated with) the treatment and another
                  that is (or is associated with) the outcome. Endogenous
                  selection bias can result from direct conditioning on the
                  outcome variable, a post-outcome variable, a post-treatment
                  variable, and even a pre-treatment variable. We highlight the
                  difference between endogenous selection bias, common-cause
                  confounding, and overcontrol bias and discuss numerous
                  examples from social stratification, cultural sociology,
                  social network analysis, political sociology, social
                  demography, and the sociology of education.},
  url          = {http://dx.doi.org/10.1146/annurev-soc-071913-043455},
  keywords     = {causality; confounding; directed acyclic graphs;
                  identification; selection},
  language     = {en}
}

@ARTICLE{Davies1998-to,
  title        = {When can odds ratios mislead?},
  author       = {Davies, H T and Crombie, I K and Tavakoli, M},
  journaltitle = {BMJ},
  volume       = {316},
  issue        = {7136},
  pages        = {989--991},
  date         = {1998-03-28},
  doi          = {10.1136/bmj.316.7136.989},
  pmc          = {PMC1112884},
  pmid         = {9550961},
  issn         = {0959-8138},
  url          = {http://dx.doi.org/10.1136/bmj.316.7136.989},
  language     = {en}
}

@ARTICLE{Rafi2020-jd,
  title        = {Semantic and cognitive tools to aid statistical science:
                  Replace confidence and significance by compatibility and
                  surprise},
  author       = {Rafi, Z and Greenland, S},
  journaltitle = {BMC Med. Res. Methodol.},
  publisher    = {BioMed Central Ltd},
  volume       = {20},
  issue        = {1},
  date         = {2020},
  doi          = {10.1186/s12874-020-01105-9},
  pmc          = {32998683},
  issn         = {1471-2288},
  abstract     = {Background: Researchers often misinterpret and misrepresent
                  statistical outputs. This abuse has led to a large literature
                  on modification or replacement of testing thresholds and
                  P-values with confidence intervals, Bayes factors, and other
                  devices. Because the core problems appear cognitive rather
                  than statistical, we review some simple methods to aid
                  researchers in interpreting statistical outputs. These methods
                  emphasize logical and information concepts over probability,
                  and thus may be more robust to common misinterpretations than
                  are traditional descriptions. Methods: We use the Shannon
                  transform of the P-value p, also known as the binary surprisal
                  or S-value s = -log2(p), to provide a measure of the
                  information supplied by the testing procedure, and to help
                  calibrate intuitions against simple physical experiments like
                  coin tossing. We also use tables or graphs of test statistics
                  for alternative hypotheses, and interval estimates for
                  different percentile levels, to thwart fallacies arising from
                  arbitrary dichotomies. Finally, we reinterpret P-values and
                  interval estimates in unconditional terms, which describe
                  compatibility of data with the entire set of analysis
                  assumptions. We illustrate these methods with a reanalysis of
                  data from an existing record-based cohort study. Conclusions:
                  In line with other recent recommendations, we advise that
                  teaching materials and research reports discuss P-values as
                  measures of compatibility rather than significance, compute
                  P-values for alternative hypotheses whenever they are computed
                  for null hypotheses, and interpret interval estimates as
                  showing values of high compatibility with data, rather than
                  regions of confidence. Our recommendations emphasize cognitive
                  devices for displaying the compatibility of the observed data
                  with various hypotheses of interest, rather than focusing on
                  single hypothesis tests or interval estimates. We believe
                  these simple reforms are well worth the minor effort they
                  require. © 2020 The Author(s).},
  url          = {http://dx.doi.org/10.1186/s12874-020-01105-9},
  keywords     = {Bias; Cognitive science; Confidence intervals; Data
                  interpretation; Evidence; Hypothesis tests; Information;
                  Models, statistical; P-values; Statistical significance; Bayes
                  theorem; cognition; cohort analysis; confidence interval;
                  human; probability; semantics; Bayes Theorem; Cognition;
                  Cohort Studies; Confidence Intervals; Humans; Probability;
                  Semantics}
}

@ARTICLE{Muff2022-pg,
  title        = {Rewriting results sections in the language of evidence},
  author       = {Muff, Stefanie and Nilsen, Erlend B and O'Hara, Robert B and
                  Nater, Chloé R},
  journaltitle = {Trends Ecol. Evol.},
  volume       = {37},
  issue        = {3},
  pages        = {203--210},
  date         = {2022-03},
  doi          = {10.1016/j.tree.2021.10.009},
  pmid         = {34799145},
  issn         = {0169-5347,1872-8383},
  abstract     = {Despite much criticism, black-or-white null-hypothesis
                  significance testing with an arbitrary P-value cutoff still is
                  the standard way to report scientific findings. One obstacle
                  to progress is likely a lack of knowledge about suitable
                  alternatives. Here, we suggest language of evidence that
                  allows for a more nuanced approach to communicate scientific
                  findings as a simple and intuitive alternative to statistical
                  significance testing. We provide examples for rewriting
                  results sections in research papers accordingly. Language of
                  evidence has previously been suggested in medical statistics,
                  and it is consistent with reporting approaches of
                  international research networks, like the Intergovernmental
                  Panel on Climate Change, for example. Instead of re-inventing
                  the wheel, ecology and evolution might benefit from adopting
                  some of the 'good practices' that exist in other fields.},
  url          = {http://dx.doi.org/10.1016/j.tree.2021.10.009},
  keywords     = {P-values; evidence; interpretation of scientific results;
                  null-hypothesis significance testing; reproducibility crisis;
                  statistical significance},
  language     = {en}
}

@ARTICLE{Muff2022-gp,
  title        = {Response to 'Why {P}-values are not measures of evidence' by
                  {D}. Lakens},
  author       = {Muff, Stefanie and Nilsen, Erlend B and O'Hara, Robert B and
                  Nater, Chloé R},
  journaltitle = {Trends Ecol. Evol.},
  date         = {2022-01-22},
  doi          = {10.1016/j.tree.2022.01.001},
  pmid         = {35078625},
  issn         = {0169-5347,1872-8383},
  url          = {http://dx.doi.org/10.1016/j.tree.2022.01.001},
  language     = {en}
}

@ARTICLE{Lakens2022-pt,
  title        = {Why {P} values are not measures of evidence},
  author       = {Lakens, Daniël},
  journaltitle = {Trends Ecol. Evol.},
  date         = {2022-01-10},
  doi          = {10.1016/j.tree.2021.12.006},
  pmid         = {35027226},
  issn         = {0169-5347,1872-8383},
  url          = {http://dx.doi.org/10.1016/j.tree.2021.12.006},
  language     = {en}
}

@BOOK{Blitzstein2019-kg,
  title     = {Introduction to Probability},
  author    = {Blitzstein, Joseph K and Hwang, Jessica},
  publisher = {Chapman and Hall/CRC},
  edition   = {2},
  date      = {2019-02-08},
  pagetotal = {634},
  isbn      = {9781138369917},
  language  = {en}
}

@BOOK{Martin2018-dv,
  title     = {Bayesian Analysis with Python: Introduction to statistical
               modeling and probabilistic programming using {PyMC3} and {ArviZ}},
  author    = {Martin, Osvaldo},
  publisher = {Packt Publishing},
  location  = {Birmingham, England},
  edition   = {2},
  date      = {2018-12-26},
  pagetotal = {356},
  isbn      = {9781789341652}
}

@BOOK{Gelman2020-pw,
  title     = {Regression and Other Stories},
  author    = {Gelman, Andrew and Hill, Jennifer and Vehtari, Aki},
  publisher = {Cambridge University Press},
  date      = {2020}
}

@ARTICLE{Packard2011-vn,
  title        = {Rotational distortion in conventional allometric analyses},
  author       = {Packard, Gary C},
  journaltitle = {Comp. Biochem. Physiol. A Mol. Integr. Physiol.},
  volume       = {159},
  issue        = {4},
  pages        = {392--400},
  date         = {2011-08},
  doi          = {10.1016/j.cbpa.2011.04.005},
  pmid         = {21527351},
  issn         = {1095-6433,1531-4332},
  abstract     = {Three data sets from the recent literature were submitted to
                  new analyses to illustrate the rotational distortion that
                  commonly accompanies traditional allometric analyses and that
                  often causes allometric equations to be inaccurate and
                  misleading. The first investigation focused on the scaling of
                  evaporative water loss to body mass in passerine birds; the
                  second was concerned with the influence of body size on field
                  metabolic rates of rodents; and the third addressed
                  interspecific variation in kidney mass among primates.
                  Straight lines were fitted to logarithmic transformations by
                  Ordinary Least Squares and Generalized Linear Models, and the
                  resulting equations then were re-expressed as two-parameter
                  power functions in the original arithmetic scales. The
                  re-expressed models were displayed on bivariate graphs
                  together with tracings for equations fitted directly to
                  untransformed data by nonlinear regression. In all instances,
                  models estimated by back-transformation failed to describe
                  major features of the arithmetic distribution whereas
                  equations fitted by nonlinear regression performed quite well.
                  The poor performance of equations based on models fitted to
                  logarithms can be traced to the increased weight and leverage
                  exerted in those analyses by observations for small species
                  and to the decreased weight and leverage exerted by large
                  ones. The problem of rotational distortion can be avoided by
                  performing exploratory analysis on untransformed values and by
                  validating fitted models in the scale of measurement.},
  url          = {http://dx.doi.org/10.1016/j.cbpa.2011.04.005},
  urldate      = {2016-01-24},
  language     = {en}
}

@ARTICLE{Packard2011-fu,
  title        = {Fitting statistical models in bivariate allometry},
  author       = {Packard, Gary C and Birchard, Geoffrey F and Boardman, Thomas
                  J},
  journaltitle = {Biol. Rev. Camb. Philos. Soc.},
  volume       = {86},
  issue        = {3},
  pages        = {549--563},
  date         = {2011-08-01},
  doi          = {10.1111/j.1469-185X.2010.00160.x},
  pmid         = {21040370},
  issn         = {1464-7931,1469-185X},
  abstract     = {Several attempts have been made in recent years to formulate a
                  general explanation for what appear to be recurring patterns
                  of allometric variation in morphology, physiology, and ecology
                  of both plants and animals (e.g. the Metabolic Theory of
                  Ecology, the Allometric Cascade, the Metabolic-Level
                  Boundaries hypothesis). However, published estimates for
                  parameters in allometric equations often are inaccurate, owing
                  to undetected bias introduced by the traditional method for
                  fitting lines to empirical data. The traditional method
                  entails fitting a straight line to logarithmic transformations
                  of the original data and then back-transforming the resulting
                  equation to the arithmetic scale. Because of fundamental
                  changes in distributions attending transformation of predictor
                  and response variables, the traditional practice may cause
                  influential outliers to go undetected, and it may result in an
                  underparameterized model being fitted to the data. Also,
                  substantial bias may be introduced by the insidious rotational
                  distortion that accompanies regression analyses performed on
                  logarithms. Consequently, the aforementioned patterns of
                  allometric variation may be illusions, and the theoretical
                  explanations may be wide of the mark. Problems attending the
                  traditional procedure can be largely avoided in future
                  research simply by performing preliminary analyses on
                  arithmetic values and by validating fitted equations in the
                  arithmetic domain. The goal of most allometric research is to
                  characterize relationships between biological variables and
                  body size, and this is done most effectively with data
                  expressed in the units of measurement. Back-transforming from
                  a straight line fitted to logarithms is not a generally
                  reliable way to estimate an allometric equation in the
                  original scale.},
  url          = {http://dx.doi.org/10.1111/j.1469-185X.2010.00160.x},
  urldate      = {2016-01-24},
  language     = {en}
}

@ARTICLE{Graham2003-yz,
  title        = {Confronting multicollinearity in ecological multiple
                  regression},
  author       = {Graham, Michael H},
  journaltitle = {Ecology},
  volume       = {84},
  issue        = {11},
  pages        = {2809--2815},
  date         = {2003-11},
  doi          = {10.1890/02-3114},
  issn         = {0012-9658,1939-9170},
  abstract     = {The natural complexity of ecological communities regularly
                  lures ecologists to collect elaborate data sets in which
                  confounding factors are often present. Although multiple
                  regression is commonly used in such cases to test the
                  individual effects of many explanatory variables on a
                  continuous response, the inherent collinearity
                  (multicollinearity) of confounded explanatory variables
                  encumbers analyses and threatens their statistical and
                  inferential interpretation. Using numerical simulations, I
                  quantified the impact of multicollinearity on ecological
                  multiple regression and found that even low levels of
                  collinearity bias analyses (r ≥ 0.28 or r2 ≥ 0.08), causing
                  (1) inaccurate model parameterization, (2) decreased
                  statistical power, and (3) exclusion of significant predictor
                  variables during model creation. Then, using real ecological
                  data, I demonstrated the utility of various statistical
                  techniques for enhancing the reliability and interpretation of
                  ecological multiple regression in the presence of
                  multicollinearity.},
  url          = {http://doi.wiley.com/10.1890/02-3114}
}

@BOOK{Wright2021-hb,
  title     = {Tidyverse Skills for Data Science in {R}},
  author    = {Wright, Carrie and Ellis, Shannon and Hicks, Stephanie and Peng,
               Roger D},
  publisher = {Leanpub},
  date      = {2021}
}

@ARTICLE{Lind2016-uf,
  title        = {Unified data management for distributed experiments: A model
                  for collaborative grassroots scientific networks},
  author       = {Lind, Eric M},
  journaltitle = {Ecol. Inform.},
  volume       = {36},
  pages        = {231--236},
  date         = {2016-11-01},
  doi          = {10.1016/j.ecoinf.2016.08.002},
  issn         = {1574-9541},
  abstract     = {The rapidly growing number of grassroots ecological research
                  networks demonstrates that ecologists have embraced
                  distributed data collection and experimentation as a new tool
                  for addressing global questions. A clear advantage of these
                  networks is the ability to gather data at larger spatial and
                  temporal scales and at relatively lower cost than could be
                  typically accomplished by a single research team. However, a
                  challenge arising from this structure is the need to merge
                  distributed datasets into a coherent whole. The Nutrient
                  Network, a coordinated distributed experiment entering its
                  tenth year of data collection, has records from over 90 sites
                  worldwide to date. In this paper I present lessons learned
                  about data management from this project, focusing on such
                  issues as standardization, storage, updates, and distribution
                  of data within the network. I provide a relational database
                  schema and associated workflow that could be generalized to
                  many distributed ecological experiments or networked data
                  observatories, especially those with need for taxonomic
                  reconciliation of species occurrences. The success of
                  distributed data collection efforts, especially long-term
                  networks, will be proportional to the ability to coordinate
                  and effectively combine project datasets.},
  url          = {http://www.sciencedirect.com/science/article/pii/S1574954116301133},
  keywords     = {Data management; Database schema; Distributed experiment;
                  Nutrient network; Taxonomic resolution}
}

@ARTICLE{Freedman2017-pg,
  title        = {{Reproducibility2020}: Progress and priorities},
  author       = {Freedman, Leonard P and Venugopalan, Gautham and Wisman,
                  Rosann},
  journaltitle = {F1000Res.},
  volume       = {6},
  pages        = {604},
  date         = {2017-05-02},
  doi          = {10.12688/f1000research.11334.1},
  pmc          = {PMC5461896},
  pmid         = {28620458},
  issn         = {2046-1402},
  abstract     = {The preclinical research process is a cycle of idea
                  generation, experimentation, and reporting of results. The
                  biomedical research community relies on the reproducibility of
                  published discoveries to create new lines of research and to
                  translate research findings into therapeutic applications.
                  Since 2012, when scientists from Amgen reported that they were
                  able to reproduce only 6 of 53 "landmark" preclinical studies,
                  the biomedical research community began discussing the scale
                  of the reproducibility problem and developing initiatives to
                  address critical challenges. Global Biological Standards
                  Institute (GBSI) released the "Case for Standards" in 2013,
                  one of the first comprehensive reports to address the rising
                  concern of irreproducible biomedical research. Further
                  attention was drawn to issues that limit scientific
                  self-correction, including reporting and publication bias,
                  underpowered studies, lack of open access to methods and data,
                  and lack of clearly defined standards and guidelines in areas
                  such as reagent validation. To evaluate the progress made
                  towards reproducibility since 2013, GBSI identified and
                  examined initiatives designed to advance quality and
                  reproducibility. Through this process, we identified key roles
                  for funders, journals, researchers and other stakeholders and
                  recommended actions for future progress. This paper describes
                  our findings and conclusions.},
  url          = {http://dx.doi.org/10.12688/f1000research.11334.1},
  keywords     = {preclinical research; protocol sharing; reagents and reference
                  materials; reproducibility; scientific publications; study
                  design},
  language     = {en}
}

@ARTICLE{Munafo2017-ia,
  title        = {A manifesto for reproducible science},
  author       = {Munafò, Marcus R and Nosek, Brian A and Bishop, Dorothy V M
                  and Button, Katherine S and Chambers, Christopher D and Percie
                  du Sert, Nathalie and Simonsohn, Uri and Wagenmakers, Eric-Jan
                  and Ware, Jennifer J and Ioannidis, John P A},
  journaltitle = {Nature Human Behaviour},
  volume       = {1},
  issue        = {1},
  pages        = {0021},
  date         = {2017-01-10},
  doi          = {10.1038/s41562-016-0021},
  issn         = {2397-3374},
  abstract     = {Improving the reliability and efficiency of scientific
                  research will increase the credibility of the published
                  scientific literature and accelerate discovery. Here we argue
                  for the adoption of measures to optimize key elements of the
                  scientific process: methods, reporting and dissemination,
                  reproducibility, evaluation and incentives. There is some
                  evidence from both simulations and empirical studies
                  supporting the likely effectiveness of these measures, but
                  their broad adoption by researchers, institutions, funders and
                  journals will require iterative evaluation and improvement. We
                  discuss the goals of these measures, and how they can be
                  implemented, in the hope that this will facilitate action
                  toward improving the transparency, reproducibility and
                  efficiency of scientific research.},
  url          = {https://doi.org/10.1038/s41562-016-0021}
}

@BOOK{McElreath2007-hs,
  title     = {Mathematical Models of Social Evolution: A Guide for the
               Perplexed},
  author    = {McElreath, Richard and Boyd, Robert},
  publisher = {University of Chicago Press},
  date      = {2007}
}

@BOOK{Whitlock2014-wn,
  title     = {The Analysis of Biological Data},
  author    = {Whitlock, Michael C and Schluter, Dolph},
  publisher = {Roberts and Company Publishers},
  location  = {Greenwood Village, Colorado},
  edition   = {2nd Edition},
  date      = {2014-06-02},
  pagetotal = {768},
  isbn      = {9781936221486},
  url       = {http://www.amazon.com/Analysis-Biological-Data-Second/dp/1936221489/ref=sr_1_1?s=books&ie=UTF8&qid=1425318495&sr=1-1&keywords=whitlock+schluter},
  language  = {English}
}

@ARTICLE{Hubbard2019-bv,
  title        = {Will the {ASA}'s Efforts to Improve Statistical Practice be
                  Successful? Some Evidence to the Contrary},
  author       = {Hubbard, Raymond},
  journaltitle = {Am. Stat.},
  publisher    = {Taylor \& Francis},
  volume       = {73},
  issue        = {sup1},
  pages        = {31--35},
  date         = {2019-03-29},
  doi          = {10.1080/00031305.2018.1497540},
  issn         = {0003-1305},
  abstract     = {ABSTRACTRecent efforts by the American Statistical Association
                  to improve statistical practice, especially in countering the
                  misuse and abuse of null hypothesis significance testing
                  (NHST) and p-values, are to be welcomed. But will they be
                  successful? The present study offers compelling evidence that
                  this will be an extraordinarily difficult task. Dramatic
                  citation-count data on 25 articles and books severely critical
                  of NHST's negative impact on good science, underlining that
                  this issue was/is well known, did nothing to stem its usage
                  over the period 1960?2007. On the contrary, employment of NHST
                  increased during this time. To be successful in this endeavor,
                  as well as restoring the relevance of the statistics
                  profession to the scientific community in the 21st century,
                  the ASA must be prepared to dispense detailed advice. This
                  includes specifying those situations, if they can be
                  identified, in which the p-value plays a clearly valuable role
                  in data analysis and interpretation. The ASA might also
                  consider a statement that recommends abandoning the use of
                  p-values.},
  url          = {https://doi.org/10.1080/00031305.2018.1497540},
  note         = {doi: 10.1080/00031305.2018.1497540}
}

@ARTICLE{Hubbard2019-ie,
  title        = {The Limited Role of Formal Statistical Inference in Scientific
                  Inference},
  author       = {Hubbard, Raymond and Haig, Brian D and Parsa, Rahul A},
  journaltitle = {Am. Stat.},
  publisher    = {Taylor \& Francis},
  volume       = {73},
  issue        = {sup1},
  pages        = {91--98},
  date         = {2019-03-29},
  doi          = {10.1080/00031305.2018.1464947},
  issn         = {0003-1305},
  abstract     = {ABSTRACTSuch is the grip of formal methods of statistical
                  inference?that is, frequentist methods for generalizing from
                  sample to population in enumerative studies?in the drawing of
                  scientific inferences that the two are routinely deemed
                  equivalent in the social, management, and biomedical sciences.
                  This, despite the fact that legitimate employment of said
                  methods is difficult to implement on practical grounds alone.
                  But supposing the adoption of these procedures were simple
                  does not get us far; crucially, methods of formal statistical
                  inference are ill-suited to the analysis of much scientific
                  data. Even findings from the claimed gold standard for
                  examination by the latter, randomized controlled trials, can
                  be problematic.Scientific inference is a far broader concept
                  than statistical inference. Its authority derives from the
                  accumulation, over an extensive period of time, of both
                  theoretical and empirical knowledge that has won the
                  (provisional) acceptance of the scholarly community. A major
                  focus of scientific inference can be viewed as the pursuit of
                  significant sameness, meaning replicable and empirically
                  generalizable results among phenomena. Regrettably, the
                  obsession with users of statistical inference to report
                  significant differences in data sets actively thwarts
                  cumulative knowledge development.The manifold problems
                  surrounding the implementation and usefulness of formal
                  methods of statistical inference in advancing science do not
                  speak well of much teaching in methods/statistics classes.
                  Serious reflection on statistics' role in producing viable
                  knowledge is needed. Commendably, the American Statistical
                  Association is committed to addressing this challenge, as
                  further witnessed in this special online, open access issue of
                  The American Statistician.},
  url          = {https://doi.org/10.1080/00031305.2018.1464947},
  note         = {doi: 10.1080/00031305.2018.1464947}
}

@ARTICLE{Leek2017-de,
  title        = {Is Most Published Research Really False?},
  author       = {Leek, Jeffrey T and Jager, Leah R},
  journaltitle = {Annual Review of Statistics and Its Application},
  publisher    = {Annual Reviews},
  volume       = {4},
  issue        = {1},
  pages        = {109--122},
  date         = {2017-03-07},
  eprint       = {http://dx.doi.org/10.1146/annurev-statistics-060116-054104},
  doi          = {10.1146/annurev-statistics-060116-054104},
  issn         = {2326-8298},
  abstract     = {There has been an increasing concern in both the scientific
                  and lay communities that most published medical findings are
                  false. But what does it mean to be false? Here we describe the
                  range of definitions of false discoveries in the scientific
                  literature. We summarize the philosophical, statistical, and
                  experimental evidence for each type of false discovery. We
                  discuss common underpinning problems with the scientific and
                  data analytic practices and point to tools and behaviors that
                  can be implemented to reduce the problems with published
                  scientific results.},
  url          = {https://doi.org/10.1146/annurev-statistics-060116-054104},
  note         = {doi: 10.1146/annurev-statistics-060116-054104}
}

@ARTICLE{Lenth2001-xy,
  title        = {Some Practical Guidelines for Effective Sample Size
                  Determination},
  author       = {Lenth, Russell V},
  journaltitle = {Am. Stat.},
  publisher    = {Taylor \& Francis},
  volume       = {55},
  issue        = {3},
  pages        = {187--193},
  date         = {2001-08-01},
  doi          = {10.1198/000313001317098149},
  issn         = {0003-1305},
  abstract     = {Sample size determination is often an important step in
                  planning a statistical study?and it is usually a difficult
                  one. Among the important hurdles to be surpassed, one must
                  obtain an estimate of one or more error variances and specify
                  an effect size of importance. There is the temptation to take
                  some shortcuts. This article offers some suggestions for
                  successful and meaningful sample size determination. Also
                  discussed is the possibility that sample size may not be the
                  main issue, that the real goal is to design a high-quality
                  study. Finally, criticism is made of some ill-advised
                  shortcuts relating to power and sample size.},
  url          = {https://doi.org/10.1198/000313001317098149},
  urldate      = {2016-02-25},
  note         = {doi: 10.1198/000313001317098149}
}

@BOOK{McElreath2020-tk,
  title     = {{Statistical Rethinking: A Bayesian Course with Examples in R and
               Stan}},
  author    = {McElreath, Richard},
  publisher = {CRC Press},
  edition   = {2nd},
  date      = {2020}
}

@ARTICLE{Wainer2006-jm,
  title        = {Finding What Is Not There through the Unfortunate Binning of
                  Results: The Mendel Effect},
  author       = {Wainer, Howard and Gessaroli, Marc and Verdi, Monica},
  journaltitle = {Chance},
  publisher    = {Taylor \& Francis},
  volume       = {19},
  issue        = {1},
  pages        = {49--52},
  date         = {2006-01-01},
  doi          = {10.1080/09332480.2006.10722771},
  issn         = {0933-2480},
  url          = {https://doi.org/10.1080/09332480.2006.10722771},
  note         = {doi: 10.1080/09332480.2006.10722771}
}

@ARTICLE{Felsenstein1985-my,
  title        = {Phylogenies and the Comparative Method},
  author       = {Felsenstein, Joseph},
  journaltitle = {Am. Nat.},
  volume       = {125},
  issue        = {1},
  pages        = {1--15},
  date         = {1985},
  eprint       = {http://dx.doi.org/10.1086/284325},
  doi          = {10.1086/284325},
  issn         = {0003-0147},
  abstract     = {Comparative studies of the relationship between two
                  phenotypes, or between a phenotype and an environment, are
                  frequently carried out by invalid statistical methods. Most
                  regression, correlation, and contingency table methods,
                  including nonparametric methods, assume that the points are
                  drawn independently from a common distribution. When species
                  are taken from a branching phylogeny, they are manifestly
                  nonindependent. Use of a statistical method that assumes
                  independence will cause overstatement of the significance in
                  hypothesis tests. Some illustrative examples of these
                  phenomena have been given, and limitations of previous
                  proposals of ways to correct for the nonindependence have been
                  discussed. A method of correcting for the phylogeny has been
                  proposed. It requires that we know both the tree topology and
                  the branch lengths, and that we be willing to allow the
                  characters to be modeled by Brownian motion on a linear scale.
                  Given these conditions, the phylogeny specifies a set of
                  contrasts among species, contrasts that are statistically
                  independent and can be used in regression or correlation
                  studies. The considerable barriers to making practical use of
                  this technique have been discussed.},
  url          = {http://dx.doi.org/10.1086/284325}
}

@ARTICLE{Halliday2018-ca,
  title        = {Letter to the editor},
  author       = {Halliday, Tanya M and Thomas, Diana M and Siu, Cynthia O and
                  Allison, David B},
  journaltitle = {J. Women Aging},
  volume       = {30},
  issue        = {1},
  pages        = {2--5},
  date         = {2018-01},
  doi          = {10.1080/08952841.2017.1407575},
  pmid         = {29220635},
  issn         = {0895-2841,1540-7322},
  url          = {http://dx.doi.org/10.1080/08952841.2017.1407575},
  language     = {en}
}

@ARTICLE{Kruschke2018-mg,
  title        = {Rejecting or Accepting Parameter Values in Bayesian Estimation},
  author       = {Kruschke, John K},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  publisher    = {SAGE Publications Inc},
  volume       = {1},
  issue        = {2},
  pages        = {270--280},
  date         = {2018-05-08},
  doi          = {10.1177/2515245918771304},
  issn         = {2515-2459},
  abstract     = {This article explains a decision rule that uses Bayesian
                  posterior distributions as the basis for accepting or
                  rejecting null values of parameters. This decision rule
                  focuses on the range of plausible values indicated by the
                  highest density interval of the posterior distribution and the
                  relation between this range and a region of practical
                  equivalence (ROPE) around the null value. The article also
                  discusses considerations for setting the limits of a ROPE and
                  emphasizes that analogous considerations apply to setting the
                  decision thresholds for p values and Bayes factors.},
  url          = {https://doi.org/10.1177/2515245918771304},
  note         = {doi: 10.1177/2515245918771304}
}

@ARTICLE{Lango_Allen2010-iu,
  title        = {Hundreds of variants clustered in genomic loci and biological
                  pathways affect human height},
  author       = {Lango Allen, Hana and {many others}},
  journaltitle = {Nature},
  volume       = {467},
  issue        = {7317},
  pages        = {832--838},
  date         = {2010-10-14},
  doi          = {10.1038/nature09410},
  pmc          = {PMC2955183},
  pmid         = {20881960},
  issn         = {0028-0836,1476-4687},
  abstract     = {Most common human traits and diseases have a polygenic pattern
                  of inheritance: DNA sequence variants at many genetic loci
                  influence the phenotype. Genome-wide association (GWA) studies
                  have identified more than 600 variants associated with human
                  traits, but these typically explain small fractions of
                  phenotypic variation, raising questions about the use of
                  further studies. Here, using 183,727 individuals, we show that
                  hundreds of genetic variants, in at least 180 loci, influence
                  adult height, a highly heritable and classic polygenic trait.
                  The large number of loci reveals patterns with important
                  implications for genetic studies of common human diseases and
                  traits. First, the 180 loci are not random, but instead are
                  enriched for genes that are connected in biological pathways
                  (P = 0.016) and that underlie skeletal growth defects (P <
                  0.001). Second, the likely causal gene is often located near
                  the most strongly associated variant: in 13 of 21 loci
                  containing a known skeletal growth gene, that gene was closest
                  to the associated variant. Third, at least 19 loci have
                  multiple independently associated variants, suggesting that
                  allelic heterogeneity is a frequent feature of polygenic
                  traits, that comprehensive explorations of already-discovered
                  loci should discover additional variants and that an
                  appreciable fraction of associated loci may have been
                  identified. Fourth, associated variants are enriched for
                  likely functional effects on genes, being over-represented
                  among variants that alter amino-acid structure of proteins and
                  expression levels of nearby genes. Our data explain
                  approximately 10\% of the phenotypic variation in height, and
                  we estimate that unidentified common variants of similar
                  effect sizes would increase this figure to approximately 16\%
                  of phenotypic variation (approximately 20\% of heritable
                  variation). Although additional approaches are needed to
                  dissect the genetic architecture of polygenic human traits
                  fully, our findings indicate that GWA studies can identify
                  large numbers of loci that implicate biologically relevant
                  genes and pathways.},
  url          = {http://dx.doi.org/10.1038/nature09410},
  language     = {en}
}

@BOOK{Bolker2007-rm,
  title     = {Ecological Models and Data in {R}},
  author    = {Bolker, Benjamin M},
  publisher = {Princeton University Press},
  date      = {2007},
  pagetotal = {516}
}

@BOOK{Buffalo2015-ah,
  title     = {Bioinformatics Data Skills},
  author    = {Buffalo, Vincent},
  publisher = {O'Reilly Media, Inc.},
  date      = {2015}
}

@ARTICLE{Welsh1988-fh,
  title        = {The Fallacy of Averages},
  author       = {Welsh, A H and Peterson, A Townsend and Altmann, Stuart A},
  journaltitle = {Am. Nat.},
  volume       = {132},
  issue        = {2},
  pages        = {277--288},
  date         = {1988},
  eprint       = {http://dx.doi.org/10.1086/284850},
  doi          = {10.1086/284850},
  issn         = {0003-0147},
  abstract     = {In the biological literature, the mean of the product of two
                  or more random variables is frequently calculated from the
                  product of their means. However, unless the variables are
                  independent, an exceptional occurrence in biological systems,
                  the two are not equivalent. Corresponding false assumptions
                  commonly are made about ratios of means and various other
                  functions of means. These assumptions are examples of perhaps
                  the most common statistical fallacy in the biological
                  literature, the fallacy of averages: the false assumption that
                  the mean of a nonlinear function of several variables equals
                  the function of the means of those variables. We provide the
                  relationship between functions of means and means of functions
                  for common functions of one variable (linear, reciprocal, and
                  exponential functions), for two or more variables (product,
                  ratio, sum), and for the product of allometric relationships.},
  url          = {http://dx.doi.org/10.1086/284850}
}

@ARTICLE{Groenen2016-qm,
  title        = {Multinomial Multiple Correspondence Analysis},
  author       = {Groenen, Patrick J F and Josse, Julie},
  journaltitle = {arXiv [stat.ME]},
  date         = {2016-03-10},
  eprint       = {1603.03174},
  eprinttype   = {arXiv},
  eprintclass  = {stat.ME},
  abstract     = {Relations between categorical variables can be analyzed
                  conveniently by multiple correspondence analysis (MCA). \%It
                  is well suited to discover relations that may exist between
                  categories of different variables. The graphical
                  representation of MCA results in so-called biplots makes it
                  easy to interpret the most important associations. However, a
                  major drawback of MCA is that it does not have an underlying
                  probability model for an individual selecting a category on a
                  variable. In this paper, we propose such probability model
                  called multinomial multiple correspondence analysis (MMCA)
                  that combines the underlying low-rank representation of MCA
                  with maximum likelihood. An efficient majorization algorithm
                  that uses an elegant bound for the second derivative is
                  derived to estimate the parameters. The proposed model can
                  easily lead to overfitting causing some of the parameters to
                  wander of to infinity. We add the nuclear norm penalty to
                  counter this issue and discuss ways of selecting
                  regularization parameters. The proposed approach is well
                  suited to study and vizualise the dependences for high
                  dimensional data.},
  url          = {http://arxiv.org/abs/1603.03174},
  urldate      = {2017-01-06}
}

@ARTICLE{Audigier2016-ck,
  title        = {A principal component method to impute missing values for
                  mixed data},
  author       = {Audigier, Vincent and Husson, François and Josse, Julie},
  journaltitle = {Adv. Data Anal. Classif.},
  publisher    = {Springer Berlin Heidelberg},
  volume       = {10},
  issue        = {1},
  pages        = {5--26},
  date         = {2016-03-01},
  doi          = {10.1007/s11634-014-0195-1},
  issn         = {1862-5347,1862-5355},
  abstract     = {We propose a new method to impute missing values in mixed data
                  sets. It is based on a principal component method, the
                  factorial analysis for mixed data, which balances the
                  influence of all the variables that are continuous and
                  categorical in the construction of the principal components.
                  Because the imputation uses the principal axes and components,
                  the prediction of the missing values is based on the
                  similarity between individuals and on the relationships
                  between variables. The properties of the method are
                  illustrated via simulations and the quality of the imputation
                  is assessed using real data sets. The method is compared to a
                  recent method (Stekhoven and Buhlmann Bioinformatics
                  28:113–118, 2011) based on random forest and shows better
                  performance especially for the imputation of categorical
                  variables and situations with highly linear relationships
                  between continuous variables.},
  url          = {https://link.springer.com/article/10.1007/s11634-014-0195-1},
  urldate      = {2017-02-27},
  language     = {en}
}

@ARTICLE{Barba2016-fu,
  title        = {The hard road to reproducibility},
  author       = {Barba, Lorena A},
  journaltitle = {Science},
  volume       = {354},
  issue        = {6308},
  pages        = {142},
  date         = {2016-10-07},
  doi          = {10.1126/science.354.6308.142},
  pmid         = {27846503},
  issn         = {0036-8075,1095-9203},
  abstract     = {Early in my Ph.D. studies, my supervisor assigned me the task
                  of running computer code written by a previous student who was
                  graduated and gone. It was hell. I had to sort through many
                  different versions of the code, saved in folders with a
                  mysterious numbering scheme. There was no documentation and},
  url          = {http://dx.doi.org/10.1126/science.354.6308.142},
  urldate      = {2016-11-19},
  language     = {en}
}

@ARTICLE{Roff2002-rf,
  title        = {Comparing {G} Matrices: A Manova Approach},
  shorttitle   = {Comparing G Matrices},
  author       = {Roff, Derek A},
  journaltitle = {Evolution},
  volume       = {56},
  issue        = {6},
  pages        = {1286--1291},
  date         = {2002},
  issn         = {0014-3820},
  abstract     = {There is considerable interest in comparing genetic
                  variance-covariances matrices (G matrix). However, present
                  methods are difficult to implement and cannot readily be
                  extended to incorporate effects of other variables such as
                  habitat, sex, or location. In this paper I present a method
                  based on MANOVA that can be done using only standard
                  statistical packages (coding for the method using SPLUS is
                  available from the author). The crux of the approach is to use
                  the jackknife method to estimate the pseudovalues of the
                  estimates; these estimates can then be used as datapoints in a
                  MANOVA. I illustrate the method using two published datasets:
                  (1) variation in G matrices resulting from differences in
                  rearing condition, species, and sex in the crickets Gryllus
                  firmus and G. pennsylvanicus', and (2) variation in G matrices
                  associated with habitat and history in the amphipod Gammarus
                  minus.},
  url          = {http://www.jstor.org/stable/3061691},
  urldate      = {2016-06-15}
}

@ARTICLE{Kass2016-ha,
  title        = {Ten Simple Rules for Effective Statistical Practice},
  author       = {Kass, Robert E and Caffo, Brian S and Davidian, Marie and
                  Meng, Xiao-Li and Yu, Bin and Reid, Nancy},
  journaltitle = {PLoS Comput. Biol.},
  volume       = {12},
  issue        = {6},
  pages        = {e1004961},
  date         = {2016-06},
  doi          = {10.1371/journal.pcbi.1004961},
  pmc          = {PMC4900655},
  pmid         = {27281180},
  issn         = {1553-734X,1553-7358},
  url          = {http://dx.doi.org/10.1371/journal.pcbi.1004961},
  urldate      = {2016-06-11},
  language     = {en}
}

@ARTICLE{Colegrave2003-eb,
  title        = {Confidence intervals are a more useful complement to
                  nonsignificant tests than are power calculations},
  author       = {Colegrave, Nick and Ruxton, Graeme D},
  journaltitle = {Behav. Ecol.},
  volume       = {14},
  issue        = {3},
  pages        = {446--447},
  date         = {2003},
  issn         = {1045-2249},
  url          = {https://beheco.oxfordjournals.org/content/14/3/446.full},
  urldate      = {2016-05-18}
}

@INBOOK{Orbanz2011-bv,
  title     = {Bayesian nonparametric models},
  author    = {Orbanz, Peter and Teh, Yee Whye},
  booktitle = {Encyclopedia of Machine Learning},
  publisher = {Springer},
  pages     = {81--89},
  date      = {2011},
  url       = {http://link.springer.com/10.1007/978-0-387-30164-8_66},
  urldate   = {2016-05-18}
}

@ARTICLE{Ebden2015-cl,
  title        = {Gaussian Processes: A Quick Introduction},
  shorttitle   = {Gaussian Processes},
  author       = {Ebden, Mark},
  journaltitle = {arXiv:1505.02965 [math, stat]},
  date         = {2015-05-12},
  abstract     = {A gentle introduction to Gaussian processes (GPs). The three
                  parts of the document consider GPs for regression,
                  classification, and dimensionality reduction.},
  url          = {http://arxiv.org/abs/1505.02965},
  urldate      = {2016-05-18},
  note         = {Comment: 13 pages: 6 for regression, 5 for classification, 2
                  for dimensionality reduction}
}

@ARTICLE{Eddy2004-jd,
  title        = {What is Bayesian statistics?},
  author       = {Eddy, Sean R},
  journaltitle = {Nat. Biotechnol.},
  volume       = {22},
  issue        = {9},
  pages        = {1177--1178},
  date         = {2004-09},
  doi          = {10.1038/nbt0904-1177},
  pmid         = {15340486},
  issn         = {1087-0156},
  abstract     = {There seem to be a lot of computational biology papers with
                  'Bayesian' in their titles these days. What's distinctive
                  about 'Bayesian' methods?},
  url          = {http://dx.doi.org/10.1038/nbt0904-1177},
  urldate      = {2016-05-14},
  language     = {en}
}

@ARTICLE{Symonds2002-qm,
  title        = {The Effects of Topological Inaccuracy in Evolutionary Trees on
                  the Phylogenetic Comparative Method of Independent Contrasts},
  author       = {Symonds, Matthew R E},
  journaltitle = {Syst. Biol.},
  volume       = {51},
  issue        = {4},
  pages        = {541--553},
  date         = {2002-07-01},
  doi          = {10.1080/10635150290069977},
  pmid         = {12227998},
  issn         = {1063-5157,1076-836X},
  url          = {http://sysbio.oxfordjournals.org/content/51/4/541},
  urldate      = {2016-05-02},
  language     = {en}
}

@ARTICLE{Beaulieu2013-am,
  title        = {Identifying Hidden Rate Changes in the Evolution of a Binary
                  Morphological Character: The Evolution of Plant Habit in
                  Campanulid Angiosperms},
  shorttitle   = {Identifying Hidden Rate Changes in the Evolution of a Binary
                  Morphological Character},
  author       = {Beaulieu, Jeremy M and O'Meara, Brian C and Donoghue, Michael
                  J},
  journaltitle = {Syst. Biol.},
  volume       = {62},
  issue        = {5},
  pages        = {725--737},
  date         = {2013-09-01},
  doi          = {10.1093/sysbio/syt034},
  pmid         = {23676760},
  issn         = {1063-5157,1076-836X},
  abstract     = {The growth of phylogenetic trees in scope and in size is
                  promising from the standpoint of understanding a wide variety
                  of evolutionary patterns and processes. With trees comprised
                  of larger, older, and globally distributed clades, it is
                  likely that the lability of a binary character will differ
                  significantly among lineages, which could lead to errors in
                  estimating transition rates and the associated inference of
                  ancestral states. Here we develop and implement a new method
                  for identifying different rates of evolution in a binary
                  character along different branches of a phylogeny. We
                  illustrate this approach by exploring the evolution of growth
                  habit in Campanulidae, a flowering plant clade containing some
                  35,000 species. The distribution of woody versus herbaceous
                  species calls into question the use of traditional models of
                  binary character evolution. The recognition and accommodation
                  of changes in the rate of growth form evolution in different
                  lineages demonstrates, for the first time, a robust picture of
                  growth form evolution across a very large, very old, and very
                  widespread flowering plant clade. [Binary character;
                  Campanulidae; comparative methods; flowering plants; growth
                  habit; herbaceous; Hidden rates model; woody.]},
  url          = {http://sysbio.oxfordjournals.org/content/62/5/725},
  urldate      = {2016-05-01},
  language     = {en}
}

@ARTICLE{Clavel2015-gu,
  title        = {{mvMORPH}: an {R} package for fitting multivariate
                  evolutionary models to morphometric data},
  shorttitle   = {mv <span style="font-variant},
  author       = {Clavel, Julien and Escarguel, Gilles and Merceron, Gildas},
  editor       = {Poisot, Timothée},
  journaltitle = {Methods Ecol. Evol.},
  volume       = {6},
  issue        = {11},
  pages        = {1311--1319},
  date         = {2015},
  doi          = {10.1111/2041-210X.12420},
  issn         = {2041-210X},
  url          = {http://doi.wiley.com/10.1111/2041-210X.12420},
  urldate      = {2016-05-01},
  language     = {en}
}

@ARTICLE{Boettiger2012-mb,
  title        = {Is Your Phylogeny Informative? Measuring the Power of
                  Comparative Methods},
  shorttitle   = {Is Your Phylogeny Informative?},
  author       = {Boettiger, Carl and Coop, Graham and Ralph, Peter},
  journaltitle = {Evolution},
  volume       = {66},
  issue        = {7},
  pages        = {2240--2251},
  date         = {2012-07-01},
  doi          = {10.1111/j.1558-5646.2011.01574.x},
  issn         = {0014-3820,1558-5646},
  abstract     = {Phylogenetic comparative methods may fail to produce
                  meaningful results when either the underlying model is
                  inappropriate or the data contain insufficient information to
                  inform the inference. The ability to measure the statistical
                  power of these methods has become crucial to ensure that data
                  quantity keeps pace with growing model complexity. Through
                  simulations, we show that commonly applied model choice
                  methods based on information criteria can have remarkably high
                  error rates; this can be a problem because methods to estimate
                  the uncertainty or power are not widely known or applied.
                  Furthermore, the power of comparative methods can depend
                  significantly on the structure of the data. We describe a
                  Monte Carlo-based method which addresses both of these
                  challenges, and show how this approach both quantifies and
                  substantially reduces errors relative to information criteria.
                  The method also produces meaningful confidence intervals for
                  model parameters. We illustrate how the power to distinguish
                  different models, such as varying levels of selection, varies
                  both with number of taxa and structure of the phylogeny. We
                  provide an open-source implementation in the pmc
                  (“Phylogenetic Monte Carlo”) package for the R programming
                  language. We hope such power analysis becomes a routine part
                  of model comparison in comparative methods.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/j.1558-5646.2011.01574.x/abstract},
  urldate      = {2016-04-27},
  language     = {en}
}

@ARTICLE{Haber2016-ab,
  title        = {Phenotypic Covariation and Morphological Diversification in
                  the Ruminant Skull},
  author       = {Haber, Annat},
  journaltitle = {Am. Nat.},
  volume       = {187},
  issue        = {5},
  pages        = {576--591},
  date         = {2016-03-30},
  doi          = {10.1086/685811},
  issn         = {0003-0147},
  abstract     = {Differences among clades in their diversification patterns
                  result from a combination of extrinsic and intrinsic factors.
                  In this study, I examined the role of intrinsic factors in the
                  morphological diversification of ruminants, in general, and in
                  the differences between bovids and cervids, in particular.
                  Using skull morphology, which embodies many of the adaptations
                  that distinguish bovids and cervids, I examined 132 of the 200
                  extant ruminant species. As a proxy for intrinsic constraints,
                  I quantified different aspects of the phenotypic covariation
                  structure within species and compared them with the
                  among-species divergence patterns, using phylogenetic
                  comparative methods. My results show that for most species,
                  divergence is well aligned with their phenotypic covariance
                  matrix and that those that are better aligned have diverged
                  further away from their ancestor. Bovids have dispersed into a
                  wider range of directions in morphospace than cervids, and
                  their overall disparity is higher. This difference is best
                  explained by the lower eccentricity of bovids’ within-species
                  covariance matrices. These results are consistent with the
                  role of intrinsic constraints in determining amount, range,
                  and direction of dispersion and demonstrate that intrinsic
                  constraints can influence macroevolutionary patterns even as
                  the covariance structure evolves.},
  url          = {http://www.journals.uchicago.edu/doi/abs/10.1086/685811},
  urldate      = {2016-04-25}
}

@ARTICLE{Lynch1991-wo,
  title        = {Methods for the Analysis of Comparative Data in Evolutionary
                  Biology},
  author       = {Lynch, Michael},
  journaltitle = {Evolution},
  volume       = {45},
  issue        = {5},
  pages        = {1065--1080},
  date         = {1991},
  issn         = {0014-3820},
  abstract     = {Inferences regarding phylogenetic patterns and constraints on
                  the evolution of characters often can be derived only from
                  comparisons of extant species. If the phylogeny of these
                  species is known, then the mean phenotypes of taxa can be
                  partitioned into heritable phylogenetic effects and
                  nonheritable residual components. Methods are presented for
                  the estimation of phylogeny-wide means of characters, the
                  variance-covariance structure of the components of
                  taxon-specific means, and the mean phenotypes of ancestral
                  taxa. These methods, which are largely an extension of
                  maximum-likelihood techniques used in quantitative genetics,
                  make an efficient use of the data, are unbiased by
                  phylogenetically uninformative contributions to mean
                  phenotypes, and take into account fully the nonindependence of
                  data resulting from evolutionary relationships. Statistical
                  tests are introduced for evaluating the significance of
                  phylogenetic heritability and of correlations between traits,
                  and expressions are given for the standard errors of ancestral
                  mean phenotype estimates. It is argued that the covariance
                  structure of phylogenetic effects provides a description of a
                  macroevolutionary pattern, whereas that for the residual
                  effects, when corrected for sampling error, is more closely
                  related to a microevolutionary pattern.},
  url          = {http://www.jstor.org/stable/2409716},
  urldate      = {2016-04-22}
}

@ARTICLE{Dembo2015-ax,
  title        = {Bayesian analysis of a morphological supermatrix sheds light
                  on controversial fossil hominin relationships},
  author       = {Dembo, Mana and Matzke, Nicholas J and Mooers, Arne Ø and
                  Collard, Mark},
  journaltitle = {Proc. R. Soc. B},
  volume       = {282},
  issue        = {1812},
  pages        = {20150943},
  date         = {2015-08-07},
  doi          = {10.1098/rspb.2015.0943},
  issn         = {0962-8452,1471-2954},
  abstract     = {The phylogenetic relationships of several hominin species
                  remain controversial. Two methodological issues contribute to
                  the uncertainty—use of partial, inconsistent datasets and
                  reliance on phylogenetic methods that are ill-suited to
                  testing competing hypotheses. Here, we report a study designed
                  to overcome these issues. We first compiled a supermatrix of
                  craniodental characters for all widely accepted hominin
                  species. We then took advantage of recently developed Bayesian
                  methods for building trees of serially sampled tips to test
                  among hypotheses that have been put forward in three of the
                  most important current debates in hominin phylogenetics—the
                  relationship between Australopithecus sediba and Homo, the
                  taxonomic status of the Dmanisi hominins, and the place of the
                  so-called hobbit fossils from Flores, Indonesia, in the
                  hominin tree. Based on our results, several published
                  hypotheses can be statistically rejected. For example, the
                  data do not support the claim that Dmanisi hominins and all
                  other early Homo specimens represent a single species, nor
                  that the hobbit fossils are the remains of small-bodied modern
                  humans, one of whom had Down syndrome. More broadly, our study
                  provides a new baseline dataset for future work on hominin
                  phylogeny and illustrates the promise of Bayesian approaches
                  for understanding hominin phylogenetic relationships.},
  url          = {http://rspb.royalsocietypublishing.org/content/282/1812/20150943},
  urldate      = {2016-04-21},
  language     = {en}
}

@ARTICLE{Ho2014-yr,
  title        = {Intrinsic inference difficulties for trait evolution with
                  Ornstein-Uhlenbeck models},
  author       = {Ho, Lam Si Tung and Ané, Cécile},
  journaltitle = {Methods Ecol. Evol.},
  volume       = {5},
  issue        = {11},
  pages        = {1133--1146},
  date         = {2014-11-01},
  doi          = {10.1111/2041-210X.12285},
  issn         = {2041-210X},
  abstract     = {* For the study of macroevolution, phenotypic data are
                  analysed across species on a dated phylogeny using
                  phylogenetic comparative methods. In this context, the
                  Ornstein-Uhlenbeck (OU) process is now being used extensively
                  to model selectively driven trait evolution, whereby a trait
                  is attracted to a selection optimum μ. * We report here
                  theoretical properties of the maximum-likelihood (ML)
                  estimators for these parameters, including their
                  non-uniqueness and inaccuracy, and show that theoretical
                  expectations indeed apply to real trees. We provide necessary
                  conditions for ML estimators to be well defined and practical
                  implications for model parametrization. * We then show how
                  these limitations carry over to difficulties in detecting
                  shifts in selection regimes along a phylogeny. When the
                  phylogenetic placement of these shifts is unknown, we identify
                  a ‘large p - small n’ problem where traditional model
                  selection criteria fail and favour overly complex scenarios.
                  Instead, we propose a modified criterion that is better
                  adapted to change-point models. * The challenges we identify
                  here are inherent to trait evolution models on phylogenetic
                  trees when observations are limited to present-day taxa, and
                  require the addition of fossil taxa to be alleviated. We
                  conclude with recommendations for empiricists.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12285/abstract},
  urldate      = {2016-04-21},
  language     = {en}
}

@ARTICLE{Ionan2014-pr,
  title        = {Comparison of confidence interval methods for an intra-class
                  correlation coefficient ({ICC})},
  author       = {Ionan, Alexei C and Polley, Mei-Yin C and McShane, Lisa M and
                  Dobbin, Kevin K},
  journaltitle = {BMC Med. Res. Methodol.},
  volume       = {14},
  date         = {2014-11-22},
  doi          = {10.1186/1471-2288-14-121},
  pmc          = {PMC4258044},
  issn         = {1471-2288},
  abstract     = {Background The intraclass correlation coefficient (ICC) is
                  widely used in biomedical research to assess the
                  reproducibility of measurements between raters, labs,
                  technicians, or devices. For example, in an inter-rater
                  reliability study, a high ICC value means that noise
                  variability (between-raters and within-raters) is small
                  relative to variability from patient to patient. A confidence
                  interval or Bayesian credible interval for the ICC is a
                  commonly reported summary. Such intervals can be constructed
                  employing either frequentist or Bayesian methodologies.
                  Methods This study examines the performance of three different
                  methods for constructing an interval in a two-way, crossed,
                  random effects model without interaction: the Generalized
                  Confidence Interval method (GCI), the Modified Large Sample
                  method (MLS), and a Bayesian method based on a noninformative
                  prior distribution (NIB). Guidance is provided on interval
                  construction method selection based on study design, sample
                  size, and normality of the data. We compare the coverage
                  probabilities and widths of the different interval methods.
                  Results We show that, for the two-way, crossed, random effects
                  model without interaction, care is needed in interval method
                  selection because the interval estimates do not always have
                  properties that the user expects. While different methods
                  generally perform well when there are a large number of levels
                  of each factor, large differences between the methods emerge
                  when the number of one or more factors is limited. In
                  addition, all methods are shown to lack robustness to certain
                  hard-to-detect violations of normality when the sample size is
                  limited. Conclusions Decision rules and software programs for
                  interval construction are provided for practical
                  implementation in the two-way, crossed, random effects model
                  without interaction. All interval methods perform similarly
                  when the data are normal and there are sufficient numbers of
                  levels of each factor. The MLS and GCI methods outperform the
                  NIB when one of the factors has a limited number of levels and
                  the data are normally distributed or nearly normally
                  distributed. None of the methods work well if the number of
                  levels of a factor are limited and data are markedly
                  non-normal. The software programs are implemented in the
                  popular R language. Electronic supplementary material The
                  online version of this article (doi:10.1186/1471-2288-14-121)
                  contains supplementary material, which is available to
                  authorized users.},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4258044/},
  urldate      = {2016-04-14}
}

@ARTICLE{Rice2010-vr,
  title        = {A Decision-Theoretic Formulation of Fisher’s Approach to
                  Testing},
  author       = {Rice, Kenneth},
  journaltitle = {Am. Stat.},
  volume       = {64},
  issue        = {4},
  pages        = {345--349},
  date         = {2010-11-01},
  doi          = {10.1198/tast.2010.09060},
  issn         = {0003-1305},
  abstract     = {In Fisher’s interpretation of statistical testing, a test is
                  seen as a ‘screening’ procedure; one either reports some
                  scientific findings, or alternatively gives no firm
                  conclusions. These choices differ fundamentally from
                  hypothesis testing, in the style of Neyman and Pearson, which
                  does not consider a noncommittal response; tests are developed
                  as choices between two complementary hypotheses, typically
                  labeled ‘null’ and ‘alternative.’ The same choices are
                  presented in typical Bayesian tests, where Bayes Factors are
                  used to judge the relative support for a null or alternative
                  model. In this article, we use decision theory to show that
                  Bayesian tests can also describe Fisher-style ‘screening’
                  procedures, and that such approaches lead directly to Bayesian
                  analogs of the Wald test and two-sided p-value, and to
                  Bayesian tests with frequentist properties that can be
                  determined easily and accurately. In contrast to hypothesis
                  testing, these ‘screening’ decisions do not exhibit the
                  Lindley/Jeffreys paradox, that divides frequentists and
                  Bayesians.},
  url          = {http://dx.doi.org/10.1198/tast.2010.09060},
  urldate      = {2016-04-12}
}

@ARTICLE{Stodden2015-ze,
  title        = {Reproducing Statistical Results},
  author       = {Stodden, Victoria},
  journaltitle = {Annual Review of Statistics and Its Application},
  volume       = {2},
  issue        = {1},
  pages        = {1--19},
  date         = {2015},
  doi          = {10.1146/annurev-statistics-010814-020127},
  abstract     = {The reproducibility of statistical findings has become a
                  concern not only for statisticians, but for all researchers
                  engaged in empirical discovery. Section 2 of this article
                  identifies key reasons statistical findings may not replicate,
                  including power and sampling issues; misapplication of
                  statistical tests; the instability of findings under
                  reasonable perturbations of data or models; lack of access to
                  methods, data, or equipment; and cultural barriers such as
                  researcher incentives and rewards. Section 3 discusses five
                  proposed remedies for these replication failures: improved
                  prepublication and postpublication validation of findings; the
                  complete disclosure of research steps; assessment of the
                  stability of statistical findings; providing access to digital
                  research objects, in particular data and software; and
                  ensuring these objects are legally reusable.},
  url          = {http://dx.doi.org/10.1146/annurev-statistics-010814-020127},
  urldate      = {2016-04-01}
}

@DATASET{Morris2016-cd,
  title    = {Data from: Sexual selection on skeletal shape in Carnivora},
  author   = {Morris, Jeremy S and Carrier, David R},
  date     = {2016-03-10},
  doi      = {10.5061/dryad.86523},
  abstract = {Lifetime reproductive success of males is often dependent upon the
              ability to physically compete for mates. However, species
              variation in social structure leads to differences in the relative
              importance of intraspecific aggression. Here we present a large
              comparative data set on sexual dimorphism in skeletal shape in
              Carnivora to test the hypotheses that carnivorans exhibit sexual
              dimorphism in skeletal anatomy that is reflective of greater
              specialization for physical aggression in males relative to
              females and that this dimorphism is associated with the intensity
              of sexual selection. We tested these hypotheses using a set of
              functional indices predicted to improve aggressive performance.
              Our results indicate that skeletal shape dimorphism is widespread
              within our sample. Functional traits thought to enhance aggressive
              performance are more pronounced in males. Phylogenetic model
              selection suggests that the evolution of this dimorphism is driven
              by sexual selection, with the best-fitting model indicating
              greater dimorphism in polygynous versus non-polygynous species.
              Skeletal shape dimorphism is correlated with body size dimorphism,
              a common indicator of the intensity of male-male competition, but
              not with mean body size. These results represent the first
              evidence of sexual dimorphism in the primary locomotor system of a
              large sample of mammals.},
  url      = {http://datadryad.org/resource/doi:10.5061/dryad.86523},
  urldate  = {2016-03-30}
}

@ARTICLE{Morris2016-pb,
  title        = {Sexual selection on skeletal shape in Carnivora},
  author       = {Morris, Jeremy S and Carrier, David R},
  journaltitle = {Evolution},
  date         = {2016-03-01},
  doi          = {10.1111/evo.12904},
  issn         = {0014-3820,1558-5646},
  abstract     = {Lifetime reproductive success of males is often dependent upon
                  the ability to physically compete for mates. However, species
                  variation in social structure leads to differences in the
                  relative importance of intraspecific aggression. Here, we
                  present a large comparative dataset on sexual dimorphism in
                  skeletal shape in Carnivora to test the hypotheses that
                  carnivorans exhibit sexual dimorphism in skeletal anatomy that
                  is reflective of greater specialization for physical
                  aggression in males relative to females and that this
                  dimorphism is associated with the intensity of sexual
                  selection. We tested these hypotheses using a set of
                  functional indices predicted to improve aggressive
                  performance. Our results indicate that skeletal shape
                  dimorphism is widespread within our sample. Functional traits
                  thought to enhance aggressive performance are more pronounced
                  in males. Phylogenetic model selection suggests that the
                  evolution of this dimorphism is driven by sexual selection,
                  with the best-fitting model indicating greater dimorphism in
                  polygynous versus nonpolygynous species. Skeletal shape
                  dimorphism is correlated with body size dimorphism, a common
                  indicator of the intensity of male–male competition, but not
                  with mean body size. These results represent the first
                  evidence of sexual dimorphism in the primary locomotor system
                  of a large sample of mammals.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/evo.12904/abstract},
  urldate      = {2016-03-30},
  language     = {en}
}

@DATASET{Linde-Medina2016-vx,
  title    = {Data from: Are more diverse parts of the mammalian skull more
              labile?},
  author   = {Linde-Medina, Marta and Boughner, Julia C and Santana, Sharlene E
              and Diogo, Rui},
  date     = {2016-03-04},
  doi      = {10.5061/dryad.rd25r},
  abstract = {Morphological variation is unevenly distributed within the
              mammalian skull; some of its parts have diversified more than
              others. It is commonly thought that this pattern of variation is
              mainly the result of the structural organization of the skull, as
              defined by the pattern and magnitude of trait covariation.
              Patterns of trait covariation can facilitate morphological
              diversification if they are aligned in the direction of selection,
              or these patterns can constrain diversification if oriented in a
              different direction. Within this theoretical framework, it is
              thought that more variable parts possess patterns of trait
              covariation that made them more capable of evolutionary change,
              that is, are more labile. However, differences in the degree of
              morphological variation among skull traits could arise despite
              variation in trait lability if, for example, some traits have
              evolved at a different rate and/or undergone stabilizing
              selection. Here, we test these hypotheses in the mammalian skull
              using 2D geometric morphometrics to quantify skull shape and
              estimating constraint, rates of evolution, and lability. Contrary
              to the expectations, more variable parts of the skull across
              mammalian species are less capable of evolutionary change than are
              less variable skull parts. Our results suggest that patterns of
              morphological variation in the skull could result from differences
              in rate of evolution and stabilizing selection.},
  url      = {http://datadryad.org/resource/doi:10.5061/dryad.rd25r},
  urldate  = {2017-02-01}
}

@ARTICLE{Linde-Medina2016-zy,
  title        = {Are more diverse parts of the mammalian skull more labile?},
  author       = {Linde-Medina, Marta and Boughner, Julia C and Santana,
                  Sharlene E and Diogo, Rui},
  journaltitle = {Ecol. Evol.},
  volume       = {6},
  issue        = {8},
  pages        = {2318--2324},
  date         = {2016-04},
  doi          = {10.1002/ece3.2046},
  pmc          = {PMC4782257},
  pmid         = {27069580},
  issn         = {2045-7758},
  abstract     = {Morphological variation is unevenly distributed within the
                  mammalian skull; some of its parts have diversified more than
                  others. It is commonly thought that this pattern of variation
                  is mainly the result of the structural organization of the
                  skull, as defined by the pattern and magnitude of trait
                  covariation. Patterns of trait covariation can facilitate
                  morphological diversification if they are aligned in the
                  direction of selection, or these patterns can constrain
                  diversification if oriented in a different direction. Within
                  this theoretical framework, it is thought that more variable
                  parts possess patterns of trait covariation that made them
                  more capable of evolutionary change, that is, are more labile.
                  However, differences in the degree of morphological variation
                  among skull traits could arise despite variation in trait
                  lability if, for example, some traits have evolved at a
                  different rate and/or undergone stabilizing selection. Here,
                  we test these hypotheses in the mammalian skull using 2D
                  geometric morphometrics to quantify skull shape and estimating
                  constraint, rates of evolution, and lability. Contrary to the
                  expectations, more variable parts of the skull across
                  mammalian species are less capable of evolutionary change than
                  are less variable skull parts. Our results suggest that
                  patterns of morphological variation in the skull could result
                  from differences in rate of evolution and stabilizing
                  selection.},
  url          = {http://dx.doi.org/10.1002/ece3.2046},
  urldate      = {2016-03-30},
  keywords     = {Evolutionary rate; Ornstein–Uhlenbeck model; Pagel's delta;
                  geometric morphometrics},
  language     = {en}
}

@DATASET{Williams2016-wh,
  title    = {Data from: Combining statistical inference and decisions in
              ecology},
  author   = {Williams, Perry J and Hooten, Mevin B},
  date     = {2016-09-02},
  doi      = {10.5061/dryad.75756},
  abstract = {Statistical decision theory (SDT) is a sub-field of decision
              theory that formally incorporates statistical investigation into a
              decision-theoretic framework to account for uncertainties in a
              decision problem. SDT provides a unifying analysis of three types
              of information: statistical results from a data set, knowledge of
              the consequences of potential choices (i.e., loss), and prior
              beliefs about a system. SDT links the theoretical development of a
              large body of statistical methods including point estimation,
              hypothesis testing, and confidence interval estimation. The theory
              and application of SDT have mainly been developed and published in
              the fields of mathematics, statistics, operations research, and
              other decision sciences, but have had limited exposure in ecology.
              Thus, we provide an introduction to SDT for ecologists and
              describe its utility for linking the conventionally separate tasks
              of statistical investigation and decision making in a single
              framework. We describe the basic framework of both Bayesian and
              frequentist SDT, its traditional use in statistics, and discuss
              its application to decision problems that occur in ecology. We
              demonstrate SDT with two types of decisions: Bayesian point
              estimation, and an applied management problem of selecting a
              prescribed fire rotation for managing a grassland bird species.
              Central to SDT, and decision theory in general, are loss
              functions. Thus, we also provide basic guidance and references for
              constructing loss functions for an SDT problem.},
  url      = {http://datadryad.org/resource/doi:10.5061/dryad.75756},
  urldate  = {2016-03-30}
}

@ARTICLE{Williams2016-vu,
  title        = {Combining Statistical Inference and Decisions in Ecology},
  author       = {Williams, Perry J and Hooten, Mevin B},
  journaltitle = {Ecol. Appl.},
  date         = {2016-03-01},
  doi          = {10.1890/15-1593.1},
  issn         = {1051-0761,1939-5582},
  abstract     = {Statistical decision theory (SDT) is a sub-field of decision
                  theory that formally incorporates statistical investigation
                  into a decision-theoretic framework to account for
                  uncertainties in a decision problem. SDT provides a unifying
                  analysis of three types of information: statistical results
                  from a data set, knowledge of the consequences of potential
                  choices (i.e., loss), and prior beliefs about a system. SDT
                  links the theoretical development of a large body of
                  statistical methods including point estimation, hypothesis
                  testing, and confidence interval estimation. The theory and
                  application of SDT have mainly been developed and published in
                  the fields of mathematics, statistics, operations research,
                  and other decision sciences, but have had limited exposure in
                  ecology. Thus, we provide an introduction to SDT for
                  ecologists and describe its utility for linking the
                  conventionally separate tasks of statistical investigation and
                  decision making in a single framework. We describe the basic
                  framework of both Bayesian and frequentist SDT, its
                  traditional use in statistics, and discuss its application to
                  decision problems that occur in ecology. We demonstrate SDT
                  with two types of decisions: Bayesian point estimation, and an
                  applied management problem of selecting a prescribed fire
                  rotation for managing a grassland bird species. Central to
                  SDT, and decision theory in general, are loss functions. Thus,
                  we also provide basic guidance and references for constructing
                  loss functions for an SDT problem. This article is protected
                  by copyright. All rights reserved.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1890/15-1593.1/abstract},
  urldate      = {2016-03-30},
  language     = {en}
}

@ARTICLE{Still2004-de,
  title        = {How many clusters? An information-theoretic perspective},
  shorttitle   = {How many clusters?},
  author       = {Still, Susanne and Bialek, William},
  journaltitle = {Neural Comput.},
  volume       = {16},
  issue        = {12},
  pages        = {2483--2506},
  date         = {2004-12},
  doi          = {10.1162/0899766042321751},
  pmid         = {15516271},
  issn         = {0899-7667},
  abstract     = {Clustering provides a common means of identifying structure in
                  complex data, and there is renewed interest in clustering as a
                  tool for the analysis of large data sets in many fields. A
                  natural question is how many clusters are appropriate for the
                  description of a given system. Traditional approaches to this
                  problem are based on either a framework in which clusters of a
                  particular shape are assumed as a model of the system or on a
                  two-step procedure in which a clustering criterion determines
                  the optimal assignments for a given number of clusters and a
                  separate criterion measures the goodness of the classification
                  to determine the number of clusters. In a statistical
                  mechanics approach, clustering can be seen as a trade-off
                  between energy- and entropy-like terms, with lower temperature
                  driving the proliferation of clusters to provide a more
                  detailed description of the data. For finite data sets, we
                  expect that there is a limit to the meaningful structure that
                  can be resolved and therefore a minimum temperature beyond
                  which we will capture sampling noise. This suggests that
                  correcting the clustering criterion for the bias that arises
                  due to sampling errors will allow us to find a clustering
                  solution at a temperature that is optimal in the sense that we
                  capture maximal meaningful structure--without having to define
                  an external criterion for the goodness or stability of the
                  clustering. We show that in a general information-theoretic
                  framework, the finite size of a data set determines an optimal
                  temperature, and we introduce a method for finding the maximal
                  number of clusters that can be resolved from the data in the
                  hard clustering limit.},
  url          = {http://dx.doi.org/10.1162/0899766042321751},
  language     = {eng}
}

@ARTICLE{Witten2010-fb,
  title        = {A framework for feature selection in clustering},
  author       = {Witten, Daniela M and Tibshirani, Robert},
  journaltitle = {J. Am. Stat. Assoc.},
  volume       = {105},
  issue        = {490},
  pages        = {713--726},
  date         = {2010-06-01},
  doi          = {10.1198/jasa.2010.tm09415},
  pmc          = {PMC2930825},
  issn         = {0162-1459},
  abstract     = {We consider the problem of clustering observations using a
                  potentially large set of features. One might expect that the
                  true underlying clusters present in the data differ only with
                  respect to a small fraction of the features, and will be
                  missed if one clusters the observations using the full set of
                  features. We propose a novel framework for sparse clustering,
                  in which one clusters the observations using an adaptively
                  chosen subset of the features. The method uses a lasso-type
                  penalty to select the features. We use this framework to
                  develop simple methods for sparse K-means and sparse
                  hierarchical clustering. A single criterion governs both the
                  selection of the features and the resulting clusters. These
                  approaches are demonstrated on simulated data and on genomic
                  data sets.},
  url          = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2930825/},
  urldate      = {2016-03-28}
}

@ARTICLE{Morant1923-co,
  title        = {A First Study of the Tibetan Skull},
  author       = {Morant, G M},
  journaltitle = {Biometrika},
  volume       = {14},
  issue        = {3/4},
  pages        = {193--260},
  date         = {1923},
  issn         = {0006-3444},
  url          = {http://www.jstor.org/stable/2331812},
  urldate      = {2016-03-14}
}

@ARTICLE{Felice2016-lh,
  title        = {The evolution of sexually dimorphic tail feathers is not
                  associated with tail skeleton dimorphism},
  author       = {Felice, Ryan N and O'Connor, Patrick M},
  journaltitle = {J. Avian Biol.},
  publisher    = {Blackwell Publishing Ltd},
  volume       = {47},
  issue        = {3},
  pages        = {371--377},
  date         = {2016-05-01},
  doi          = {10.1111/jav.00801},
  issn         = {0908-8857},
  abstract     = {Sexual selection can influence the evolution of sexually
                  dimorphic exaggerated display structures. Herein, we explore
                  whether such costly ornamental integumentary structures evolve
                  independently or if they are correlated with phenotypic change
                  in the associated skeletal system. In birds, elongate tail
                  feathers have frequently evolved in males and are beneficial
                  as intraspecific display structures but impart a
                  locomotor/energetic cost. Using the sexually dimorphic tail
                  feathers of several passeriform species as a model system, we
                  test the hypothesis that taxa with sexually dimorphic tail
                  feathers also exhibit sexual dimorphism in the caudal skeleton
                  that supports the muscles and integument of the tail
                  apparatus. Caudal skeletal morphology is quantified using both
                  geometric morphometrics and linear morphometrics across four
                  sexually dimorphic passeriform species and four closely
                  related monomorphic species. Sexual dimorphism is assessed
                  using permutational MANOVA. Sexual dimorphism in caudal
                  skeletal morphology is found only in those taxa that exhibit
                  active functional differences in tail use between males and
                  females. Thus, dimorphism in tail feather length is not
                  necessarily correlated with the evolution of caudal skeletal
                  dimorphism. Sexual selection is sufficient to generate
                  phenotypic divergence in integumentary display structures
                  between the sexes, but these change are not reflected in the
                  underlying caudal skeleton. This suggests that caudal feathers
                  and bones evolve semi-independently from one another and
                  evolve at different rates in response to different types of
                  selective pressures.},
  url          = {http://dx.doi.org/10.1111/jav.00801},
  urldate      = {2016-03-14},
  language     = {en}
}

@ARTICLE{Margres2015-gc,
  title        = {Phenotypic integration in the feeding system of the eastern
                  diamondback rattlesnake (Crotalus adamanteus)},
  author       = {Margres, Mark J and Wray, Kenneth P and Seavy, Margaret and
                  McGivern, James J and Sanader, Dragana and Rokyta, Darin R},
  journaltitle = {Mol. Ecol.},
  volume       = {24},
  issue        = {13},
  pages        = {3405--3420},
  date         = {2015-07-01},
  doi          = {10.1111/mec.13240},
  issn         = {0962-1083,1365-294X},
  abstract     = {Selection can vary geographically across environments and
                  temporally over the lifetime of an individual. Unlike
                  geographic contexts, where different selective regimes can act
                  on different alleles, age-specific selection is constrained to
                  act on the same genome by altering age-specific expression.
                  Snake venoms are exceptional traits for studying ontogeny
                  because toxin expression variation directly changes the
                  phenotype; relative amounts of venom components determine, in
                  part, venom efficacy. Phenotypic integration is the dependent
                  relationship between different traits that collectively
                  produce a complex phenotype and, in venomous snakes, may
                  include traits as diverse as venom, head shape and fang
                  length. We examined the feeding system of the eastern
                  diamondback rattlesnake (Crotalus adamanteus) across
                  environments and over the lifetime of individuals and used a
                  genotype–phenotype map approach, protein expression data and
                  morphological data to demonstrate that: (i) ontogenetic
                  effects explained more of the variation in toxin expression
                  variation than geographic effects, (ii) both juveniles and
                  adults varied geographically, (iii) toxin expression variation
                  was a result of directional selection and (iv) different venom
                  phenotypes covaried with morphological traits also associated
                  with feeding in temporal (ontogenetic) and geographic
                  (functional) contexts. These data are the first to
                  demonstrate, to our knowledge, phenotypic integration between
                  multiple morphological characters and a biochemical phenotype
                  across populations and age classes. We identified copy number
                  variation as the mechanism driving the difference in the venom
                  phenotype associated with these morphological differences, and
                  the parallel mitochondrial, venom and morphological divergence
                  between northern and southern clades suggests that each clade
                  may warrant classification as a separate evolutionarily
                  significant unit.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/mec.13240/abstract},
  urldate      = {2016-03-14},
  language     = {en}
}

@ARTICLE{Gonzalez2008-ud,
  title        = {{CCA}: An {R} package to extend canonical correlation analysis},
  shorttitle   = {CCA},
  author       = {González, Ignacio and Déjean, Sébastien and Martin, Pascal G P
                  and Baccini, Alain and {others}},
  journaltitle = {J. Stat. Softw.},
  volume       = {23},
  issue        = {12},
  pages        = {1--14},
  date         = {2008},
  url          = {http://www.jstatsoft.org/htaccess.php?volume=23&type=i&issue=12&paper=true},
  urldate      = {2016-03-13}
}

@ARTICLE{Baker2016-aq,
  title        = {Statisticians issue warning over misuse of {P} values},
  author       = {Baker, Monya},
  journaltitle = {Nature},
  date         = {2016-03-07},
  doi          = {10.1038/nature.2016.19503},
  issn         = {0028-0836,1476-4687},
  url          = {http://www.nature.com/doifinder/10.1038/nature.2016.19503},
  urldate      = {2016-03-07}
}

@ARTICLE{Meehl1967-he,
  title        = {Theory-Testing in Psychology and Physics: A Methodological
                  Paradox},
  shorttitle   = {Theory-Testing in Psychology and Physics},
  author       = {Meehl, Paul E},
  journaltitle = {Philos. Sci.},
  volume       = {34},
  issue        = {2},
  pages        = {103--115},
  date         = {1967},
  issn         = {0031-8248},
  abstract     = {Because physical theories typically predict numerical values,
                  an improvement in experimental precision reduces the tolerance
                  range and hence increases corroborability. In most
                  psychological research, improved power of a statistical design
                  leads to a prior probability approaching 1/2 of finding a
                  significant difference in the theoretically predicted
                  direction. Hence the corroboration yielded by "success" is
                  very weak, and becomes weaker with increased precision.
                  "Statistical significance" plays a logical role in psychology
                  precisely the reverse of its role in physics. This problem is
                  worsened by certain unhealthy tendencies prevalent among
                  psychologists, such as a premium placed on experimental
                  "cuteness" and a free reliance upon ad hoc explanations to
                  avoid refutation.},
  url          = {http://www.jstor.org/stable/186099},
  urldate      = {2016-03-07}
}

@ARTICLE{Wasserstein2016-qk,
  title        = {The {ASA}'s Statement on p-Values: Context, Process, and
                  Purpose},
  shorttitle   = {The ASA's statement on p-values},
  author       = {Wasserstein, Ronald L and Lazar, Nicole A},
  journaltitle = {Am. Stat.},
  publisher    = {Taylor \& Francis},
  volume       = {70},
  issue        = {2},
  pages        = {129--133},
  date         = {2016-04-02},
  doi          = {10.1080/00031305.2016.1154108},
  issn         = {0003-1305},
  url          = {https://doi.org/10.1080/00031305.2016.1154108},
  urldate      = {2016-03-07},
  note         = {doi: 10.1080/00031305.2016.1154108}
}

@ARTICLE{Kaplan2015-rd,
  title        = {Likelihood of Null Effects of Large {NHLBI} Clinical Trials
                  Has Increased over Time},
  author       = {Kaplan, Robert M and Irvin, Veronica L},
  journaltitle = {PLoS One},
  volume       = {10},
  issue        = {8},
  pages        = {e0132382},
  date         = {2015-08-05},
  doi          = {10.1371/journal.pone.0132382},
  issn         = {1932-6203},
  abstract     = {Background We explore whether the number of null results in
                  large National Heart Lung, and Blood Institute (NHLBI) funded
                  trials has increased over time. Methods We identified all
                  large NHLBI supported RCTs between 1970 and 2012 evaluating
                  drugs or dietary supplements for the treatment or prevention
                  of cardiovascular disease. Trials were included if direct
                  costs >\$500,000/year, participants were adult humans, and the
                  primary outcome was cardiovascular risk, disease or death. The
                  55 trials meeting these criteria were coded for whether they
                  were published prior to or after the year 2000, whether they
                  registered in clinicaltrials.gov prior to publication, used
                  active or placebo comparator, and whether or not the trial had
                  industry co-sponsorship. We tabulated whether the study
                  reported a positive, negative, or null result on the primary
                  outcome variable and for total mortality. Results 17 of 30
                  studies (57\%) published prior to 2000 showed a significant
                  benefit of intervention on the primary outcome in comparison
                  to only 2 among the 25 (8\%) trials published after 2000 (χ 2
                  =12.2,df= 1, p=0.0005). There has been no change in the
                  proportion of trials that compared treatment to placebo versus
                  active comparator. Industry co-sponsorship was unrelated to
                  the probability of reporting a significant benefit.
                  Pre-registration in clinical trials.gov was strongly
                  associated with the trend toward null findings. Conclusions
                  The number NHLBI trials reporting positive results declined
                  after the year 2000. Prospective declaration of outcomes in
                  RCTs, and the adoption of transparent reporting standards, as
                  required by clinicaltrials.gov, may have contributed to the
                  trend toward null findings.},
  url          = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0132382},
  urldate      = {2016-02-29}
}

@ARTICLE{Akaike1981-vc,
  title        = {Likelihood of a model and information criteria},
  author       = {Akaike, Hirotugu},
  journaltitle = {J. Econom.},
  volume       = {16},
  issue        = {1},
  pages        = {3--14},
  date         = {1981-05},
  doi          = {10.1016/0304-4076(81)90071-3},
  issn         = {0304-4076},
  url          = {http://www.sciencedirect.com/science/article/pii/0304407681900713},
  urldate      = {2016-02-29}
}

@ARTICLE{Yang2010-ab,
  title        = {Common {SNPs} explain a large proportion of the heritability
                  for human height},
  author       = {Yang, Jian and Benyamin, Beben and McEvoy, Brian P and Gordon,
                  Scott and Henders, Anjali K and Nyholt, Dale R and Madden,
                  Pamela A and Heath, Andrew C and Martin, Nicholas G and
                  Montgomery, Grant W and Goddard, Michael E and Visscher, Peter
                  M},
  journaltitle = {Nat. Genet.},
  volume       = {42},
  issue        = {7},
  pages        = {565--569},
  date         = {2010-07},
  doi          = {10.1038/ng.608},
  issn         = {1061-4036},
  abstract     = {SNPs discovered by genome-wide association studies (GWASs)
                  account for only a small fraction of the genetic variation of
                  complex traits in human populations. Where is the remaining
                  heritability? We estimated the proportion of variance for
                  human height explained by 294,831 SNPs genotyped on 3,925
                  unrelated individuals using a linear model analysis, and
                  validated the estimation method with simulations based on the
                  observed genotype data. We show that 45\% of variance can be
                  explained by considering all SNPs simultaneously. Thus, most
                  of the heritability is not missing but has not previously been
                  detected because the individual effects are too small to pass
                  stringent significance tests. We provide evidence that the
                  remaining heritability is due to incomplete linkage
                  disequilibrium between causal variants and genotyped SNPs,
                  exacerbated by causal variants having lower minor allele
                  frequency than the SNPs explored to date. View full text},
  url          = {http://www.nature.com/ng/journal/v42/n7/abs/ng.608.html},
  urldate      = {2016-02-28},
  language     = {en}
}

@ARTICLE{Valle1999-hq,
  title        = {Selection of the Number of Principal Components: The Variance
                  of the Reconstruction Error Criterion with a Comparison to
                  Other Methods},
  shorttitle   = {Selection of the Number of Principal Components},
  author       = {Valle, Sergio and Li, Weihua and Qin, S Joe},
  journaltitle = {Ind. Eng. Chem. Res.},
  volume       = {38},
  issue        = {11},
  pages        = {4389--4401},
  date         = {1999},
  doi          = {10.1021/ie990110i},
  issn         = {0888-5885,1520-5045},
  url          = {http://pubs.acs.org/doi/abs/10.1021/ie990110i},
  urldate      = {2016-02-26},
  language     = {en}
}

@ARTICLE{Gelman2014-ng,
  title        = {The statistical crisis in science},
  author       = {Gelman, Andrew and Loken, Eric},
  journaltitle = {Am. Sci.},
  volume       = {102},
  pages        = {460--465},
  date         = {2014},
  issn         = {0003-0996}
}

@ARTICLE{Speed1986-xy,
  title        = {Question, answers and statistics},
  author       = {Speed, Terry},
  journaltitle = {ICOTS},
  date         = {1986},
  url          = {http://www.stat.auckland.ac.nz/~iase/publications/icots2/Speed.pdf},
  urldate      = {2016-02-25}
}

@ARTICLE{Morey2016-yh,
  title        = {The fallacy of placing confidence in confidence intervals},
  author       = {Morey, Richard D and Hoekstra, Rink and Rouder, Jeffrey N and
                  Lee, Michael D and Wagenmakers, Eric-Jan},
  journaltitle = {Psychon. Bull. Rev.},
  volume       = {23},
  issue        = {1},
  pages        = {103--123},
  date         = {2016-02},
  doi          = {10.3758/s13423-015-0947-8},
  pmc          = {PMC4742505},
  pmid         = {26450628},
  issn         = {1069-9384,1531-5320},
  abstract     = {Interval estimates - estimates of parameters that include an
                  allowance for sampling uncertainty - have long been touted as
                  a key component of statistical analyses. There are several
                  kinds of interval estimates, but the most popular are
                  confidence intervals (CIs): intervals that contain the true
                  parameter value in some known proportion of repeated samples,
                  on average. The width of confidence intervals is thought to
                  index the precision of an estimate; CIs are thought to be a
                  guide to which parameter values are plausible or reasonable;
                  and the confidence coefficient of the interval (e.g., 95 \%)
                  is thought to index the plausibility that the true parameter
                  is included in the interval. We show in a number of examples
                  that CIs do not necessarily have any of these properties, and
                  can lead to unjustified or arbitrary inferences. For this
                  reason, we caution against relying upon confidence interval
                  theory to justify interval estimates, and suggest that other
                  theories of interval estimation should be used instead.},
  url          = {http://dx.doi.org/10.3758/s13423-015-0947-8},
  urldate      = {2016-02-25},
  keywords     = {Bayesian inference and parameter estimation; Bayesian
                  statistics; Statistical inference; Statistics},
  language     = {en}
}

@REPORT{Janzen2016-eb,
  type     = {resreport},
  title    = {Stochastic processes dominate community assembly in cichlid
              communities in Lake Tanganyika},
  author   = {Janzen, Thijs and Alzate, Adriana and Muschick, Moritz and van der
              Plas, Fons and Etienne, Rampal S},
  number   = {biorxiv;039503v2},
  date     = {2016-02-12},
  url      = {http://biorxiv.org/lookup/doi/10.1101/039503},
  urldate  = {2016-02-25},
  language = {en}
}

@ARTICLE{Leos-Barajas2016-lh,
  title        = {Analysis of animal accelerometer data using hidden Markov
                  models},
  author       = {Leos-Barajas, Vianey and Photopoulou, Theoni and Langrock,
                  Roland and Patterson, Toby A and Watanabe, Yuuki and
                  Murgatroyd, Megan and Papastamatiou, Yannis P},
  journaltitle = {arXiv:1602.06466 [q-bio]},
  date         = {2016-02-20},
  abstract     = {Use of accelerometers is now widespread within animal
                  biotelemetry as they provide a means of measuring an animal's
                  activity in a meaningful and quantitative way where direct
                  observation is not possible. In sequential acceleration data
                  there is a natural dependence between observations of movement
                  or behaviour, a fact that has been largely ignored in most
                  analyses. Analyses of acceleration data where serial
                  dependence has been explicitly modelled have largely relied on
                  hidden Markov models (HMMs). Depending on the aim of an
                  analysis, either a supervised or an unsupervised learning
                  approach can be applied. Under a supervised context, an HMM is
                  trained to classify unlabelled acceleration data into a finite
                  set of pre-specified categories, whereas we will demonstrate
                  how an unsupervised learning approach can be used to infer new
                  aspects of animal behaviour. We will provide the details
                  necessary to implement and assess an HMM in both the
                  supervised and unsupervised context, and discuss the data
                  requirements of each case. We outline two applications to
                  marine and aerial systems (sharks and eagles) taking the
                  unsupervised approach, which is more readily applicable to
                  animal activity measured in the field. HMMs were used to infer
                  the effects of temporal, atmospheric and tidal inputs on
                  animal behaviour. Animal accelerometer data allow ecologists
                  to identify important correlates and drivers of animal
                  activity (and hence behaviour). The HMM framework is well
                  suited to deal with the main features commonly observed in
                  accelerometer data. The ability to combine direct observations
                  of animals activity and combine it with statistical models
                  which account for the features of accelerometer data offer a
                  new way to quantify animal behaviour, energetic expenditure
                  and deepen our insights into individual behaviour as a
                  constituent of populations and ecosystems.},
  url          = {http://arxiv.org/abs/1602.06466},
  urldate      = {2016-02-24}
}

@ARTICLE{Willerman1991-su,
  title        = {In vivo brain size and intelligence},
  author       = {Willerman, Lee and Schultz, Robert and Neal Rutledge, J and
                  Bigler, Erin D},
  journaltitle = {Intelligence},
  volume       = {15},
  issue        = {2},
  pages        = {223--228},
  date         = {1991-04},
  doi          = {10.1016/0160-2896(91)90031-8},
  issn         = {0160-2896},
  abstract     = {It is widely believed that human brain size and intelligence
                  are only weakly related to each other. Using magnetic
                  resonance imaging, we show that larger brain size (corrected
                  for body size) is associated with higher IQ in 40 college
                  students equally divided by high versus average IQ, and by
                  sex. These results suggest that differences in human brain
                  size are relevant to explaining differences in intelligence
                  test performance.},
  url          = {http://www.sciencedirect.com/science/article/pii/0160289691900318},
  urldate      = {2016-02-24}
}

@ARTICLE{Abelson2016-ad,
  title        = {Brain size is correlated with endangerment status in mammals},
  author       = {Abelson, Eric S},
  journaltitle = {Proc. R. Soc. B},
  volume       = {283},
  issue        = {1825},
  pages        = {20152772},
  date         = {2016-02-24},
  doi          = {10.1098/rspb.2015.2772},
  pmid         = {26888034},
  issn         = {0962-8452,1471-2954},
  abstract     = {Increases in relative encephalization (RE), brain size after
                  controlling for body size, comes at a great metabolic cost and
                  is correlated with a host of cognitive traits, from the
                  ability to count objects to higher rates of innovation.
                  Despite many studies examining the implications and trade-offs
                  accompanying increased RE, the relationship between mammalian
                  extinction risk and RE is unknown. I examine whether mammals
                  with larger levels of RE are more or less likely to be at risk
                  of endangerment than less-encephalized species. I find that
                  extant species with large levels of encephalization are at
                  greater risk of endangerment, with this effect being strongest
                  in species with small body sizes. These results suggest that
                  RE could be a valuable asset in estimating extinction
                  vulnerability. Additionally, these findings suggest that the
                  cost–benefit trade-off of RE is different in large-bodied
                  species when compared with small-bodied species.},
  url          = {http://rspb.royalsocietypublishing.org/content/283/1825/20152772},
  urldate      = {2016-02-23},
  language     = {en}
}

@ARTICLE{Frasier2016-wt,
  title        = {A note on the use of multiple linear regression in molecular
                  ecology},
  author       = {Frasier, Timothy R},
  journaltitle = {Mol. Ecol. Resour.},
  volume       = {16},
  issue        = {2},
  pages        = {382--387},
  date         = {2016-03-01},
  doi          = {10.1111/1755-0998.12499},
  issn         = {1755-098X,1755-0998},
  abstract     = {Multiple linear regression analyses (also often referred to as
                  generalized linear models – GLMs, or generalized linear mixed
                  models – GLMMs) are widely used in the analysis of data in
                  molecular ecology, often to assess the relative effects of
                  genetic characteristics on individual fitness or traits, or
                  how environmental characteristics influence patterns of
                  genetic differentiation. However, the coefficients resulting
                  from multiple regression analyses are sometimes
                  misinterpreted, which can lead to incorrect interpretations
                  and conclusions within individual studies, and can propagate
                  to wider-spread errors in the general understanding of a
                  topic. The primary issue revolves around the interpretation of
                  coefficients for independent variables when interaction terms
                  are also included in the analyses. In this scenario, the
                  coefficients associated with each independent variable are
                  often interpreted as the independent effect of each predictor
                  variable on the predicted variable. However, this
                  interpretation is incorrect. The correct interpretation is
                  that these coefficients represent the effect of each predictor
                  variable on the predicted variable when all other predictor
                  variables are zero. This difference may sound subtle, but the
                  ramifications cannot be overstated. Here, my goals are to
                  raise awareness of this issue, to demonstrate and emphasize
                  the problems that can result and to provide alternative
                  approaches for obtaining the desired information.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/1755-0998.12499/abstract},
  urldate      = {2016-02-21},
  language     = {en}
}

@ARTICLE{Lloyd2016-xh,
  title        = {Estimating morphological diversity and tempo with discrete
                  character-taxon matrices: implementation, challenges,
                  progress, and future directions},
  shorttitle   = {Estimating morphological diversity and tempo with discrete
                  character-taxon matrices},
  author       = {Lloyd, Graeme T},
  journaltitle = {Biol. J. Linn. Soc. Lond.},
  volume       = {118},
  issue        = {1},
  pages        = {131--151},
  date         = {2016-05-01},
  doi          = {10.1111/bij.12746},
  issn         = {0024-4066},
  abstract     = {Discrete character-taxon matrices are increasingly being used
                  in an attempt to understand the pattern and tempo of
                  morphological evolution; however, methodological
                  sophistication and bespoke software implementations have
                  lagged behind. In the present study, an attempt is made to
                  provide a state-of-the-art description of methodologies and
                  introduce a new R package (Claddis) for performing
                  foundational disparity (morphologic diversity) and rate
                  calculations. Simulations using its core functions show that:
                  (1) of the two most commonly used distance metrics
                  (Generalized Euclidean Distance and Gower's Coefficient), the
                  latter tends to carry forward more of the true signal; (2) a
                  novel distance metric may improve signal retention further;
                  (3) this signal retention may come at the cost of pruning
                  incomplete taxa from the data set; and (4) the utility of
                  bivariate plots of ordination spaces are undermined by their
                  frequently extremely low variances. By contrast, challenges to
                  estimating morphologic tempo are presented qualitatively, such
                  as how trees are time-scaled and changes are counted. Both
                  disparity and rates deserve better time series approaches that
                  could unlock new macroevolutionary analyses. However, these
                  challenges need not be fatal, and several potential future
                  solutions and directions are suggested.},
  url          = {http://dx.doi.org/10.1111/bij.12746},
  urldate      = {2016-02-19},
  keywords     = {cladistics; disparity; evolution; fossils; macroevolution;
                  time series},
  language     = {en}
}

@ARTICLE{Wahlsten1990-hc,
  title        = {Insensitivity of the analysis of variance to
                  heredity-environment interaction},
  author       = {Wahlsten, Douglas},
  journaltitle = {Behav. Brain Sci.},
  volume       = {13},
  issue        = {01},
  pages        = {109--120},
  date         = {1990-03},
  doi          = {10.1017/S0140525X00077797},
  issn         = {0140-525X,1469-1825},
  abstract     = {It makes sense to attribute a definite percentage of variation
                  in some measure of behavior to variation in heredity only if
                  the effects of heredity and environment are truly additive.
                  Additivity is often tested by examining the interaction effect
                  in a two-way analysis of variance (ANOVA) or its equivalent
                  multiple regression model. If this effect is not statistically
                  significant at the α = 0.05 level, it is common practice in
                  certain fields (e.g., human behavior genetics) to conclude
                  that the two factors really are additive and then to use
                  linear models, which assume additivity. Comparing several
                  simple models of nonadditive, interactive relationships
                  between heredity and environment, however, reveals that ANOVA
                  often fails to detect nonadditivity because it has much less
                  power in tests of interaction than in tests of main effects.
                  Likewise, the sample sizes needed to detect real interactions
                  are substantially greater than those needed to detect main
                  effects. Data transformations that reduce interaction effects
                  also change drastically the properties ofthe causal model and
                  may conceal theoretically interesting and practically useful
                  relationships. If the goal ofpartitioning variance among
                  mutually exclusive causes and calculating “heritability”
                  coefficients is abandoned, interactive relationships can be
                  examined more seriously and can enhance our understanding of
                  the ways living things develop.},
  url          = {http://journals.cambridge.org/article_S0140525X00077797},
  urldate      = {2016-02-16}
}

@ARTICLE{Rodger1974-bq,
  title        = {Multiple Contrasts, Factors, Error Rate and Power},
  author       = {Rodger, R S},
  journaltitle = {Br. J. Math. Stat. Psychol.},
  volume       = {27},
  issue        = {2},
  pages        = {179--198},
  date         = {1974-11-01},
  doi          = {10.1111/j.2044-8317.1974.tb00539.x},
  issn         = {0007-1102,2044-8317},
  abstract     = {A method is given for choosing (post hoc) a set of v1 mutually
                  orthogonal null contrasts such that the maximum number (r)
                  rejectable by a new criterion are rejected and v1 – r
                  retained. Type I error rate is defined as the expected
                  proportion of the v1 decisions which will be errors when all
                  nulls are true. Because the new criterion uses F, the expected
                  proportion of rejections can be calculated for the case when
                  all nulls are not true, and this is taken as the definition of
                  power. Theoretical means are deducible from decisions for v1
                  mutually orthogonal contrasts and, if rejected null contrasts
                  are given suitable non-zero values, there is no ambiguity
                  about the theoretical means. The traditional values of FΓ; v1,
                  v2 ‘load the dice’ against finding true interactions
                  ‘significant’ in factorial analyses. The new values (table
                  given) do not have this property and their use is illustrated
                  using a one-way anova on data from a factorially designed
                  experiment. This procedure permits the analysis of unequal
                  replications in factorially designed experiments.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/j.2044-8317.1974.tb00539.x/abstract},
  urldate      = {2016-02-16},
  language     = {en}
}

@ARTICLE{Olejnik2003-km,
  title        = {Generalized eta and omega squared statistics: measures of
                  effect size for some common research designs},
  shorttitle   = {Generalized eta and omega squared statistics},
  author       = {Olejnik, Stephen and Algina, James},
  journaltitle = {Psychol. Methods},
  volume       = {8},
  issue        = {4},
  pages        = {434--447},
  date         = {2003-12},
  doi          = {10.1037/1082-989X.8.4.434},
  pmid         = {14664681},
  issn         = {1082-989X},
  abstract     = {The editorial policies of several prominent educational and
                  psychological journals require that researchers report some
                  measure of effect size along with tests for statistical
                  significance. In analysis of variance contexts, this
                  requirement might be met by using eta squared or omega squared
                  statistics. Current procedures for computing these measures of
                  effect often do not consider the effect that design features
                  of the study have on the size of these statistics. Because
                  research-design features can have a large effect on the
                  estimated proportion of explained variance, the use of partial
                  eta or omega squared can be misleading. The present article
                  provides formulas for computing generalized eta and omega
                  squared statistics, which provide estimates of effect size
                  that are comparable across a variety of research designs.},
  url          = {http://dx.doi.org/10.1037/1082-989X.8.4.434},
  language     = {eng}
}

@ARTICLE{Ross2016-px,
  title        = {The Origins and Maintenance of Female Genital Modification
                  across Africa},
  author       = {Ross, Cody T and Strimling, Pontus and Ericksen, Karen Paige
                  and Lindenfors, Patrik and Mulder, Monique Borgerhoff},
  journaltitle = {Hum. Nat.},
  pages        = {1--28},
  date         = {2016-02-04},
  doi          = {10.1007/s12110-015-9244-5},
  issn         = {1045-6767,1936-4776},
  abstract     = {We present formal evolutionary models for the origins and
                  persistence of the practice of Female Genital Modification
                  (FGMo). We then test the implications of these models using
                  normative cross-cultural data on FGMo in Africa and Bayesian
                  phylogenetic methods that explicitly model adaptive evolution.
                  Empirical evidence provides some support for the findings of
                  our evolutionary models that the de novo origins of the FGMo
                  practice should be associated with social stratification, and
                  that social stratification should place selective pressures on
                  the adoption of FGMo; these results, however, are tempered by
                  the finding that FGMo has arisen in many cultures that have no
                  social stratification, and that forces operating orthogonally
                  to stratification appear to play a more important role in the
                  cross-cultural distribution of FGMo. To explain these cases,
                  one must consider cultural evolutionary explanations in
                  conjunction with behavioral ecological ones. We conclude with
                  a discussion of the implications of our study for policies
                  designed to end the practice of FGMo.},
  url          = {http://link.springer.com/article/10.1007/s12110-015-9244-5},
  urldate      = {2016-02-15},
  language     = {en}
}

@ARTICLE{McElreath2015-uv,
  title        = {Replication, Communication, and the Population Dynamics of
                  Scientific Discovery},
  author       = {McElreath, Richard and Smaldino, Paul E},
  journaltitle = {PLoS One},
  volume       = {10},
  issue        = {8},
  pages        = {e0136088},
  date         = {2015-08-26},
  doi          = {10.1371/journal.pone.0136088},
  pmc          = {PMC4550284},
  pmid         = {26308448},
  issn         = {1932-6203},
  abstract     = {Many published research results are false (Ioannidis, 2005),
                  and controversy continues over the roles of replication and
                  publication policy in improving the reliability of research.
                  Addressing these problems is frustrated by the lack of a
                  formal framework that jointly represents hypothesis formation,
                  replication, publication bias, and variation in research
                  quality. We develop a mathematical model of scientific
                  discovery that combines all of these elements. This model
                  provides both a dynamic model of research as well as a formal
                  framework for reasoning about the normative structure of
                  science. We show that replication may serve as a ratchet that
                  gradually separates true hypotheses from false, but the same
                  factors that make initial findings unreliable also make
                  replications unreliable. The most important factors in
                  improving the reliability of research are the rate of false
                  positives and the base rate of true hypotheses, and we offer
                  suggestions for addressing each. Our results also bring
                  clarity to verbal debates about the communication of research.
                  Surprisingly, publication bias is not always an obstacle, but
                  instead may have positive impacts-suppression of negative
                  novel findings is often beneficial. We also find that
                  communication of negative replications may aid true discovery
                  even when attempts to replicate have diminished power. The
                  model speaks constructively to ongoing debates about the
                  design and conduct of science, focusing analysis and
                  discussion on precise, internally consistent models, as well
                  as highlighting the importance of population dynamics.},
  url          = {http://dx.doi.org/10.1371/journal.pone.0136088},
  urldate      = {2016-02-15},
  language     = {en}
}

@ARTICLE{Vuilleumier1970-dn,
  title        = {Insular Biogeography in Continental Regions. {I}. The Northern
                  Andes of South America},
  author       = {Vuilleumier, Francois},
  journaltitle = {Am. Nat.},
  volume       = {104},
  issue        = {938},
  pages        = {373--388},
  date         = {1970},
  issn         = {0003-0147},
  abstract     = {In order to test whether the theory of insular biogeography
                  also applies to a continental situation, species diversity and
                  endemism were studied among the birds living in islands of
                  paramo vegetation above timberline in the northern Andes of
                  South America. Stepwise regression analyses were performed,
                  assuming that measures of environmental diversity (especially
                  area) and of isolation (interisland distances) permit
                  prediction of species numbers and numbers of endemics in a
                  continental situation, as they do in archipelagos. With seven
                  independent variables included in the equations, prediction of
                  species diversity and endemism was extremely good. From 92\%
                  to 97\% of the variance in species numbers can be accounted
                  for by regression, the best fit (97\%) being obtained with a
                  linear model. From 87\% to 93\% of the variance in number of
                  endemics can be predicted by regression, a semilog model
                  providing the best fit (93 \% ). The Andean islands conform to
                  archipelagos in two ways: first, because the species-area
                  curve offers a reasonable prediction, as a first
                  approximation, of species numbers; and second, because the
                  numbers of endemics can best be predicted by some measure of
                  interisland distance. The paramo islands differ from oceanic
                  islands, however, because the distance effect curve is more
                  linear than exponential, and because there is no statistically
                  significant correlation between endemism and area of islands.
                  These differences can be explained if isolation between
                  islands is less absolute, so that the probability distribution
                  of dispersal away from a source area is uniform, instead of
                  exponential or normal.},
  url          = {http://www.jstor.org/stable/2459123},
  urldate      = {2016-02-10}
}

@ARTICLE{Bufford2015-ef,
  title        = {Defoliation by pastoralists affects savanna tree seedling
                  dynamics by limiting the facilitative role of canopy cover},
  author       = {Bufford, Jennifer L and Gaoue, Orou G},
  journaltitle = {Ecol. Appl.},
  volume       = {25},
  issue        = {5},
  pages        = {1319--1329},
  date         = {2015-07-01},
  doi          = {10.1890/14-0953.1},
  issn         = {1051-0761,1939-5582},
  abstract     = {Recurrent tree defoliation by pastoralists, akin to herbivory,
                  can negatively affect plant reproduction and population
                  dynamics. However, our understanding of the indirect role of
                  defoliation in seedling recruitment and tree–grass dynamics in
                  tropical savanna is limited. In West African savanna, Fulani
                  pastoralists frequently defoliate several fodder tree species
                  to feed livestock in the dry season. We investigated the
                  direct and indirect effects of recurrent defoliation of
                  African mahogany (Khaya senegalensis) by Fulani people on
                  seedling (<2 cm basal diameter) and sapling dynamics in West
                  Africa using four years of demographic data on seedling and
                  sapling density, growth, and survival, coupled with fruit
                  production and microhabitat data over the same time period.
                  Tree canopy cover facilitated seedlings but had negative
                  effects on sapling growth possibly via intraspecific
                  competition with adult plants. Interspecific competition with
                  grasses strongly reduced seedling survival but had a weak
                  effect on sapling growth. Fire reduced seedling survival and
                  weakly reduced growth of seedlings and saplings, but did not
                  affect sapling survival. These results indicate that the
                  effect of fire on seedlings and saplings is distinct, a
                  mechanism suitable for an episodic recruitment of seedlings
                  into the sapling stage and consistent with predictions from
                  the demographic bottleneck model. Defoliation affected
                  seedling density and sapling growth through changes in canopy
                  cover, but had no effect on seedling growth and sapling
                  survival. In the moist region, sapling density was higher in
                  sites with low-intensity defoliation, indicating that
                  defoliation may strengthen the tree recruitment bottleneck.
                  Our study suggests that large-scale defoliation can alter the
                  facilitative role of nurse trees on seedling dynamics and
                  tree–sapling competition. Given that tree defoliation by local
                  people is a widespread activity throughout savanna–forest
                  systems in West Africa, it has the potential to affect
                  tree–grass coexistence. Incorporating the influence of large
                  tree defoliation into existing models of savanna dynamics can
                  further our understanding of tree–grass coexistence and
                  improve management. A rotating harvest system, which allows
                  seedlings to recruit episodically, or a patchwork harvest,
                  which maintains some nursery trees in the mosaic, could help
                  sustain seedling recruitment and minimize the indirect effects
                  of harvest.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1890/14-0953.1/abstract},
  urldate      = {2016-02-09},
  language     = {en}
}

@ARTICLE{Margalida2016-wv,
  title        = {Improving the peer-review process and editorial quality: key
                  errors escaping the review and editorial process in top
                  scientific journals},
  shorttitle   = {Improving the peer-review process and editorial quality},
  author       = {Margalida, Antoni and Colomer, M Àngels},
  journaltitle = {PeerJ},
  volume       = {4},
  pages        = {e1670},
  date         = {2016-02-09},
  doi          = {10.7717/peerj.1670},
  pmc          = {PMC4756748},
  pmid         = {26893961},
  issn         = {2167-8359},
  abstract     = {We apply a novel mistake index to assess trends in the
                  proportion of corrections published between 1993 and 2014 in
                  Nature, Science and PNAS. The index revealed a progressive
                  increase in the proportion of corrections published in these
                  three high-quality journals. The index appears to be
                  independent of the journal impact factor or the number of
                  items published, as suggested by a comparative analyses among
                  16 top scientific journals of different impact factors and
                  disciplines. A more detailed analysis suggests that the trend
                  in the time-to-correction increased significantly over time
                  and also differed among journals (Nature 233 days; Science 136
                  days; PNAS 232 days). A detailed review of 1,428 errors showed
                  that 60\% of corrections were related to figures, authors,
                  references or results. According to the three categories
                  established, 34.7\% of the corrections were considered mild,
                  47.7\% moderate and 17.6\% severe, also differing among
                  journals. Errors occurring during the printing process were
                  responsible for 5\% of corrections in Nature, 3\% in Science
                  and 18\% in PNAS. The measurement of the temporal trends in
                  the quality of scientific manuscripts can assist editors and
                  reviewers in identifying the most common mistakes, increasing
                  the rigor of peer-review and improving the quality of
                  published scientific manuscripts.},
  url          = {http://dx.doi.org/10.7717/peerj.1670},
  urldate      = {2016-02-09},
  keywords     = {Bibliometric analyses; Corrections; Mistake index; Peer
                  review; Publishing},
  language     = {en}
}

@ARTICLE{Tukey1951-vs,
  title        = {Components in Regression},
  author       = {Tukey, John W},
  journaltitle = {Biometrics},
  volume       = {7},
  issue        = {1},
  pages        = {33--69},
  date         = {1951},
  doi          = {10.2307/3001602},
  issn         = {0006-341X},
  url          = {http://www.jstor.org/stable/3001602},
  urldate      = {2016-02-09}
}

@ARTICLE{Sokal1962-um,
  title        = {Variation and Covariation of Characters of Alate Pemphigus
                  populi-transversus in Eastern North America},
  author       = {Sokal, Robert R},
  journaltitle = {Evolution},
  volume       = {16},
  issue        = {2},
  pages        = {227--245},
  date         = {1962},
  doi          = {10.2307/2406199},
  issn         = {0014-3820},
  abstract     = {1. An earlier study (Sokal, 1952) of character variation in
                  the gall making aphid Pemphigus populi-transversus was
                  extended to investigate character relations among localities
                  in eastern North America. 2. Twenty-three localities of 15
                  galls each ranging from Massachusetts to Kansas and Wisconsin
                  to Florida were used in the study. Eighteen characters were
                  measused on two alates per gall. The study involved 12,420
                  measurements on 690 aphids. 3. Hierarchic analyses of variance
                  showed that almost every character differed significantly
                  among localities and most differed among galls within
                  localities. These analyses permitted the study of the
                  percentage of variation attributable to each level of
                  variation; this is shown in table 1. 4. The hierarchic
                  structure of these data made it possible to compute five
                  separate correlation matrices, product-moment matrices at the
                  intragall, intergall, and interlocality levels, and component
                  correlation matrices at the intergall and interlocality
                  levels. Appreciable differences among the three levels of
                  correlation were observed. The product-moment correlation
                  matrices at the higher levels appear to be intermediate
                  between the next lower matrix and the appropriate component
                  correlation matrix. 5. The differences in the correlation
                  matrices are reflected by cluster analyses of some of the
                  highest correlations (shown in figs. 2, 3, and 4). The highest
                  correlations at the intragall level exhibit a regional
                  morphogenetic pattern, while those at the intergall and
                  interlocality levels appear to be adaptational trends not
                  necessarily of adjacent structures and not immediately related
                  to morphogenesis. 6. Multiple factor analysis with rotation to
                  simple structure was undertaken on all correlation matrices.
                  Partial results are shown in table 5. In all but one
                  correlation matrix, three common factors appear to account for
                  nearly all of the observed correlations. 7. The differences in
                  factor pattern must be caused by different genetic and
                  environmental variation patterns at the different hierarchic
                  levels in this study. The implications of this phenomenon for
                  sampling problems in studies of geographic variation is
                  discussed. 8. By means of factor analysis one is able to
                  determine a few common factors, which represent the
                  variational patterns in the species at the level which one
                  wishes to study.},
  url          = {http://www.jstor.org/stable/2406199},
  urldate      = {2016-02-09}
}

@ARTICLE{Sokal1952-gw,
  title        = {Variation in a Local Population of Pemphigus},
  author       = {Sokal, Robert R},
  journaltitle = {Evolution},
  volume       = {6},
  issue        = {3},
  pages        = {296--315},
  date         = {1952},
  doi          = {10.2307/2405415},
  issn         = {0014-3820},
  abstract     = {1. A local population of the gallmaking aphid Pemphigus
                  populi-transversus was studied with a view to finding
                  characters suitable for a study of intraspecific variation. 2.
                  Twenty-eight galls, representing that number of clones, were
                  used and the stem mother and four alates of each gall were
                  measured. Twenty-one characters were measured for each alate
                  and eight for each stem mother. 3. Means and coefficients of
                  variation are given for each character measured. The values of
                  the latter are relatively high due to anormality of the data.
                  4. By analysis of variance, one continuous and six meristic
                  alate characters were shown to lack intergall variance and
                  thus owe their variation to intragall, environmental factors
                  only. The remaining alate characters exhibit significant
                  variance between galls. 5. An analysis of covariance
                  demonstrated that the intergall variance of thorax length
                  accounts for much of the intergall variances of other alate
                  characters. Thus thorax length was found to be the most
                  representative alate character. 6. Other characters were
                  chosen on the basis of their relative independence from thorax
                  length. Forewing length, thorax width, femur length and
                  antennal segment IV length were so chosen. 7. Total
                  correlation coefficients were calculated and showed a lack of
                  correlation between the non-significant meristic characters
                  and other characters as well as high correlations among the
                  significant characters. 8. The total correlation coefficients
                  were partitioned into intragall and intergall correlation
                  coefficients. There are low non-hereditary intragall
                  correlations between characters, while the intergall
                  correlation are high for all significant characters. 9. Stem
                  mother characters showed low correlations among themselves and
                  with alate characters, except for stem mother total length
                  which is well correlated with alate characters. 10. The
                  assumption that intergall variance is in part due to genetic
                  factors is made and defended. 11. The presence of a general
                  size factor of probably genetic origin is believed
                  demonstrated for the first time in insects. There is some
                  indication of group size factors. 12. Non-genetic special size
                  factors are shown for some characters and there is some
                  evidence that intragall correlations are a function of
                  distance between correlated characters. 13. Pearson's rule on
                  correlations can be shown in modified form in antennal and leg
                  correlations.},
  url          = {http://www.jstor.org/stable/2405415},
  urldate      = {2016-02-09}
}

@ARTICLE{Gotelli2002-fx,
  title        = {Assembly rules for New England ant assemblages},
  author       = {Gotelli, Nicholas J and Ellison, Aaron M},
  journaltitle = {Oikos},
  volume       = {99},
  issue        = {3},
  pages        = {591--599},
  date         = {2002-12-01},
  doi          = {10.1034/j.1600-0706.2002.11734.x},
  issn         = {0030-1299,1600-0706},
  abstract     = {Community assembly rules specify patterns of species
                  co-occurrence and morphology dictated by interspecific
                  competition. We collected data on the occurrence of
                  ground-foraging ant species in 22 ombrotrophic bogs and
                  adjacent forest plots of New England to test two general
                  assembly rules: reduced co-occurrence of species among
                  communities, and even spacing of body sizes of species within
                  communities. We used null models to generate random
                  communities unstructured by competition and evaluated patterns
                  at regional and local spatial scales. At the regional scale,
                  species co-occurrence in forests, but not bogs, was less than
                  expected by chance, whereas, at the local scale, co-occurrence
                  in both habitats was not different from random. At the
                  regional scale, spacing of body size distributions was random
                  (in bogs) or aggregated (in forests). At the local scale, body
                  size patterns were weakly segregated in bogs, but random or
                  weakly aggregated in forests. In bogs, size ratio constancy
                  was accompanied by greater generic diversity than expected.
                  Although assembly rules were originally developed for
                  vertebrate communities, they successfully explained some
                  patterns in New England ant assemblages. However, the patterns
                  were contingent on spatial scale, and were distinctly
                  different for bog and forest communities, despite their close
                  proximity and the presence of many shared species in both
                  assemblages. The harsh physical conditions of bogs may act as
                  a habitat filter that alters community assembly rules.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1034/j.1600-0706.2002.11734.x/abstract},
  urldate      = {2016-02-08},
  language     = {en}
}

@ARTICLE{Gotelli2002-ic,
  title        = {Biogeography at a Regional Scale: Determinants of Ant Species
                  Density in New England Bogs and Forests},
  shorttitle   = {Biogeography at a Regional Scale},
  author       = {Gotelli, Nicholas J and Ellison, Aaron M},
  journaltitle = {Ecology},
  volume       = {83},
  issue        = {6},
  pages        = {1604--1609},
  date         = {2002-06-01},
  doi          = {10.1890/0012-9658(2002)083[1604:BAARSD]2.0.CO;2},
  issn         = {0012-9658,1939-9170},
  abstract     = {We examined species density gradients of ants of New England
                  in 22 ombrotrophic bogs and their surrounding forests. We
                  tested the hypothesis that species density was correlated with
                  large-scale geographic variables (latitude, longitude,
                  elevation) and small-scale site variables (habitat area,
                  vegetation composition, light availability). Species density
                  was consistently higher in forests than in bogs. Ant species
                  density measured in three other New World studies yielded
                  similar results, with steeper diversity slopes in closed
                  canopy vs. open habitats. In New England bogs and forests,
                  latitude was the single most important predictor of species
                  density, even though the latitudinal span of the entire study
                  region was less than three degrees. Diversity patterns
                  documented in our study of mid-latitude ant communities are
                  similar to those seen in studies spanning tropical and
                  temperate habitats. Species density of forest ants was
                  associated strongly with latitude, elevation, light
                  availability, and vegetation composition. Species density of
                  bog ants was less predictable and was correlated only with
                  latitude and vegetation. Overall, our results suggest that
                  species–energy relationships are important at regional spatial
                  scales. Explanations for the latitudinal gradient in ant
                  species density may not depend on unique differences between
                  tropical and temperate communities, but could operate at all
                  latitudes.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1890/0012-9658(2002)083[1604:BAARSD]2.0.CO;2/abstract},
  urldate      = {2016-02-08},
  language     = {en}
}

@ARTICLE{Zelditch1988-dt,
  title        = {Ontogenetic Variation in Patterns of Phenotypic Integration in
                  the Laboratory Rat},
  author       = {Zelditch, Miriam Leah},
  journaltitle = {Evolution},
  publisher    = {[Society for the Study of Evolution, Wiley]},
  volume       = {42},
  issue        = {1},
  pages        = {28--41},
  date         = {1988},
  doi          = {10.2307/2409113},
  issn         = {0014-3820,1558-5646},
  abstract     = {I used confirmatory factor analysis to evaluate the ability of
                  causal developmental models to predict observed phenotypic
                  integration in limb and skull measures at five stages of
                  postnatal ontogeny in the laboratory rat. To analyze the
                  dynamics of phenotypic integration, I fit successive
                  age-classes simultaneously to a common model. Growth was the
                  principal developmental explanation of observed phenotypic
                  covariation in the limb and skull. No complex morphogenetic
                  model more adequately reconstructed observed covariance
                  structure. Models that could not be interpreted in
                  embryological terms, coupled with a growth component, provide
                  the best models for observed phenotypic integration. During
                  postnatal growth, some aspects of integration vary in both the
                  skull and limb. The covariance between factors and the
                  proportion of variance unique to each character differ between
                  some sequential age-classes. The factor-pattern is invariant
                  in the limb; however, repatterning in the skull occurs in the
                  interval between eye-opening and weaning. The temporal
                  variation in the structure of covariation suggests that
                  functional interactions among characters may create observed
                  patterns of phenotypic integration. The developmental
                  constraints responsible for evolutionary modification of
                  phenotypes might be equally dynamic and responsive to
                  embryonic functional interactions.},
  url          = {http://www.jstor.org/stable/2409113},
  urldate      = {2016-02-08}
}

@ARTICLE{Zelditch1987-li,
  title        = {Evaluating Models of Developmental Integration in the
                  Laboratory Rat Using Confirmatory Factor Analysis},
  author       = {Zelditch, Miriam Leah},
  journaltitle = {Syst. Zool.},
  publisher    = {[Oxford University Press, Society of Systematic Biologists,
                  Taylor \& Francis, Ltd.]},
  volume       = {36},
  issue        = {4},
  pages        = {368--380},
  date         = {1987},
  doi          = {10.2307/2413401},
  issn         = {0039-7989},
  abstract     = {This study describes a procedure for constructing and
                  evaluating developmental models by using confirmatory factor
                  analysis which predicts covariation among morphological
                  measures. The principal advantage of confirmatory factor
                  analysis lies in its ability to reject poorly fitting
                  hypotheses in favor of those better able to reconstruct
                  observed variance-covariance structure. Conflicting causal
                  hypotheses of increasing complexity are applied to osteometric
                  measures taken on a sample of one-day-old laboratory rats,
                  then evaluated for their relative ability to reconstruct
                  observed covariance. Models derived from competing hypotheses
                  could not be distinguished. When models are constructed after
                  measurements are chosen, then discrimination between
                  alternatives may require indirect comparisons. In contrast,
                  when hypotheses of integration vary in their predictions and
                  the models differ significantly in fit, then confirmatory
                  factor analysis can be used to decide between conflicting
                  hypotheses.},
  url          = {http://www.jstor.org/stable/2413401},
  urldate      = {2016-02-08}
}

@ARTICLE{Williams1959-gy,
  title        = {Multivariate Methods in Plant Ecology: {I}.
                  Association-Analysis in Plant Communities},
  shorttitle   = {Multivariate Methods in Plant Ecology},
  author       = {Williams, W T and Lambert, J M},
  journaltitle = {J. Ecol.},
  volume       = {47},
  issue        = {1},
  pages        = {83--101},
  date         = {1959},
  doi          = {10.2307/2257249},
  issn         = {0022-0477},
  abstract     = {1. Goodall's method of subdividing a set of sample quadrats
                  into homogeneous groups, in which all species-associations
                  have been made non-significant or indeterminate, is subjected
                  to a theoretical analysis. 2. A new sorting method is
                  described, consisting of hierarchical division on the species
                  with the highest aggregated value of the chosen
                  association-index in the class under study. The properties of
                  suitable indices are briefly considered, but in order to bring
                  this exploratory study within the reach of hand-computation,
                  the index used (Σχ2) was constructed from corrected χ2 values,
                  non-significant and indeterminate values being taken as zero,
                  and ambiguities being resolved in the next highest class in
                  which discrimination is possible. Equal weight is given to
                  positive and negative associations. 3. The statistical
                  efficiency of the method is confirmed by its application to
                  populations from two heathland communities. 4. The nature of
                  the ecological information thus obtained is assessed, and it
                  is concluded that a method of this type is likely to prove a
                  very useful tool in primary survey.},
  url          = {http://www.jstor.org/stable/2257249},
  urldate      = {2016-02-08}
}

@ARTICLE{Sokal1958-ne,
  title        = {A statistical method for evaluating systematic relationships},
  author       = {Sokal, Robert R and Michener, Charles D},
  journaltitle = {University of Kansas Science Bulletin},
  volume       = {38},
  issue        = {2},
  pages        = {1408--1438},
  date         = {1958},
  url          = {http://archive.org/details/cbarchive_33927_astatisticalmethodforevaluatin1902},
  urldate      = {2016-02-08},
  language     = {eng}
}

@ARTICLE{James1990-ss,
  title        = {Multivariate Analysis in Ecology and Systematics: Panacea or
                  Pandora's Box?},
  shorttitle   = {Multivariate Analysis in Ecology and Systematics},
  author       = {James, Frances C and McCulloch, Charles E},
  journaltitle = {Annu. Rev. Ecol. Syst.},
  volume       = {21},
  pages        = {129--166},
  date         = {1990},
  issn         = {0066-4162},
  url          = {http://www.jstor.org/stable/2097021},
  urldate      = {2016-02-08}
}

@ARTICLE{Miles1984-lb,
  title        = {The Correlation Between Ecology and Morphology in Deciduous
                  Forest Passerine Birds},
  author       = {Miles, Donald B and Ricklefs, Robert E},
  journaltitle = {Ecology},
  volume       = {65},
  issue        = {5},
  pages        = {1629--1640},
  date         = {1984},
  doi          = {10.2307/1939141},
  issn         = {0012-9658},
  abstract     = {We investigated the correspondence between feeding behavior
                  and morphology among 19 species of passerine birds in the
                  Hubbard Brook Experimental Forest, New Hampshire, using data
                  in Holmes et al. (1979). Fourteen categories of foraging
                  behavior were ordinated by reciprocal averaging. The first and
                  second derived axes accounted for 61\% of the total variance,
                  and distinguished foraging substrate and maneuver. A
                  morphological space was defined by eight external
                  measurements. The correspondence between the positions of
                  species in spaces defined by reciprocal averaging and
                  morphology was determined by canonical correlation analysis.
                  This analysis revealed two strong correlations: the first
                  (R\textasciicircum2 = 0.94) related substrate utilization to
                  the lengths of the tarsus and midtoe, and the second
                  (R\textasciicircum2 = 0.70) related foraging maneuver to
                  midtoe length. The canonical correlation analysis accounted
                  for 83 and 74\% of the variation on reciprocal averaging axes
                  I and II; of the morphological variables, only tarsus (76\%)
                  and midtoe (64\%) contributed strongly to the correlations.
                  Therefore, although morphology predicts foraging behavior in
                  this data set, considerable morphological variation is not
                  related to the foraging variables that characterize the
                  species' ecological relationships.},
  url          = {http://www.jstor.org/stable/1939141},
  urldate      = {2016-02-08}
}

@ARTICLE{Cramer1979-el,
  title        = {Some symmetric, invariant measures of multivariate association},
  author       = {Cramer, Elliot M and Nicewander, W Alan},
  journaltitle = {Psychometrika},
  volume       = {44},
  issue        = {1},
  pages        = {43--54},
  date         = {1979-03},
  doi          = {10.1007/BF02293783},
  issn         = {0033-3123,1860-0980},
  abstract     = {A distinction is drawn between redundancy measurement and the
                  measurement of multivariate association for two sets of
                  variables. Several measures of multivariate association
                  between two sets of variables are examined. It is shown that
                  all of these measures are generalizations of the (univariate)
                  squared-multiple correlation; all are functions of the
                  canonical correlations, and all are invariant under linear
                  transformations of the original sets of variables. It is
                  further shown that the measures can be considered to be
                  symmetric and are strictly ordered for any two sets of
                  observed variables. It is suggested that measures of
                  multivariate relationship may be used to generalize the
                  concept of test reliability to the case of vector random
                  variables.},
  url          = {http://link.springer.com/article/10.1007/BF02293783},
  urldate      = {2016-02-08},
  language     = {en}
}

@ARTICLE{Cohen1982-jw,
  title        = {Set Correlation As A General Multivariate Data-Analytic Method},
  author       = {Cohen, Jacob},
  journaltitle = {Multivariate Behav. Res.},
  volume       = {17},
  issue        = {3},
  pages        = {301--341},
  date         = {1982-07-01},
  doi          = {10.1207/s15327906mbr1703_2},
  issn         = {0027-3171},
  abstract     = {Set correlation is a multivariate generalization of multiple
                  regression/correlation analysis that features the employment
                  of overall measures of association interpretable as
                  proportions of variance and the use of set-partialled sets of
                  variables, e.g. D·C with B·A. Partialling is a powerful device
                  that may be used for statistical control and for representing
                  non-linear and conditional (interactive) relationships,
                  contrast functions, and the uniqueness of a variable or subset
                  of variables. Generally, it offers a means for specifying
                  functional components of sets. Since information in virtually
                  any form can be represented as a set, partialled if necessary,
                  the extension of partialling to sets of dependent variables
                  makes it possible, within a single framework, to study
                  relationships that are currently handled by diverse methods.
                  Because of its flexibility and generality, beyond its capacity
                  to handle the standard multivariate methods as special cases,
                  set correlation offers some useful novel data-analytic
                  techniques, among which are illustrated a hierarchical
                  analysis of common and unique aspects of a battery,
                  multivariate contrasts among outcomes, the multivariate
                  analysis of partial variance, and contingency table analysis.},
  url          = {http://dx.doi.org/10.1207/s15327906mbr1703_2},
  urldate      = {2016-02-08}
}

@ARTICLE{Hotelling1936-yy,
  title        = {Relations Between Two Sets of Variates},
  author       = {Hotelling, Harold},
  journaltitle = {Biometrika},
  volume       = {28},
  issue        = {3/4},
  pages        = {321--377},
  date         = {1936},
  doi          = {10.2307/2333955},
  issn         = {0006-3444},
  url          = {http://www.jstor.org/stable/2333955},
  urldate      = {2016-02-08}
}

@ARTICLE{Neyman1933-uj,
  title        = {On the Problem of the Most Efficient Tests of Statistical
                  Hypotheses},
  author       = {Neyman, J and Pearson, E S},
  journaltitle = {Philosophical Transactions of the Royal Society of London A:
                  Mathematical, Physical and Engineering Sciences},
  volume       = {231},
  issue        = {694-706},
  pages        = {289--337},
  date         = {1933-01-01},
  doi          = {10.1098/rsta.1933.0009},
  issn         = {1364-503X,1471-2962},
  url          = {http://rsta.royalsocietypublishing.org/content/231/694-706/289},
  urldate      = {2016-02-01},
  language     = {en}
}

@ARTICLE{Jones2009-vg,
  title        = {{PanTHERIA}: a species-level database of life history,
                  ecology, and geography of extant and recently extinct mammals},
  shorttitle   = {PanTHERIA},
  author       = {Jones, Kate E and Bielby, Jon and Cardillo, Marcel and Fritz,
                  Susanne A and O'Dell, Justin and Orme, C David L and Safi,
                  Kamran and Sechrest, Wes and Boakes, Elizabeth H and Carbone,
                  Chris and Connolly, Christina and Cutts, Michael J and Foster,
                  Janine K and Grenyer, Richard and Habib, Michael and Plaster,
                  Christopher A and Price, Samantha A and Rigby, Elizabeth A and
                  Rist, Janna and Teacher, Amber and Bininda-Emonds, Olaf R P
                  and Gittleman, John L and Mace, Georgina M and Purvis, Andy},
  journaltitle = {Ecology},
  volume       = {90},
  issue        = {9},
  pages        = {2648--2648},
  date         = {2009-09-01},
  doi          = {10.1890/08-1494.1},
  issn         = {0012-9658,1939-9170},
  abstract     = {Analyses of life-history, ecological, and geographic trait
                  differences among species, their causes, correlates, and
                  likely consequences are increasingly important for
                  understanding and conserving biodiversity in the face of rapid
                  global change. Assembling multispecies trait data from diverse
                  literature sources into a single comprehensive data set
                  requires detailed consideration of methods to reliably compile
                  data for particular species, and to derive single estimates
                  from multiple sources based on different techniques and
                  definitions. Here we describe PanTHERIA, a species-level data
                  set compiled for analysis of life history, ecology, and
                  geography of all known extant and recently extinct mammals.
                  PanTHERIA is derived from a database capable of holding
                  multiple geo-referenced values for variables within a species
                  containing 100 740 lines of biological data for extant and
                  recently extinct mammalian species, collected over a period of
                  three years by 20 individuals. PanTHERIA also includes spatial
                  databases of mammalian geographic ranges and global climatic
                  and anthropogenic variables. Here we detail how the data
                  fields are extracted and defined for PanTHERIA using a
                  customized data input format (MammalForm); how data were
                  collected from the literature, species names and sources
                  tracked, error-checking and validation procedures applied, and
                  how data were consolidated into species-level values for each
                  variable. Tables of the consolidated species-level values are
                  made available for each of two recent species-level taxonomic
                  classifications of mammals, as well as associated taxonomic
                  synonymy conversion and data-input files. This study provides
                  a useful guide to prospective researchers on how to structure
                  and codify life-history, ecological, geographic, and taxonomic
                  data and methods to extract meaningful species-level traits.
                  It also provides comprehensive information on traits like
                  size, diet, environmental conditions, and ecology to permit
                  macroecological and macroevolutionary analyses of this
                  important clade. The complete data sets corresponding to
                  abstracts published in the Data Papers section of the journal
                  are published electronically in Ecological Archives at
                  〈http://esapubs.org/archive〉. (The accession number for each
                  Data Paper is given directly beneath the title.)},
  url          = {http://onlinelibrary.wiley.com/doi/10.1890/08-1494.1/abstract},
  urldate      = {2016-01-31},
  language     = {en}
}

@ARTICLE{Goodman1994-tz,
  title        = {The Use of Predicted Confidence Intervals When Planning
                  Experiments and the Misuse of Power When Interpreting Results},
  author       = {Goodman, Steven N and Berlin, Jesse A},
  journaltitle = {Ann. Intern. Med.},
  volume       = {121},
  issue        = {3},
  pages        = {200--206},
  date         = {1994-08-01},
  doi          = {10.7326/0003-4819-121-3-199408010-00008},
  issn         = {0003-4819},
  abstract     = {Although there is a growing understanding of the importance of
                  statistical power considerations when designing studies and of
                  the value of confidence intervals when interpreting data,
                  confusion exists about the reverse arrangement:the role of
                  confidence intervals in study design and of power in
                  interpretation. Confidence intervals should play an important
                  role when setting sample size, and power should play no role
                  once the data have been collected, but exactly the opposite
                  procedure is widely practiced. In this commentary, we present
                  the reasons why the calculation of power after a study is over
                  is inappropriate and how confidence intervals can be used
                  during both study design and study interpretation.},
  url          = {http://dx.doi.org/10.7326/0003-4819-121-3-199408010-00008},
  urldate      = {2016-01-25}
}

@ARTICLE{Packard2009-qn,
  title        = {Allometric equations for predicting body mass of dinosaurs},
  author       = {Packard, G C and Boardman, T J and Birchard, G F},
  journaltitle = {J. Zool.},
  volume       = {279},
  issue        = {1},
  pages        = {102--110},
  date         = {2009-09-01},
  doi          = {10.1111/j.1469-7998.2009.00594.x},
  issn         = {0022-5460,1469-7998},
  abstract     = {We use data from the literature to compare two statistical
                  procedures for estimating mass (or size) of quadrupedal
                  dinosaurs and other extraordinarily large animals in extinct
                  lineages. Both methods entail extrapolation from allometric
                  equations fitted to data for a reference group of contemporary
                  animals having a body form similar to that of the dinosaurs.
                  The first method is the familiar one of fitting a straight
                  line to logarithmic transformations, followed by
                  back-transformation of the resulting equation to a
                  two-parameter power function in the arithmetic scale. The
                  second procedure entails fitting a two-parameter power
                  function directly to arithmetic data for the extant forms by
                  nonlinear regression. In the example presented here, the
                  summed circumferences for humerus plus femur for 33 species of
                  quadrupedal mammals was the predictor variable in the
                  reference sample and body mass was the response variable. The
                  allometric equation obtained by back-transformation from
                  logarithms was not a good fit to the largest species in the
                  reference sample and presumably led to grossly inaccurate
                  estimates for body mass of several large dinosaurs. In
                  contrast, the allometric equation obtained by nonlinear
                  regression described data in the reference sample quite well,
                  and it presumably resulted in better estimates for body mass
                  of the dinosaurs. The problem with the traditional analysis
                  can be traced to change in the relationship between predictor
                  and response variables attending transformation, thereby
                  causing measurements for large animals not to be weighted
                  appropriately in fitting models by least squares regression.
                  Extrapolations from statistical models obtained by
                  back-transformation from lines fitted to logarithms are
                  unlikely to yield reliable predictions for body size in
                  extinct animals. Numerous reports on the biology of dinosaurs,
                  including recent studies of growth, may need to be
                  reconsidered in light of our findings.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/j.1469-7998.2009.00594.x/abstract},
  urldate      = {2016-01-24},
  language     = {en}
}

@ARTICLE{Ellison2010-dr,
  title        = {Paths to statistical fluency for ecologists},
  author       = {Ellison, Aaron M and Dennis, Brian},
  journaltitle = {Front. Ecol. Environ.},
  volume       = {8},
  issue        = {7},
  pages        = {362--370},
  date         = {2010-09-01},
  doi          = {10.1890/080209},
  issn         = {1540-9295,1540-9309},
  abstract     = {Twenty-first-century ecology requires statistical fluency.
                  Ecological observations now include diverse types of data
                  collected across spatial scales ranging from the microscopic
                  to the global, and at temporal scales ranging from nanoseconds
                  to millennia. Ecological experiments now use designs that
                  account for multiple linear and non-linear interactions, and
                  ecological theories incorporate both predictable and random
                  processes. Ecological debates often revolve around issues of
                  fundamental statistical theory and require the development of
                  novel statistical methods. In short, if we want to test
                  hypotheses, model data, and forecast future environmental
                  conditions in the 21st century, we must move beyond basic
                  statistical literacy and attain statistical fluency: the
                  ability to apply statistical principles and adapt statistical
                  methods to non-standard questions. Our prescription for
                  attaining statistical fluency includes two semesters of
                  standard calculus, calculus-based statistics courses, and,
                  most importantly, a commitment to using calculus and
                  post-calculus statistics in ecology and environmental science
                  courses.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1890/080209/abstract},
  urldate      = {2016-01-24},
  language     = {en}
}

@ARTICLE{Packard2008-ax,
  title        = {Model selection and logarithmic transformation in allometric
                  analysis},
  author       = {Packard, Gary C and Boardman, Thomas J},
  journaltitle = {Physiol. Biochem. Zool.},
  volume       = {81},
  issue        = {4},
  pages        = {496--507},
  date         = {2008-07},
  doi          = {10.1086/589110},
  pmid         = {18513152},
  issn         = {1522-2152,1537-5293},
  abstract     = {The standard approach to most allometric research is to gather
                  data on a biological function and a measure of body size,
                  convert the data to logarithms, display the new values in a
                  bivariate plot, and then fit a straight line to the
                  transformations by the method of least squares. The slope of
                  the fitted line provides an estimate for the allometric (or
                  scaling) exponent, which often is interpreted in the context
                  of underlying principles of structural and functional design.
                  However, interpretations of this sort are based on the
                  implicit assumption that the original data conform with a
                  power function having an intercept of 0 on a plot with
                  arithmetic coordinates. Whenever this assumption is not
                  satisfied, the resulting estimate for the allometric exponent
                  may be seriously biased and misleading. The problem of
                  identifying an appropriate function is compounded by the
                  logarithmic transformations, which alter the relationship
                  between the original variables and frequently conceal the
                  presence of outliers having an undue influence on properties
                  of the fitted equation, including the estimate for the
                  allometric exponent. Much of the current controversy in
                  allometric research probably can be traced to substantive
                  biases introduced by investigators who followed standard
                  practice. We illustrate such biases with examples taken from
                  the literature and outline a general methodology by which the
                  biases can be minimized in future research.},
  url          = {http://dx.doi.org/10.1086/589110},
  urldate      = {2016-01-24},
  language     = {en}
}

@ARTICLE{Packard2008-rg,
  title        = {Traditional allometric analysis fails to provide a valid
                  predictive model for mammalian metabolic rates},
  author       = {Packard, Gary C and Birchard, Geoffrey F},
  journaltitle = {J. Exp. Biol.},
  volume       = {211},
  issue        = {22},
  pages        = {3581--3587},
  date         = {2008-11-15},
  doi          = {10.1242/jeb.023317},
  pmid         = {18978222},
  issn         = {0022-0949,1477-9145},
  url          = {http://jeb.biologists.org/content/211/22/3581},
  urldate      = {2016-01-24},
  language     = {en}
}

@ARTICLE{Xiao2011-hk,
  title        = {On the use of log-transformation vs. nonlinear regression for
                  analyzing biological power laws},
  author       = {Xiao, Xiao and White, Ethan P and Hooten, Mevin B and Durham,
                  Susan L},
  journaltitle = {Ecology},
  volume       = {92},
  issue        = {10},
  pages        = {1887--1894},
  date         = {2011-10-01},
  doi          = {10.1890/11-0538.1},
  issn         = {0012-9658,1939-9170},
  abstract     = {Power-law relationships are among the most well-studied
                  functional relationships in biology. Recently the common
                  practice of fitting power laws using linear regression (LR) on
                  log-transformed data has been criticized, calling into
                  question the conclusions of hundreds of studies. It has been
                  suggested that nonlinear regression (NLR) is preferable, but
                  no rigorous comparison of these two methods has been
                  conducted. Using Monte Carlo simulations, we demonstrate that
                  the error distribution determines which method performs
                  better, with NLR better characterizing data with additive,
                  homoscedastic, normal error and LR better characterizing data
                  with multiplicative, heteroscedastic, lognormal error.
                  Analysis of 471 biological power laws shows that both forms of
                  error occur in nature. While previous analyses based on
                  log-transformation appear to be generally valid, future
                  analyses should choose methods based on a combination of
                  biological plausibility and analysis of the error
                  distribution. We provide detailed guidelines and associated
                  computer code for doing so, including a model averaging
                  approach for cases where the error structure is uncertain.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1890/11-0538.1/abstract},
  urldate      = {2016-01-24},
  language     = {en}
}

@ARTICLE{Ballantyne2013-nj,
  title        = {Evaluating model fit to determine if logarithmic
                  transformations are necessary in allometry: A comment on the
                  exchange between Packard (2009) and Kerkhoff and Enquist
                  (2009)},
  shorttitle   = {Evaluating model fit to determine if logarithmic
                  transformations are necessary in allometry},
  author       = {Ballantyne, IV, Ford},
  journaltitle = {J. Theor. Biol.},
  volume       = {317},
  pages        = {418--421},
  date         = {2013-01-21},
  doi          = {10.1016/j.jtbi.2012.09.035},
  issn         = {0022-5193},
  url          = {http://www.sciencedirect.com/science/article/pii/S0022519312005139},
  urldate      = {2016-01-24}
}

@ARTICLE{Kerkhoff2009-re,
  title        = {Multiplicative by nature: Why logarithmic transformation is
                  necessary in allometry},
  shorttitle   = {Multiplicative by nature},
  author       = {Kerkhoff, Andrew J and Enquist, Brian J},
  journaltitle = {J. Theor. Biol.},
  volume       = {257},
  issue        = {3},
  pages        = {519--521},
  date         = {2009-04-07},
  doi          = {10.1016/j.jtbi.2008.12.026},
  issn         = {0022-5193},
  url          = {http://www.sciencedirect.com/science/article/pii/S0022519308006681},
  urldate      = {2016-01-24}
}

@ARTICLE{Packard2009-wc,
  title        = {On the use of logarithmic transformations in allometric
                  analyses},
  author       = {Packard, Gary C},
  journaltitle = {J. Theor. Biol.},
  volume       = {257},
  issue        = {3},
  pages        = {515--518},
  date         = {2009-04-07},
  doi          = {10.1016/j.jtbi.2008.10.016},
  issn         = {0022-5193},
  url          = {http://www.sciencedirect.com/science/article/pii/S0022519308005468},
  urldate      = {2016-01-24}
}

@ARTICLE{Lindley1976-gh,
  title        = {Inference for a Bernoulli Process (A Bayesian View)},
  author       = {Lindley, D V and Phillips, L D},
  journaltitle = {Am. Stat.},
  volume       = {30},
  issue        = {3},
  pages        = {112},
  date         = {1976},
  doi          = {10.2307/2683855},
  issn         = {0003-1305},
  url          = {http://www.jstor.org/stable/2683855?origin=crossref},
  urldate      = {2016-01-23}
}

@ARTICLE{Matyas2015-xk,
  title        = {Harnessing the power of an online teaching community: connect,
                  share, and collaborate},
  shorttitle   = {Harnessing the power of an online teaching community},
  author       = {Matyas, Marsha Lakes and Silverthorn, Dee U},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {39},
  issue        = {4},
  pages        = {272--277},
  date         = {2015-12-01},
  doi          = {10.1152/advan.00093.2015},
  pmid         = {26628648},
  issn         = {1043-4046,1522-1229},
  url          = {http://advan.physiology.org/content/39/4/272},
  urldate      = {2016-01-23},
  language     = {en}
}

@ARTICLE{Curran-Everett2015-rz,
  title        = {Explorations in statistics: the analysis of change},
  shorttitle   = {Explorations in statistics},
  author       = {Curran-Everett, Douglas and Williams, Calvin L},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {39},
  issue        = {2},
  pages        = {49--54},
  date         = {2015-06-01},
  doi          = {10.1152/advan.00018.2015},
  pmid         = {26031718},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This tenth installment of Explorations in Statistics
                  explores the analysis of a potential change in some
                  physiological response. As researchers, we often express
                  absolute change as percent change so we can account for
                  different initial values of the response. But this creates a
                  problem: percent change is really just a ratio, and a ratio is
                  infamous for its ability to mislead. This means we may fail to
                  find a group difference that does exist, or we may find a
                  group difference that does not exist. What kind of an approach
                  to science is that? In contrast, analysis of covariance is
                  versatile: it can accommodate an analysis of the relationship
                  between absolute change and initial value when percent change
                  is useless.},
  url          = {http://advan.physiology.org/content/39/2/49},
  urldate      = {2016-01-23},
  language     = {en}
}

@ARTICLE{Curran-Everett2006-ox,
  title        = {A classic learning opportunity from Fenn, Rahn, and Otis
                  (1946): the alveolar gas equation},
  shorttitle   = {A classic learning opportunity from Fenn, Rahn, and Otis
                  (1946)},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {30},
  issue        = {2},
  pages        = {58--62},
  date         = {2006-06-01},
  doi          = {10.1152/advan.00076.2005},
  pmid         = {16709734},
  issn         = {1043-4046,1522-1229},
  abstract     = {The alveolar gas equation, the focus of a classic paper by
                  Fenn, Rahn, and Otis, provides a framework for understanding
                  the mechanisms involved in pulmonary gas exchange as well as
                  the limits of human performance. The classic 1946 paper by
                  Fehn, Rahn, and Otis gives your students an opportunity to
                  learn about the alveolar gas equation from the physiologists
                  who pioneered it and demonstrates that mathematics and data
                  graphics are fundamental tools with which to learn respiratory
                  physiology. In this essay, I outline avenues of discovery by
                  which your students can explore the alveolar gas equation.
                  Meaningful learning stems from inspiration: to learn, you must
                  be inspired to learn. If anyone can inspire learning in
                  respiratory physiology, it is Wallace Fenn, Hermann Rahn, and
                  Arthur Otis.},
  url          = {http://advan.physiology.org/content/30/2/58},
  urldate      = {2016-01-23},
  language     = {en}
}

@ARTICLE{Curran-Everett1995-yd,
  title        = {Hearts, lungs, and children: a physiologist returns to
                  kindergarten},
  shorttitle   = {Hearts, lungs, and children},
  author       = {Curran-Everett, D},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {269},
  issue        = {6},
  pages        = {S32},
  date         = {1995-12-01},
  pmid         = {8554092},
  issn         = {1043-4046,1522-1229},
  url          = {http://advan.physiology.org/content/269/6/S32},
  urldate      = {2016-01-23},
  language     = {en}
}

@ARTICLE{Blischak2016-kd,
  title        = {A Quick Introduction to Version Control with Git and {GitHub}},
  author       = {Blischak, John D and Davenport, Emily R and Wilson, Greg},
  journaltitle = {PLoS Comput. Biol.},
  volume       = {12},
  issue        = {1},
  pages        = {e1004668},
  date         = {2016-01},
  doi          = {10.1371/journal.pcbi.1004668},
  pmc          = {PMC4718703},
  pmid         = {26785377},
  issn         = {1553-734X,1553-7358},
  url          = {http://dx.doi.org/10.1371/journal.pcbi.1004668},
  urldate      = {2016-01-20},
  language     = {en}
}

@ARTICLE{Kruschke2010-cg,
  title        = {Bayesian data analysis},
  author       = {Kruschke, John K},
  journaltitle = {Wiley Interdiscip. Rev. Cogn. Sci.},
  volume       = {1},
  issue        = {5},
  pages        = {658--676},
  date         = {2010},
  issn         = {1939-5078},
  url          = {http://onlinelibrary.wiley.com/doi/10.1002/wcs.72/pdf},
  urldate      = {2016-01-19}
}

@ARTICLE{Kruschke2011-jx,
  title        = {Bayesian assessment of null values via parameter estimation
                  and model comparison},
  author       = {Kruschke, John K},
  journaltitle = {Perspect. Psychol. Sci.},
  volume       = {6},
  issue        = {3},
  pages        = {299},
  date         = {2011},
  issn         = {1745-6916},
  url          = {http://pps.sagepub.com/content/6/3/299.short},
  urldate      = {2016-01-19}
}

@ARTICLE{Kruschke2013-au,
  title        = {Bayesian estimation supersedes the t test},
  author       = {Kruschke, John K},
  journaltitle = {J. Exp. Psychol. Gen.},
  volume       = {142},
  issue        = {2},
  pages        = {573--603},
  date         = {2013},
  issn         = {0096-3445},
  url          = {http://psycnet.apa.org/journals/xge/142/2/573/},
  urldate      = {2016-01-19}
}

@ARTICLE{Shalizi2009-fz,
  title        = {Dynamics of Bayesian updating with dependent data and
                  misspecified models},
  author       = {Shalizi, Cosma Rohilla},
  journaltitle = {Electron. J. Stat.},
  volume       = {3},
  pages        = {1039--1074},
  date         = {2009},
  doi          = {10.1214/09-EJS485},
  issn         = {1935-7524},
  abstract     = {Much is now known about the consistency of Bayesian updating
                  on infinite-dimensional parameter spaces with independent or
                  Markovian data. Necessary conditions for consistency include
                  the prior putting enough weight on the correct neighborhoods
                  of the data-generating distribution; various sufficient
                  conditions further restrict the prior in ways analogous to
                  capacity control in frequentist nonparametrics. The
                  asymptotics of Bayesian updating with mis-specified models or
                  priors, or non-Markovian data, are far less well explored.
                  Here I establish sufficient conditions for posterior
                  convergence when all hypotheses are wrong, and the data have
                  complex dependencies. The main dynamical assumption is the
                  asymptotic equipartition (Shannon-McMillan-Breiman) property
                  of information theory. This, along with Egorov’s Theorem on
                  uniform convergence, lets me build a sieve-like structure for
                  the prior. The main statistical assumption, also a form of
                  capacity control, concerns the compatibility of the prior and
                  the data-generating process, controlling the fluctuations in
                  the log-likelihood when averaged over the sieve-like sets. In
                  addition to posterior convergence, I derive a kind of large
                  deviations principle for the posterior measure, extending in
                  some cases to rates of convergence, and discuss the advantages
                  of predicting using a combination of models known to be wrong.
                  An appendix sketches connections between these results and the
                  replicator dynamics of evolutionary theory.},
  url          = {http://projecteuclid.org/euclid.ejs/1256822130},
  urldate      = {2016-01-18},
  language     = {EN}
}

@ARTICLE{Langsrud2003-as,
  title        = {{ANOVA} for unbalanced data: Use Type {II} instead of Type
                  {III} sums of squares},
  shorttitle   = {ANOVA for unbalanced data},
  author       = {Langsrud, Øyvind},
  journaltitle = {Stat. Comput.},
  volume       = {13},
  issue        = {2},
  pages        = {163--167},
  date         = {2003-04-01},
  doi          = {10.1023/A:1023260610025},
  issn         = {0960-3174},
  abstract     = {Methods for analyzing unbalanced factorial designs can be
                  traced back to Yates (1934). Today, most major statistical
                  programs perform, by default, unbalanced ANOVA based on Type
                  III sums of squares (Yates's weighted squares of means). As
                  criticized by Nelder and Lane (1995), this analysis is founded
                  on unrealistic models—models with interactions, but without
                  all corresponding main effects. The Type II analysis (Yates's
                  method of fitting constants) is usually not preferred because
                  of the underlying assumption of no interactions. This argument
                  is, however, also founded on unrealistic models. Furthermore,
                  by considering the power of the two methods, it is clear that
                  Type II is preferable.},
  url          = {https://doi.org/10.1023/A:1023260610025},
  urldate      = {2016-01-18},
  language     = {en}
}

@ARTICLE{Bedeian1994-ha,
  title        = {Simple Question, Not So Simple Answer: Interpreting
                  Interaction Terms in Moderated Multiple Regression},
  shorttitle   = {Simple Question, Not So Simple Answer},
  author       = {Bedeian, Arthur G and Mossholder, Kevin W},
  journaltitle = {J. Manage.},
  volume       = {20},
  issue        = {1},
  pages        = {159--165},
  date         = {1994-04-01},
  doi          = {10.1177/014920639402000108},
  issn         = {0149-2063,1557-1211},
  abstract     = {The appropriate interpretation of interaction terms in studies
                  employing moderated multiple regression (MMR) analysis is
                  considered. It is argued that given a theory-based, a priori
                  hypothesis, an MMR analysis is analogous to a planned
                  statistical comparison and, thus, a significant overall F
                  value is not a prerequisite for interpreting a significant
                  interaction term.},
  url          = {http://jom.sagepub.com/content/20/1/159},
  urldate      = {2016-01-18},
  language     = {en}
}

@ARTICLE{Cortina1993-vh,
  title        = {Interaction, Nonlinearity, and Multicollinearity: implications
                  for Multiple Regression},
  shorttitle   = {Interaction, Nonlinearity, and Multicollinearity},
  author       = {Cortina, Jose M},
  journaltitle = {J. Manage.},
  volume       = {19},
  issue        = {4},
  pages        = {915--922},
  date         = {1993-08-01},
  doi          = {10.1177/014920639301900411},
  issn         = {0149-2063,1557-1211},
  abstract     = {Moderated Hierarchical Multiple Regression (MHMR) is typically
                  used to test for the presence of interactions. When an
                  interaction term is composed of correlated variables,
                  linearity and additivity become confounded. The result of this
                  confounding is that an interaction term in MHMR may be
                  statistically significant only because of its overlap with
                  unmeasured nonlinear terms. I recommend that squared terms be
                  used as covariates in such situations and show that the
                  resulting loss of power with respect to the test of
                  significance for the interaction term is limited to that
                  associated with the loss of degrees of freedom and is
                  therefore negligible if it exists at all.},
  url          = {http://jom.sagepub.com/content/19/4/915},
  urldate      = {2016-01-18},
  language     = {en}
}

@ARTICLE{Watson2016-zr,
  title        = {How Can Evolution Learn?},
  author       = {Watson, Richard A and Szathmáry, Eörs},
  journaltitle = {Trends Ecol. Evol.},
  volume       = {31},
  issue        = {2},
  pages        = {147--157},
  date         = {2016-02},
  doi          = {10.1016/j.tree.2015.11.009},
  pmid         = {26705684},
  issn         = {0169-5347,1872-8383},
  abstract     = {The theory of evolution links random variation and selection
                  to incremental adaptation. In a different intellectual domain,
                  learning theory links incremental adaptation (e.g., from
                  positive and/or negative reinforcement) to intelligent
                  behaviour. Specifically, learning theory explains how
                  incremental adaptation can acquire knowledge from past
                  experience and use it to direct future behaviours toward
                  favourable outcomes. Until recently such cognitive learning
                  seemed irrelevant to the 'uninformed' process of evolution. In
                  our opinion, however, new results formally linking
                  evolutionary processes to the principles of learning might
                  provide solutions to several evolutionary puzzles - the
                  evolution of evolvability, the evolution of ecological
                  organisation, and evolutionary transitions in individuality.
                  If so, the ability for evolution to learn might explain how it
                  produces such apparently intelligent designs.},
  url          = {http://dx.doi.org/10.1016/j.tree.2015.11.009},
  urldate      = {2016-01-18},
  language     = {en}
}

@ARTICLE{Brambor2006-si,
  title        = {Understanding Interaction Models: Improving Empirical Analyses},
  shorttitle   = {Understanding Interaction Models},
  author       = {Brambor, Thomas and Clark, William Roberts and Golder, Matt},
  journaltitle = {Polit. Anal.},
  volume       = {14},
  issue        = {1},
  pages        = {63--82},
  date         = {2006-12-21},
  doi          = {10.1093/pan/mpi014},
  issn         = {1047-1987,1476-4989},
  abstract     = {Multiplicative interaction models are common in the
                  quantitative political science literature. This is so for good
                  reason. Institutional arguments frequently imply that the
                  relationship between political inputs and outcomes varies
                  depending on the institutional context. Models of strategic
                  interaction typically produce conditional hypotheses as well.
                  Although conditional hypotheses are ubiquitous in political
                  science and multiplicative interaction models have been found
                  to capture their intuition quite well, a survey of the top
                  three political science journals from 1998 to 2002 suggests
                  that the execution of these models is often flawed and
                  inferential errors are common. We believe that considerable
                  progress in our understanding of the political world can occur
                  if scholars follow the simple checklist of dos and don'ts for
                  using multiplicative interaction models presented in this
                  article. Only 10\% of the articles in our survey followed the
                  checklist.},
  url          = {http://pan.oxfordjournals.org/content/14/1/63},
  urldate      = {2016-01-18},
  language     = {en}
}

@ARTICLE{Braumoeller2004-gk,
  title        = {Hypothesis Testing and Multiplicative Interaction Terms},
  author       = {Braumoeller, Bear F},
  journaltitle = {Int. Organ.},
  volume       = {58},
  issue        = {04},
  pages        = {807--820},
  date         = {2004-10},
  doi          = {10.1017/S0020818304040251},
  issn         = {0020-8183,1531-5088},
  abstract     = {When a statistical equation incorporates a multiplicative term
                  in an attempt to model interaction effects, the statistical
                  significance of the lower-order coefficients is largely
                  useless for the typical purposes of hypothesis testing. This
                  fact remains largely unappreciated in political science,
                  however. This brief article explains this point, provides
                  examples, and offers some suggestions for more meaningful
                  interpretation.I am grateful to Tim McDaniel, Anne Sartori,
                  and Beth Simmons for comments on a previous draft.},
  url          = {http://journals.cambridge.org/article_S0020818304040251},
  urldate      = {2016-01-18}
}

@ARTICLE{Leek2015-xj,
  title        = {{P} values are just the tip of the iceberg},
  shorttitle   = {Statistics},
  author       = {Leek, Jeffrey T and Peng, Roger D},
  journaltitle = {Nature},
  volume       = {520},
  issue        = {7549},
  pages        = {612--612},
  date         = {2015},
  issn         = {0028-0836},
  url          = {http://www.researchgate.net/profile/Carlos_Polanco/publication/275642181_Scientific_conjecture_versus_statistical_conjecture_a_same_level_Letter/links/554137b40cf2322227315533.pdf},
  urldate      = {2016-01-17}
}

@ARTICLE{Nuzzo2014-ey,
  title        = {Scientific method: statistical errors},
  author       = {Nuzzo, Regina},
  journaltitle = {Nature},
  volume       = {506},
  issue        = {7487},
  pages        = {150--152},
  date         = {2014-02-13},
  doi          = {10.1038/506150a},
  pmid         = {24522584},
  issn         = {0028-0836,1476-4687},
  url          = {http://dx.doi.org/10.1038/506150a},
  urldate      = {2016-01-17},
  language     = {en}
}

@ARTICLE{Smith2002-ak,
  title        = {The high cost of complexity in experimental design and data
                  analysis: type {I} and type {II} error rates in multiway
                  {ANOVA}},
  shorttitle   = {The High Cost of Complexity in Experimental Design and Data
                  Analysis},
  author       = {Smith, Rachel A and Levine, Timothy R and Lachlan, Kenneth A
                  and Fediuk, Thomas A},
  journaltitle = {Hum. Commun. Res.},
  volume       = {28},
  issue        = {4},
  pages        = {515--530},
  date         = {2002-10-01},
  doi          = {10.1111/j.1468-2958.2002.tb00821.x},
  issn         = {0360-3989,1468-2958},
  abstract     = {The availability of statistical software packages has led to a
                  sharp increase in use of complex research designs and complex
                  statistical analyses in communication research. An informal
                  examination of studies from 2 leading communication journals
                  suggests that the analysis of variance (ANOVA) is often the
                  statistic of choice, and a substantial proportion of published
                  research reports using ANOVA employ complex (k ≥ 3) factorial
                  designs, often involving multiple dependent variables. This
                  article reports a series of Monte Carlo simulations which
                  demonstrate that this complexity may come at a heavier cost
                  than many communication researchers realize. As frequently
                  used, complex factorial ANOVA yield Type I and Type II error
                  rates that many communication scholars would likely consider
                  unacceptable. Consequently, quality of statistical inference
                  in many studies is highly suspect. Communication researchers
                  are warned about problems associated with design and
                  statistical complexity and solutions are suggested.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/j.1468-2958.2002.tb00821.x/abstract},
  urldate      = {2016-01-17},
  language     = {en}
}

@BOOK{Shalizi2013-be,
  title   = {Advanced data analysis from an elementary point of view},
  author  = {Shalizi, Cosma Rohilla},
  date    = {2013},
  url     = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.371.4613&rep=rep1&type=pdf},
  urldate = {2016-01-10}
}

@ARTICLE{Khabbazian2016-zn,
  title        = {Fast and accurate detection of evolutionary shifts in
                  Ornstein-Uhlenbeck models},
  author       = {Khabbazian, Mohammad and Kriebel, Ricardo and Rohe, Karl and
                  Ané, Cécile},
  journaltitle = {Methods Ecol. Evol.},
  date         = {2016-01-01},
  doi          = {10.1111/2041-210X.12534},
  issn         = {2041-210X},
  abstract     = {The detection of evolutionary shifts in trait evolution from
                  extant taxa is motivated by the study of convergent evolution,
                  or to correlate shifts in traits with habitat changes or with
                  changes in other phenotypes. We propose here a phylogenetic
                  lasso method to study trait evolution from comparative data
                  and detect past changes in the expected mean trait values. We
                  use the Ornstein-Uhlenbeck process, which can model a changing
                  adaptive landscape over time and over lineages. Our method is
                  very fast, running in minutes for hundreds of species, and can
                  handle multiple traits. We also propose a phylogenetic
                  Bayesian information criterion (pBIC) that accounts for the
                  phylogenetic correlation between species, as well as for the
                  complexity of estimating an unknown number of shifts at
                  unknown locations in the phylogeny. This criterion does not
                  suffer model overfitting and has high precision, so it offers
                  a conservative alternative to other information criteria. Our
                  re-analysis of Anolis lizard data suggests a more conservative
                  scenario of morphological adaptation and convergence than
                  previously proposed. Software is available on GitHub. This
                  article is protected by copyright. All rights reserved.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12534/abstract},
  urldate      = {2016-01-07},
  language     = {en}
}

@ARTICLE{Fleiss1971-pa,
  title        = {Measuring nominal scale agreement among many raters},
  author       = {Fleiss, Joseph L},
  journaltitle = {Psychol. Bull.},
  volume       = {76},
  issue        = {5},
  pages        = {378--382},
  date         = {1971},
  doi          = {10.1037/h0031619},
  issn         = {0033-2909},
  abstract     = {Introduced the statistic kappa to measure nominal scale
                  agreement between a fixed pair of raters. Kappa was
                  generalized to the case where each of a sample of 30 patients
                  was rated on a nominal scale by the same number of
                  psychiatrist raters (n = 6), but where the raters rating 1 s
                  were not necessarily the same as those rating another. Large
                  sample standard errors were derived.},
  url          = {http://dx.doi.org/10.1037/h0031619}
}

@ARTICLE{Cohen1960-kq,
  title        = {A Coefficient of Agreement for Nominal Scales},
  author       = {Cohen, Jacob},
  journaltitle = {Educ. Psychol. Meas.},
  volume       = {20},
  issue        = {1},
  pages        = {37--46},
  date         = {1960-04-01},
  doi          = {10.1177/001316446002000104},
  issn         = {0013-1644,1552-3888},
  url          = {http://epm.sagepub.com/content/20/1/37},
  urldate      = {2016-01-06},
  language     = {en}
}

@BOOK{Kaplan2009-zu,
  title      = {Statistical modeling: a fresh approach},
  shorttitle = {Statistical modeling},
  author     = {Kaplan, Daniel},
  date       = {2009},
  isbn       = {9781448642397,9781448642397},
  language   = {English}
}

@BOOK{Garfunkel1986-vv,
  title     = {Statistics overview},
  author    = {Garfunkel, Solomon A and {Consortium for Mathematics and Its
               Applications (U.S.)} and {Annenberg/CPB}},
  publisher = {Annenberg/CPB},
  location  = {S. Burlington, Vt.},
  date      = {1986},
  abstract  = {Program 6 moves from baseball scores and roulette odds to
               national unemployment figures and quality control testing, to
               show that statistics help us to understand information and make
               better decisions. This overview introduces the subject, featuring
               professionals in labor statistics and medicine who use
               statistical methods to determine probable outcomes in their
               fields.},
  url       = {http://www.learner.org/resources/series82.html},
  urldate   = {2015-12-13},
  language  = {Closed captioned.}
}

@MISC{Amabile1989-pf,
  title     = {Against all odds inside statistics},
  author    = {Amabile, Teresa},
  publisher = {Annenberg/CPB Collection; Intellimation [distributor]},
  date      = {1989}
}

@BOOK{Utts2005-mg,
  title     = {Seeing through statistics},
  author    = {Utts, Jessica M},
  publisher = {Thomson, Brooks/Cole},
  location  = {Belmont, CA},
  date      = {2005},
  isbn      = {9780534394028,9780534394028},
  language  = {English}
}

@ARTICLE{Anscombe1973-kw,
  title        = {Graphs in statistical analysis},
  author       = {Anscombe, F J},
  journaltitle = {Am. Stat.},
  volume       = {27},
  issue        = {1},
  pages        = {17--21},
  date         = {1973-02-01},
  doi          = {10.1080/00031305.1973.10478966},
  issn         = {0003-1305},
  url          = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1973.10478966},
  urldate      = {2015-12-09}
}

@ARTICLE{Wilson2014-cg,
  title        = {Best practices for scientific computing},
  author       = {Wilson, Greg and Aruliah, D A and Brown, C Titus and Chue
                  Hong, Neil P and Davis, Matt and Guy, Richard T and Haddock,
                  Steven H D and Huff, Kathryn D and Mitchell, Ian M and
                  Plumbley, Mark D and Waugh, Ben and White, Ethan P and Wilson,
                  Paul},
  journaltitle = {PLoS Biol.},
  volume       = {12},
  issue        = {1},
  pages        = {e1001745},
  date         = {2014-01-07},
  doi          = {10.1371/journal.pbio.1001745},
  issn         = {1544-9173},
  abstract     = {We describe a set of best practices for scientific software
                  development, based on research and experience, that will
                  improve scientists' productivity and the reliability of their
                  software.},
  url          = {http://dx.doi.org/10.1371/journal.pbio.1001745},
  urldate      = {2015-12-08}
}

@ARTICLE{White2013-oq,
  title        = {Nine simple ways to make it easier to (re)use your data},
  author       = {White, Ethan and Baldridge, Elita and Brym, Zachary and Locey,
                  Kenneth and McGlinn, Daniel and Supp, Sarah},
  journaltitle = {Ideas Ecol. Evol.},
  volume       = {6},
  issue        = {2},
  date         = {2013},
  doi          = {10.4033/iee.2013.6b.6.f},
  issn         = {1918-3178},
  url          = {http://library.queensu.ca/ojs/index.php/IEE/article/view/4608},
  urldate      = {2015-10-20}
}

@ARTICLE{Ram2013-is,
  title        = {Git can facilitate greater reproducibility and increased
                  transparency in science},
  author       = {Ram, Karthik},
  journaltitle = {Source Code Biol. Med.},
  volume       = {8},
  issue        = {1},
  pages        = {7},
  date         = {2013-02-28},
  doi          = {10.1186/1751-0473-8-7},
  issn         = {1751-0473},
  abstract     = {Reproducibility is the hallmark of good science. Maintaining a
                  high degree of transparency in scientific reporting is
                  essential not just for gaining trust and credibility within
                  the scientific community but also for facilitating the
                  development of new ideas. Sharing data and computer code
                  associated with publications is becoming increasingly common,
                  motivated partly in response to data deposition requirements
                  from journals and mandates from funders. Despite this increase
                  in transparency, it is still difficult to reproduce or build
                  upon the findings of most scientific publications without
                  access to a more complete workflow.},
  url          = {http://www.scfbm.org/content/8/1/7/abstract},
  urldate      = {2015-09-26},
  language     = {en}
}

@ARTICLE{Crowther2015-wo,
  title        = {Reply to Veresoglou: Overdependence on "significance" testing
                  in biology},
  shorttitle   = {Reply to Veresoglou},
  author       = {Crowther, Thomas W and Maynard, Daniel S and Thomas, Stephen M
                  and Baldrian, Petr and Covey, Kristofer and Frey, Serita D and
                  Diepen, Linda T A van and Bradford, Mark A},
  journaltitle = {Proc. Natl. Acad. Sci. U. S. A.},
  volume       = {112},
  issue        = {37},
  pages        = {E5114--E5114},
  date         = {2015-09-15},
  doi          = {10.1073/pnas.1513283112},
  pmid         = {26305960},
  issn         = {0027-8424,1091-6490},
  url          = {http://www.pnas.org/content/112/37/E5114},
  urldate      = {2015-09-16},
  language     = {en}
}

@ARTICLE{Veresoglou2015-vv,
  title        = {{P} hacking in biology: An open secret},
  shorttitle   = {P hacking in biology},
  author       = {Veresoglou, Stavros D},
  journaltitle = {Proc. Natl. Acad. Sci. U. S. A.},
  volume       = {112},
  issue        = {37},
  pages        = {E5112--E5113},
  date         = {2015-09-15},
  doi          = {10.1073/pnas.1512689112},
  pmid         = {26305959},
  issn         = {0027-8424,1091-6490},
  url          = {http://www.pnas.org/content/112/37/E5112},
  urldate      = {2015-09-16},
  language     = {en}
}

@ARTICLE{Denton2015-jh,
  title        = {A new phylogenetic test for comparing multiple
                  high-dimensional evolutionary rates suggests interplay of
                  evolutionary rates and modularity in lanternfishes
                  (Myctophiformes; Myctophidae)},
  author       = {Denton, John S S and Adams, Dean C},
  journaltitle = {Evolution},
  volume       = {69},
  issue        = {9},
  pages        = {2425--2440},
  date         = {2015-09-01},
  doi          = {10.1111/evo.12743},
  issn         = {0014-3820,1558-5646},
  abstract     = {The interplay between evolutionary rates and modularity
                  influences the evolution of organismal body plans by both
                  promoting and constraining the magnitude and direction of
                  trait response to ecological conditions. However, few studies
                  have examined whether the best-fit hypothesis of modularity is
                  the same as the shape subset with the greatest difference in
                  evolutionary rate. Here, we develop a new phylogenetic
                  comparative method for comparing evolutionary rates among
                  high-dimensional traits, and apply this method to analyze body
                  shape evolution in bioluminescent lanternfishes. We frame the
                  study of evolutionary rates and modularity through analysis of
                  three hypotheses derived from the literature on fish
                  development, biomechanics, and bioluminescent communication.
                  We show that a development-informed partitioning of shape
                  exhibits the greatest evolutionary rate differences among
                  modules, but that a hydrodynamically informed partitioning is
                  the best-fit modularity hypothesis. Furthermore, we show that
                  bioluminescent lateral photophores evolve at a similar rate
                  as, and are strongly integrated with, body shape in
                  lanternfishes. These results suggest that overlapping
                  life-history constraints on development and movement define
                  axes of body shape evolution in lanternfishes, and that the
                  positions of their lateral photophore complexes are likely a
                  passive outcome of the interaction of these ecological
                  pressures.},
  url          = {http://onlinelibrary.wiley.com/doi/10.1111/evo.12743/abstract},
  urldate      = {2015-09-16},
  language     = {en}
}

@ARTICLE{Stewart2015-cd,
  title        = {Intraskeletal variability of relative cortical area in humans:
                  variability of relative cortical area},
  shorttitle   = {Intraskeletal Variability of Relative Cortical Area in Humans},
  author       = {Stewart, Marissa C and Goliath, Jesse R and Stout, Sam D and
                  Hubbe, Mark},
  journaltitle = {Anat. Rec.},
  volume       = {298},
  issue        = {9},
  pages        = {1635--1643},
  date         = {2015},
  doi          = {10.1002/ar.23181},
  issn         = {0003-276X,1932-8486},
  url          = {http://doi.wiley.com/10.1002/ar.23181},
  urldate      = {2015-08-27},
  language     = {en}
}

@ARTICLE{Sullivan2012-rr,
  title        = {Using effect size—or why the \textit{P} value is not enough},
  author       = {Sullivan, Gail M and Feinn, Richard},
  journaltitle = {J. Grad. Med. Educ.},
  volume       = {4},
  issue        = {3},
  pages        = {279--282},
  date         = {2012},
  doi          = {10.4300/JGME-D-12-00156.1},
  issn         = {1949-8349,1949-8357},
  url          = {http://www.jgme.org/doi/abs/10.4300/JGME-D-12-00156.1},
  urldate      = {2015-07-14},
  language     = {en}
}

@ARTICLE{Maddison2015-jf,
  title        = {The Unsolved Challenge to Phylogenetic Correlation Tests for
                  Categorical Characters},
  author       = {Maddison, Wayne P and FitzJohn, Richard G},
  journaltitle = {Syst. Biol.},
  volume       = {64},
  issue        = {1},
  pages        = {127--136},
  date         = {2015-01-01},
  doi          = {10.1093/sysbio/syu070},
  issn         = {1063-5157,1076-836X},
  url          = {http://sysbio.oxfordjournals.org/content/64/1/127},
  urldate      = {2015-03-24},
  language     = {en}
}

@ARTICLE{Van_der_Laan2004-in,
  title        = {Augmentation procedures for control of the generalized
                  family-wise error rate and tail probabilities for the
                  proportion of false positives},
  author       = {van der Laan, Mark J and Dudoit, Sandrine and Pollard,
                  Katherine S},
  journaltitle = {Stat. Appl. Genet. Mol. Biol.},
  volume       = {3},
  pages        = {Article15},
  date         = {2004-06-15},
  doi          = {10.2202/1544-6115.1042},
  pmid         = {16646793},
  issn         = {1544-6115},
  abstract     = {This article shows that any single-step or stepwise multiple
                  testing procedure (asymptotically) controlling the family-wise
                  error rate (FWER) can be augmented into procedures that
                  (asymptotically) control tail probabilities for the number of
                  false positives and the proportion of false positives among
                  the rejected hypotheses. Specifically, given any procedure
                  that (asymptotically) controls the FWER at level alpha, we
                  propose simple augmentation procedures that provide
                  (asymptotic) level-alpha control of: (i) the generalized
                  family-wise error rate, i.e., the tail probability, gFWER(k),
                  that the number of Type I errors exceeds a user-supplied
                  integer k, and (ii) the tail probability, TPPFP(q), that the
                  proportion of Type I errors among the rejected hypotheses
                  exceeds a user-supplied value 0<q<1. Existing approaches for
                  control of the proportion of false positives typically rely on
                  the assumption that the test statistics are independent, while
                  our proposed augmentation procedures control the gFWER and
                  TPPFP for general data generating distributions, with
                  arbitrary dependence structures among variables. Applying the
                  augmentation methods to step-down multiple testing procedures
                  that control the FWER asymptotically exactly at level alpha
                  (van der Laan et al., 2004), yields procedures that also
                  provide exact asymptotic control of the gFWER and TPPFP at
                  level alpha. The adjusted p-values for the gFWER and
                  TPPFP-controlling augmentation procedures are shown to be
                  simple functions of the adjusted p-values for the original
                  FWER-controlling procedure. Finally, two simple conservative
                  procedures are proposed for controlling the false discovery
                  rate.},
  url          = {http://dx.doi.org/10.2202/1544-6115.1042},
  language     = {en}
}

@BOOK{Moore2010-mo,
  title      = {Introduction to the Practice of Statistics},
  shorttitle = {Introduction to the Practice of Statistics},
  author     = {Moore, David S and McCabe, George P and Craig, Bruce},
  publisher  = {W. H. Freeman},
  location   = {New York},
  edition    = {7th edition},
  date       = {2010-11-19},
  pagetotal  = {694},
  isbn       = {9781429240321},
  url        = {http://www.amazon.com/Introduction-Practice-Statistics-Student-CD/dp/1429240326/ref=sr_1_1?ie=UTF8&qid=1426259382&sr=8-1&keywords=moore+mccabe},
  language   = {English}
}

@BOOK{Manly2006-ky,
  title     = {Randomization, Bootstrap and Monte Carlo Methods in Biology},
  author    = {Manly, Bryan F J},
  publisher = {Chapman and Hall/CRC},
  location  = {Boca Raton, FL},
  edition   = {3rd edition},
  date      = {2006-08-15},
  pagetotal = {480},
  isbn      = {9781584885412},
  abstract  = {Modern computer-intensive statistical methods play a key role in
               solving many problems across a wide range of scientific
               disciplines. This new edition of the bestselling Randomization,
               Bootstrap and Monte Carlo Methods in Biology illustrates the
               value of a number of these methods with an emphasis on biological
               applications. This textbook focuses on three related areas in
               computational statistics: randomization, bootstrapping, and Monte
               Carlo methods of inference. The author emphasizes the sampling
               approach within randomization testing and confidence intervals.
               Similar to randomization, the book shows how bootstrapping, or
               resampling, can be used for confidence intervals and tests of
               significance. It also explores how to use Monte Carlo methods to
               test hypotheses and construct confidence intervals.New to the
               Third EditionUpdated information on regression and time series
               analysis, multivariate methods, survival and growth data as well
               as software for computational statisticsReferences that reflect
               recent developments in methodology and computing
               techniquesAdditional references on new applications of
               computer-intensive methods in biologyProviding comprehensive
               coverage of computer-intensive applications while also offering
               data sets online, Randomization, Bootstrap and Monte Carlo
               Methods in Biology, Third Edition supplies a solid foundation for
               the ever-expanding field of statistics and quantitative analysis
               in biology.},
  url       = {http://www.amazon.com/Randomization-Bootstrap-Methods-Biology-Statistical/dp/1584885416},
  language  = {English}
}

@BOOK{Kabacoff2011-ro,
  title      = {{R} in Action: Data Analysis and Graphics with {R}},
  shorttitle = {R in action},
  author     = {Kabacoff, Robert I},
  publisher  = {Manning},
  location   = {Shelter Island, NY},
  date       = {2011},
  isbn       = {9781935182399},
  language   = {English}
}

@BOOK{Crawley2012-hr,
  title     = {The {R} Book},
  author    = {Crawley, Michael J},
  publisher = {John Wiley \& Sons, Ltd.},
  location  = {Chichester, West Sussex, United Kingdom},
  edition   = {2nd edition},
  date      = {2012},
  pagetotal = {1076},
  isbn      = {9780470973929},
  url       = {http://www.amazon.com/R-Book-Michael-J-Crawley/dp/0470973927/ref=sr_1_1?s=books&ie=UTF8&qid=1425318769&sr=1-1&keywords=crawley+the+r+book},
  language  = {English}
}

@BOOK{Harrell2010-ql,
  title      = {Regression Modeling Strategies: With Applications to Linear
                Models, Logistic Regression, and Survival Analysis},
  shorttitle = {Regression Modeling Strategies},
  author     = {Harrell, Frank E},
  publisher  = {Springer},
  location   = {New York, NY},
  date       = {2010-12-01},
  pagetotal  = {572},
  isbn       = {9781441929181},
  abstract   = {Many texts are excellent sources of knowledge about individual
                statistical tools, but the art of data analysis is about
                choosing and using multiple tools. Instead of presenting
                isolated techniques, this text emphasizes problem solving
                strategies that address the many issues arising when developing
                multivariable models using real data and not standard textbook
                examples. It includes imputation methods for dealing with
                missing data effectively, methods for dealing with nonlinear
                relationships and for making the estimation of transformations a
                formal part of the modeling process, methods for dealing with
                "too many variables to analyze and not enough observations," and
                powerful model validation techniques based on the bootstrap.
                This text realistically deals with model uncertainty and its
                effects on inference to achieve "safe data mining".},
  url        = {https://link.springer.com/book/10.1007/978-3-319-19425-7},
  language   = {English}
}

@BOOK{Fox2015-he,
  title     = {Applied Regression Analysis and Generalized Linear Models},
  author    = {Fox, John},
  publisher = {SAGE Publications, Inc},
  location  = {Thousand Oaks, CA},
  edition   = {3rd edition},
  date      = {2015},
  pagetotal = {880},
  isbn      = {9781452205663},
  abstract  = {Combining a modern, data-analytic perspective with a focus on
               applications in the social sciences, the Third Edition of Applied
               Regression Analysis and Generalized Linear Models provides
               in-depth coverage of regression analysis, generalized linear
               models, and closely related methods, such as bootstrapping and
               missing data. Updated throughout, this Third Edition includes new
               chapters on mixed-effects models for hierarchical and
               longitudinal data. Although the text is largely accessible to
               readers with a modest background in statistics and mathematics,
               author John Fox also presents more advanced material in optional
               sections and chapters throughout the book.},
  url       = {http://www.amazon.com/Applied-Regression-Analysis-Generalized-Linear/dp/1452205663/ref=sr_1_4?s=books&ie=UTF8&qid=1425318569&sr=1-4&keywords=applied+regression+analysis+fox},
  language  = {English}
}

@BOOK{Fox2010-eu,
  title     = {An {R} Companion to Applied Regression},
  author    = {Fox, John and Weisberg, Harvey Sanford},
  publisher = {SAGE Publications, Inc.},
  location  = {Thousand Oaks, CA},
  edition   = {2nd edition},
  date      = {2010},
  pagetotal = {472},
  isbn      = {9781412975148},
  abstract  = {This is a broad introduction to the R statistical computing
               environment in the context of applied regression analysis. It is
               a thoroughly updated edition of John Fox’s bestselling text An R
               and S-Plus Companion to Applied Regression (SAGE, 2002). The
               Second Edition is intended as a companion to any course on modern
               applied regression analysis. The authors provide a step-by-step
               guide to using the high-quality free statistical software R, an
               emphasis on integrating statistical computing in R with the
               practice of data analysis, coverage of generalized linear models,
               enhanced coverage of R graphics and programming, and substantial
               web-based support materials.},
  url       = {http://www.amazon.com/R-Companion-Applied-Regression/dp/141297514X/ref=sr_1_3?s=books&ie=UTF8&qid=1425318569&sr=1-3&keywords=applied+regression+analysis+fox},
  language  = {English}
}

@BOOK{Fox1997-tk,
  title     = {Applied Regression Analysis, Linear Models, and Related Methods},
  author    = {Fox, John},
  publisher = {SAGE Publications, Inc.},
  location  = {Thousand Oaks, CA},
  date      = {1997},
  pagetotal = {624},
  isbn      = {9780803945401},
  abstract  = {An accessible, detailed, and up-to-date treatment of regression
               analysis, linear models, and closely related methods is provided
               in this book. Incorporating nearly 200 graphs and numerous
               examples and exercises that employ real data from the social
               sciences, the book begins with a consideration of the role of
               statistical data analysis in social research. It then moves on to
               cover the following topics: graphical methods for examining and
               transforming data; linear least-squares regression;
               dummy-variables regression; analysis of variance; diagnostic
               methods for discovering whether a linear model fit to data
               adequately represents the data; extensions to linear least
               squares, including logit and probit models, time-series
               regression, nonlinear},
  url       = {http://www.amazon.com/Applied-Regression-Analysis-Related-Methods/dp/080394540X/ref=sr_1_2?s=books&ie=UTF8&qid=1425318569&sr=1-2&keywords=applied+regression+analysis+fox},
  language  = {English}
}

@BOOK{Sokal2011-if,
  title     = {Biometry},
  author    = {Sokal, Robert R and Rohlf, F James},
  publisher = {W. H. Freeman},
  location  = {New York},
  edition   = {4th edition},
  date      = {2011-09-16},
  pagetotal = {937},
  isbn      = {9780716786047},
  abstract  = {This easily understood but rigorous introduction to biological
               statistics is a standard text and valuable reference for anyone
               doing scientific research. The fourth edition has been thoroughly
               revised and updated using computer calculations and the authors
               have expanded on important modern topics.},
  url       = {http://www.amazon.com/Biometry-Robert-R-Sokal/dp/0716786044/ref=sr_1_1?s=books&ie=UTF8&qid=1425318545&sr=1-1&keywords=biometry},
  language  = {English}
}

@BOOK{Zar2009-am,
  title     = {Biostatistical Analysis},
  author    = {Zar, Jerrold H},
  publisher = {Pearson},
  location  = {Upper Saddle River, N.J.},
  edition   = {5th edition},
  date      = {2009-02-25},
  pagetotal = {960},
  isbn      = {9780131008465},
  abstract  = {Zar’s Biostatistical Analysis, Fifth Edition, is the ideal book
               for readers seeking practical coverage of statistical analysis
               methods used by researchers to collect, summarize, analyze and
               draw conclusions from biological research. The latest edition of
               this best-selling textbook is both comprehensive and easy to
               read. It is suitable as an introduction for beginners and as a
               comprehensive reference book for biological researchers and other
               advanced users. Introduction; Populations and Samples; Measures
               of Central Tendency; Measures of Dispersion and Variability;
               Probabilities; The Normal Distribution; One-Sample Hypotheses;
               Two-Sample Hypotheses; Paired-Sample Hypotheses; Multisample
               Hypotheses: The Analysis of Variance; Multiple Comparisons;
               Two-Factor Analysis of Variance; Data Transformations; Multiway
               Factorial Analysis of Variance; Nested (Hierarchical) Analysis of
               Variance; Multivariate Analysis of Variance; Simple Linear
               Regression; Comparing Simple Linear Regression Equations; Simple
               Linear Correlation; Multiple Regression and Correlation;
               Polynomial Regression; Testing for Goodness of Fit; Contingency
               Tables; More on Dichotomous Variables; Testing for Randomness;
               Circular Distributions: Descriptive Statistics; Circular
               Distributions: Hypothesis Testing For all readers interested in
               biostatistics.},
  url       = {https://www.pearson.com/en-us/subject-catalog/p/biostatistical-analysis/P200000006419/9780134995441},
  language  = {English}
}

@BOOK{Venables2003-rg,
  title     = {Modern Applied Statistics with {S}},
  author    = {Venables, W N and Ripley, B D},
  publisher = {Springer},
  location  = {New York},
  edition   = {4th edition},
  date      = {2003-09-02},
  pagetotal = {498},
  isbn      = {9780387954578},
  abstract  = {A guide to using S environments to perform statistical analyses
               providing both an introduction to the use of S and a course in
               modern statistical methods. The emphasis is on presenting
               practical problems and full analyses of real data sets.},
  url       = {http://www.amazon.com/Modern-Applied-Statistics-Computing/dp/0387954570/ref=sr_1_1?s=books&ie=UTF8&qid=1425318514&sr=1-1&keywords=modern+applied+statistics+with+s},
  language  = {English}
}

@BOOK{Ramsey2012-nq,
  title     = {The Statistical Sleuth: A Course in Methods of Data Analysis},
  author    = {Ramsey, Fred and Schafer, Daniel},
  publisher = {Cengage Learning},
  location  = {Boston, MA},
  edition   = {3rd edition},
  date      = {2012},
  pagetotal = {784},
  isbn      = {9781133490678},
  url       = {http://www.amazon.com/Statistical-Sleuth-Course-Methods-Analysis/dp/1133490670/ref=sr_1_1?s=books&ie=UTF8&qid=1425318354&sr=1-1&keywords=statistical+sleuth},
  language  = {English}
}

@BOOK{Tabachnick2013-yo,
  title     = {Using Multivariate Statistics},
  author    = {Tabachnick, Barbara G and Fidell, Linda S},
  publisher = {Pearson Education},
  location  = {Boston},
  date      = {2013},
  isbn      = {9780205849574,9780205890811},
  language  = {Text in English.}
}

@BOOK{Xie2013-ln,
  title     = {Dynamic Documents with {R} and knitr},
  author    = {Xie, Yihui},
  publisher = {Chapman and Hall/CRC},
  location  = {Boca Raton, FL},
  date      = {2013},
  isbn      = {9781482203530}
}

@ARTICLE{Jolicoeur1960-ad,
  title        = {Size and shape variation in the painted turtle. A principal
                  component analysis},
  author       = {Jolicoeur, P and Mosimann, J E},
  journaltitle = {Growth},
  volume       = {24},
  pages        = {339--354},
  date         = {1960-12},
  pmid         = {13790416},
  issn         = {0017-4793},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/13790416},
  language     = {eng}
}

@ARTICLE{Maddison2006-hy,
  title        = {Confounding asymmetries in evolutionary diversification and
                  character change},
  author       = {Maddison, Wayne P},
  journaltitle = {Evolution},
  volume       = {60},
  issue        = {8},
  pages        = {1743--1746},
  date         = {2006},
  issn         = {0014-3820},
  abstract     = {Studies of character evolution often assume that a phylogeny's
                  shape is determined independently of the characters, which
                  then evolve as mere passengers along the tree's branches.
                  However, if the characters help shape the tree, but this is
                  not considered, biased inferences can result. Simulations of
                  asymmetrical speciation (i.e., one character state conferring
                  a higher rate of speciation than another) result in data that
                  are interpreted to show a higher rate of change toward the
                  diversification-enhancing state, even though the rates to and
                  from this state were in fact equal. Conversely, simulations of
                  asymmetrical character change yield data that could be
                  misinterpreted as showing asymmetrical rates of speciation.
                  Studies of biased diversification and biased character change
                  need to be unified by joint models and estimation methods,
                  although how successfully the two processes can be teased
                  apart remains to be seen.},
  url          = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=17017073&retmode=ref&cmd=prlinks}
}

@BOOK{Harvey1991-mi,
  title     = {The Comparative Method in Evolutionary Biology},
  author    = {Harvey, Paul H and Pagel, Mark D},
  publisher = {Oxford University Press},
  location  = {Oxford},
  date      = {1991}
}

@ARTICLE{Jager2013-bf,
  title        = {Rejoinder: An estimate of the science-wise false discovery
                  rate and application to the top medical literature},
  author       = {Jager, Leah R and Leek, Jeffrey T},
  journaltitle = {Biostatistics},
  volume       = {15},
  issue        = {1},
  pages        = {39--45},
  date         = {2013},
  doi          = {10.1002/sim.5925/abstract;jsessionid=600EF19932F674BCC9E2DEBF20110E76.d03t01},
  issn         = {1465-4644},
  url          = {http://biostatistics.oxfordjournals.org/content/15/1/39.full.pdf?etoc}
}

@ARTICLE{Efron1977-kn,
  title        = {Stein's paradox in statistics},
  author       = {Efron, B and Morris, C N},
  journaltitle = {Scientific American},
  pages        = {119--127},
  date         = {1977},
  abstract     = {The best guess about the future is usually obtained by
                  computing the average of past events. Stein's paradox defines
                  circumstances in which there are estimators better than the
                  arithmetic average strikingly contrary to generally held
                  belief even though an obviously valid proof is given. Charles
                  Stein of Stanford University discovered such a paradox in
                  statistics in 1955. His result undermined a century and a half
                  of work on estimation theory, going back ...},
  url          = {https://www.researchgate.net/profile/Carl_Morris/publication/247647698_Stein's_Paradox_in_Statistics/links/53da1fe60cf2631430c7f8ed.pdf}
}

@ARTICLE{Fox1992-uv,
  title        = {Generalized collinearity diagnostics},
  author       = {Fox, John and Monette, Georges},
  journaltitle = {J. Am. Stat. Assoc.},
  volume       = {87},
  issue        = {417},
  pages        = {178--183},
  date         = {1992},
  issn         = {0162-1459},
  url          = {http://www.jstor.org.proxy.mul.missouri.edu/stable/2290467?seq=1&}
}

@ARTICLE{Wickham2013-qs,
  title        = {Tidy data},
  author       = {Wickham, Hadley Alexander},
  journaltitle = {J. Stat. Softw.},
  pages        = {1--23},
  date         = {2013},
  url          = {http://vita.had.co.nz/papers/tidy-data.html}
}

@ARTICLE{Ebert1994-ds,
  title        = {Allometry and model {II} non-linear regression},
  author       = {Ebert, Thomas A and Russell, Michael P},
  journaltitle = {J. Theor. Biol.},
  volume       = {168},
  issue        = {4},
  pages        = {367--372},
  date         = {1994},
  issn         = {0022-5193},
  url          = {http://www.sciencedirect.com/science/article/pii/S0022519384711167}
}

@ARTICLE{Maddison2000-so,
  title        = {Testing Character Correlation using Pairwise Comparisons on a
                  Phylogeny},
  author       = {Maddison, Wayne P},
  journaltitle = {J. Theor. Biol.},
  volume       = {202},
  issue        = {3},
  pages        = {195--204},
  date         = {2000},
  doi          = {10.1006/jtbi.1999.1050},
  issn         = {0022-5193},
  url          = {http://linkinghub.elsevier.com/retrieve/pii/S0022519399910500}
}

@REPORT{Garland2013-zc,
  type   = {resreport},
  title  = {How to structure and name data files},
  author = {Garland, Jr, Theodore},
  pages  = {1--3},
  date   = {2013}
}

@BOOK{Nunn2011-zi,
  title     = {The Comparative Approach in Evolutionary Anthropology and Biology},
  author    = {Nunn, Charles L},
  publisher = {University of Chicago Press},
  location  = {Chicago},
  date      = {2011},
  pagetotal = {380},
  isbn      = {9780226608983},
  abstract  = {Comparison is fundamental to evolutionary anthropology. When
               scientists study chimpanzee cognition, for example, they compare
               chimp performance on cognitive tasks to the performance of human
               children on the same tasks. And when new fossils are found, such
               as those of the tiny humans of Flores, scientists compare these
               remains to other fossils and contemporary humans. Comparison
               provides a way to draw general inferences about the evolution of
               traits and therefore has long been the cornerstone of efforts to
               understand biological and cultural diversity. Individual studies
               of fossilized remains, living species, or human populations are
               the essential units of analysis in a comparative study; bringing
               these elements into a broader comparative framework allows the
               puzzle pieces to fall into place, creating a means of testing
               adaptive hypotheses and generating new ones. With this book,
               Charles L. Nunn intends to ensure that evolutionary
               anthropologists and organismal biologists have the tools to
               realize the potential of comparative research. Nunn provides a
               wide-ranging investigation of the comparative foundations of
               evolutionary anthropology in past and present research, including
               studies of animal behavior, biodiversity, linguistic evolution,
               allometry, and cross-cultural variation. He also points the way
               to the future, exploring the new phylogeny-based comparative
               approaches and offering a how-to manual for scientists who wish
               to incorporate these new methods into their research.},
  url       = {http://books.google.com/books?id=qj4cSzJGQJAC&printsec=frontcover&dq=intitle:The+Comparative+Approach+in+Evolutionary+Anthropology+and+Biology&hl=&cd=1&source=gbs_api},
  note      = {<p>Chapter 1</p><p>Chapter 2<br />- Descending in a hierarchical
               fashion<br />- Hypothesis of relationships, not relationships per
               se<br />- When are genetic data not independent?<br />- Is there
               utility in paraphyletic groups?</p>}
}

@ARTICLE{Mevik2007-du,
  title        = {The pls Package: Principal Component and Partial Least Squares
                  Regression in {R}},
  author       = {Mevik, Bjørj-Helge and Wehrens, Ron},
  journaltitle = {J. Stat. Softw.},
  volume       = {18},
  issue        = {2},
  pages        = {1--24},
  date         = {2007},
  url          = {http://www.jstatsoft.org/v18/i02/}
}

@ARTICLE{Warton2012-zi,
  title        = {smatr 3 - an {R} package for estimation and inference about
                  allometric lines},
  author       = {Warton, David I and Duursma, Remko A and Falster, Daniel S and
                  Taskinen, Sara},
  journaltitle = {Methods Ecol. Evol.},
  volume       = {3},
  issue        = {2},
  pages        = {257--259},
  date         = {2012},
  doi          = {10.1111/j.2041-210X.2011.00153.x},
  url          = {http://doi.wiley.com/10.1111/j.2041-210X.2011.00153.x}
}

@ARTICLE{Barrett2012-vx,
  title        = {A hierarchical model of the evolution of human brain
                  specializations},
  author       = {Barrett, H Clark},
  journaltitle = {Proc. Natl. Acad. Sci. U. S. A.},
  volume       = {109 Suppl 1},
  pages        = {10733--10740},
  date         = {2012},
  doi          = {10.1073/pnas.1201898109},
  issn         = {0027-8424},
  abstract     = {The study of information-processing adaptations in the brain
                  is controversial, in part because of disputes about the form
                  such adaptations might take. Many psychologists assume that
                  adaptations come in two kinds, specialized and
                  general-purpose. Specialized mechanisms are typically thought
                  of as innate, domain-specific, and isolated from other brain
                  systems, whereas generalized mechanisms are developmentally
                  plastic, domain-general, and interactive. However, if brain
                  mechanisms evolve through processes of descent with
                  modification, they are likely to be heterogeneous, rather than
                  coming in just two kinds. They are likely to be hierarchically
                  organized, with some design features widely shared across
                  brain systems and others specific to particular processes.
                  Also, they are likely to be largely developmentally plastic
                  and interactive with other brain systems, rather than
                  canalized and isolated. This article presents a hierarchical
                  model of brain specialization, reviewing evidence for the
                  model from evolutionary developmental biology, genetics, brain
                  mapping, and comparative studies. Implications for the search
                  for uniquely human traits are discussed, along with ways in
                  which conventional views of modularity in psychology may need
                  to be revised.},
  url          = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=22723350&retmode=ref&cmd=prlinks}
}

@ARTICLE{Jolicoeur1963-zc,
  title        = {The multivariate generalization of the allometry equation},
  author       = {Jolicoeur, Pierre},
  journaltitle = {Biometrics},
  volume       = {19},
  issue        = {3},
  pages        = {497--499},
  date         = {1963},
  issn         = {0006-341X},
  url          = {http://www.jstor.org/stable/2527939}
}

@ARTICLE{Smith1980-py,
  title        = {Rethinking allometry},
  author       = {Smith, R J},
  journaltitle = {J. Theor. Biol.},
  volume       = {87},
  issue        = {1},
  pages        = {97--111},
  date         = {1980},
  issn         = {0022-5193},
  url          = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=7206755&retmode=ref&cmd=prlinks}
}

@ARTICLE{Heath2012-ae,
  title        = {A Hierarchical Bayesian Model for Calibrating Estimates of
                  Species Divergence Times},
  author       = {Heath, T A},
  journaltitle = {Syst. Biol.},
  volume       = {61},
  issue        = {5},
  pages        = {793--809},
  date         = {2012},
  doi          = {10.1093/sysbio/sys032},
  issn         = {1063-5157},
  url          = {http://sysbio.oxfordjournals.org/cgi/doi/10.1093/sysbio/sys032}
}

@ARTICLE{Blomberg2012-io,
  title        = {Independent Contrasts and {PGLS} Regression Estimators Are
                  Equivalent},
  author       = {Blomberg, Simon P and Lefevre, J G and Wells, J A and
                  Waterhouse, M},
  journaltitle = {Syst. Biol.},
  volume       = {61},
  issue        = {3},
  pages        = {382--391},
  date         = {2012},
  doi          = {10.1093/sysbio/syr118},
  issn         = {1063-5157},
  url          = {http://sysbio.oxfordjournals.org/cgi/doi/10.1093/sysbio/syr118}
}

@ARTICLE{Beaulieu2012-et,
  title        = {Modeling stabilizing selection: expanding the
                  Ornstein-Uhlenbeck model of adaptive evolution},
  author       = {Beaulieu, Jeremy M and Jhwueng, Dwueng-Chwuan and Boettiger,
                  Carl and O'Meara, Brian C},
  journaltitle = {Evolution},
  volume       = {66},
  issue        = {8},
  pages        = {2369--2383},
  date         = {2012},
  doi          = {10.1111/j.1558-5646.2012.01619.x},
  issn         = {0014-3820},
  url          = {http://doi.wiley.com/10.1111/j.1558-5646.2012.01619.x}
}

@BOOK{Borcard2011-ks,
  title     = {Numerical Ecology with {R}},
  author    = {Borcard, Daniel and Gillet, Francois and Legendre, Pierre},
  publisher = {Springer},
  location  = {New York},
  date      = {2011},
  pagetotal = {12},
  doi       = {10.1007/978-1-4419-7976-6},
  url       = {https://link.springer.com/book/10.1007/978-1-4419-7976-6}
}

@BOOK{Matloff2011-vl,
  title     = {The Art of {R} Programming},
  author    = {Matloff, Norman},
  publisher = {No Starch Press},
  location  = {San Francisco, CA},
  date      = {2011},
  pagetotal = {1},
  series    = {A Tour of Statistical Software Design}
}

@BOOK{Everitt2011-eu,
  title     = {An Introduction to Applied Multivariate Analysis with {R}},
  author    = {Everitt, Brian and Hothorn, Torsten},
  publisher = {Springer},
  location  = {New York},
  date      = {2011},
  url       = {https://link.springer.com/book/10.1007/978-1-4419-9650-3}
}

@ARTICLE{Zhang2011-cd,
  title        = {On fitting generalized linear mixed-effects models for binary
                  responses using different statistical packages},
  author       = {Zhang, Hui and Lu, Naiji and Feng, Changyong and Thurston,
                  Sally W and Xia, Yinglin and Zhu, Liang and Tu, Xin M},
  journaltitle = {Stat. Med.},
  volume       = {30},
  issue        = {20},
  pages        = {2562--2572},
  date         = {2011},
  doi          = {10.1002/sim.4265},
  issn         = {0277-6715},
  url          = {http://doi.wiley.com/10.1002/sim.4265}
}

@ARTICLE{Shrout1979-dn,
  title        = {Intraclass correlations: uses in assessing rater reliability},
  author       = {Shrout, Patrick E and Fleiss, Joseph L},
  journaltitle = {Psychol. Bull.},
  volume       = {86},
  issue        = {2},
  pages        = {420--428},
  date         = {1979},
  issn         = {0033-2909}
}

@ARTICLE{Paradis2002-yz,
  title        = {Analysis of comparative data using generalized estimating
                  equations},
  author       = {Paradis, Emmanuel and Claude, Julien},
  journaltitle = {J. Theor. Biol.},
  volume       = {218},
  issue        = {2},
  pages        = {175--185},
  date         = {2002-09-21},
  doi          = {10.1006/jtbi.2002.3066},
  pmid         = {12381290},
  issn         = {0022-5193},
  abstract     = {It is widely acknowledged that the analysis of comparative
                  data from related species should be performed taking into
                  account their phylogenetic relationships. We introduce a new
                  method, based on the use of generalized estimating equations
                  (GEE), for the analysis of comparative data. The principle is
                  to incorporate, in the modelling process, a correlation matrix
                  that specifies the dependence among observations. This matrix
                  is obtained from the phylogenetic tree of the studied species.
                  Using this approach, a variety of distributions (discrete or
                  continuous) can be analysed using a generalized linear
                  modelling framework, phylogenies with multichotomies can be
                  analysed, and there is no need to estimate ancestral character
                  state. A simulation study showed that the proposed approach
                  has good statistical properties with a type-I error rate close
                  to the nominal 5\%, and statistical power to detect correlated
                  evolution between two characters which increases with the
                  strength of the correlation. The proposed approach performs
                  well for the analysis of discrete characters. We illustrate
                  our approach with some data on macro-ecological correlates in
                  birds. Some extensions of the use of GEE are discussed.},
  url          = {http://dx.doi.org/10.1006/jtbi.2002.3066},
  language     = {en}
}

@ARTICLE{Harmon2010-gl,
  title        = {Early bursts of body size and shape evolution are rare in
                  comparative data},
  author       = {Harmon, Luke J and Losos, Jonathan B and Davies, T Jonathan
                  and Gillespie, Rosemary G and Gittleman, John L and Bryan
                  Jennings, W and Kozak, Kenneth H and McPeek, Mark A and
                  Moreno-Roark, Franck and Near, Thomas J and Purvis, Andy and
                  Ricklefs, Robert E and Schluter, Dolph and Schulte, Ii, James
                  A and Seehausen, Ole and Sidlauskas, Brian L and
                  Torres-Carvajal, Omar and Weir, Jason T and Mooers, Arne Ø},
  journaltitle = {Evolution},
  volume       = {64},
  issue        = {8},
  pages        = {2385--2396},
  date         = {2010},
  doi          = {10.1111/j.1558-5646.2010.01025.x},
  issn         = {0014-3820},
  abstract     = {George Gaylord Simpson famously postulated that much of life's
                  diversity originated as adaptive radiations-more or less
                  simultaneous divergences of numerous lines from a single
                  ancestral adaptive type. However, identifying adaptive
                  radiations has proven difficult due to a lack of broad-scale
                  comparative datasets. Here, we use phylogenetic comparative
                  data on body size and shape in a diversity of animal clades to
                  test a key model of adaptive radiation, in which initially
                  rapid morphological evolution is followed by relative stasis.
                  We compared the fit of this model to both single selective
                  peak and random walk models. We found little support for the
                  early-burst model of adaptive radiation, whereas both other
                  models, particularly that of selective peaks, were commonly
                  supported. In addition, we found that the net rate of
                  morphological evolution varied inversely with clade age. The
                  youngest clades appear to evolve most rapidly because
                  long-term change typically does not attain the amount of
                  divergence predicted from rates measured over short time
                  scales. Across our entire analysis, the dominant pattern was
                  one of constraints shaping evolution continually through time
                  rather than rapid evolution followed by stasis. We suggest
                  that the classical model of adaptive radiation, where
                  morphological evolution is initially rapid and slows through
                  time, may be rare in comparative data.},
  url          = {http://dx.doi.org/10.1111/j.1558-5646.2010.01025.x}
}

@ARTICLE{Gelman2002-ce,
  title        = {Let's practice what we preach: turning tables into graphs},
  author       = {Gelman, A and Pasarica, C and Dodhia, R},
  journaltitle = {Am. Stat.},
  publisher    = {Taylor \& Francis},
  volume       = {56},
  issue        = {2},
  pages        = {121--130},
  date         = {2002},
  issn         = {0003-1305},
  abstract     = {Statisticians recommend graphical displays but often use
                  tables to present their own research results. Could graphs do
                  better? We study the question by going through the tables in a
                  recent issue of the Journal of the American Statistical
                  Association. We show how it is},
  url          = {http://www.tandfonline.com/doi/abs/10.1198/000313002317572790}
}

@BOOK{Crawley2005-ih,
  title     = {Statistics: an Introduction using {R}},
  author    = {Crawley, Michael J},
  publisher = {John Wiley \& Sons, Ltd.},
  location  = {Chichester, West Sussex, United Kingdom},
  date      = {2005}
}

@ARTICLE{Bennington1994-tt,
  title        = {Use and Misuse of Mixed Model Analysis of Variance in
                  Ecological Studies},
  author       = {Bennington, Cynthia and Thayne, William},
  journaltitle = {Ecology},
  volume       = {75},
  issue        = {3},
  pages        = {717--722},
  date         = {1994},
  issn         = {0012-9658},
  abstract     = {Analysis of variance is one of the most commonly used
                  statistical techniques among ecologists and evolutionary
                  biologists. Because many ecological experiments involve random
                  as well as fixed effects, the most appropriate analysis of
                  variance model to use is often the mixed model. Consideration
                  of effects in an analysis of variance as fixed or random is
                  critical if correct tests are to be made and if correct
                  inferences are to be drawn from these tests. A literature
                  review was conducted to determine whether authors are
                  generally aware of the differences between fixed and random
                  effects and whether they are performing analyses consistent
                  with their consideration. All articles (excluding Notes and
                  Comments) in Ecology and Evolution for the years 1990 and 1991
                  were reviewed. In general, authors that stated that their
                  model contained both fixed and random effects correctly
                  analyzed it as a mixed model. There were two cases, however,
                  where authors attempted to define fixed effects as random in
                  order to justify broader generalizations about the effects.
                  Most commonly (63\% of articles using two-way or greater
                  ANOVA), authors neglected to mention whether they were dealing
                  with a completely fixed, random, or mixed model. In such
                  instances, it was not clear if the author was aware of the
                  distinction between fixed and random effects, and it was often
                  difficult to ascertain from the article whether their analysis
                  was consistent with their experimental methods. These findings
                  suggest several statistical guidelines that should be
                  followed. In particular, the inclusion of explicit
                  consideration of effects as fixed or random and clear
                  descriptions of F tests of interest would provide the reader
                  with confidence that the author has performed the analysis
                  correctly. In addition, such an explicit statement would
                  clarify the limits of the inferences about significant
                  effects.},
  url          = {http://www.jstor.org/stable/1941729}
}

@REPORT{Zahn2010-jr,
  type   = {resreport},
  title  = {Working with unbalanced cell sizes in multiple regression with
            categorical predictors},
  author = {Zahn, Ista},
  pages  = {1--18},
  date   = {2010}
}

@ARTICLE{Voss1999-sn,
  title        = {Resolving the Mixed Models Controversy},
  author       = {Voss, Daniel T},
  journaltitle = {Am. Stat.},
  publisher    = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  volume       = {53},
  issue        = {4},
  pages        = {352--356},
  date         = {1999},
  doi          = {10.2307/2686056},
  issn         = {0003-1305},
  abstract     = {Two standard mixed models with interactions are discussed.
                  When each is viewed in the context of superpopulation models,
                  the mixed models controversy is resolved. The tests suggested
                  by the expected mean squares under the constrained-parameters
                  model are correct for testing the main effects and
                  interactions under both the unconstrained-and
                  constrained-parameters models.},
  url          = {http://www.jstor.org/stable/2686056}
}

@BOOK{Chambers2008-yf,
  title     = {Software for Data Analysis: Programming with {R}},
  author    = {Chambers, John M},
  publisher = {Springer},
  location  = {New York},
  date      = {2008}
}

@ARTICLE{Ives2010-pk,
  title        = {Phylogenetic logistic regression for binary dependent
                  variables},
  author       = {Ives, Anthony R and Garland, Jr, Theodore},
  journaltitle = {Syst. Biol.},
  volume       = {59},
  issue        = {1},
  pages        = {9--26},
  date         = {2010},
  doi          = {10.1093/sysbio/syp074},
  issn         = {1063-5157},
  url          = {http://dx.doi.org/10.1093/sysbio/syp074}
}

@ARTICLE{Gartner2010-cs,
  title        = {Phylogeny, ecology, and heart position in snakes},
  author       = {Gartner, Gabriel E A and Hicks, James W and Manzani, Paulo R
                  and Andrade, Denis V and Abe, Augusto S and Wang, Tobias and
                  Secor, Stephen M and Garland, Jr, Theodore},
  journaltitle = {Physiol. Biochem. Zool.},
  volume       = {83},
  issue        = {1},
  pages        = {43--54},
  date         = {2010},
  doi          = {10.1086/648509},
  issn         = {1522-2152},
  abstract     = {The cardiovascular system of all animals is affected by
                  gravitational pressure gradients, the intensity of which
                  varies according to organismic features, behavior, and habitat
                  occupied. A previous nonphylogenetic analysis of heart
                  position in snakes-which often assume vertical postures-found
                  the heart located 15\%-25\% of total body length from the head
                  in terrestrial and arboreal species but 25\%-45\% in aquatic
                  species. It was hypothesized that a more anterior heart in
                  arboreal species served to reduce the hydrostatic blood
                  pressure when these animals adopt vertical postures during
                  climbing, whereas an anterior heart position would not be
                  needed in aquatic habitats, where the effects of gravity are
                  less pronounced. We analyzed a new data set of 155 species
                  from five major families of Alethinophidia (one of the two
                  major branches of snakes, the other being blind snakes,
                  Scolecophidia) using both conventional and phylogenetically
                  based statistical methods. General linear models regressing
                  log(10) snout-heart position on log(10) snout-vent length
                  (SVL), as well as dummy variables coding for habitat and/or
                  clade, were compared using likelihood ratio tests and the
                  Akaike Information Criterion. Heart distance to the tip of the
                  snout scaled isometrically with SVL. In all instances,
                  phylogenetic models that incorporated transformation of the
                  branch lengths under an Ornstein-Uhlenbeck model of evolution
                  (to mimic stabilizing selection) better fit the data as
                  compared with their nonphylogenetic counterparts. The best-fit
                  model predicting snake heart position included aspects of both
                  habitat and clade and indicated that arboreal snakes in our
                  study tend to have hearts placed more posteriorly, opposite
                  the trend identified in previous studies. Phylogenetic signal
                  in relative heart position was apparent both within and among
                  clades. Our results suggest that overcoming gravitational
                  pressure gradients in snakes most likely involves the combined
                  action of several cardiovascular and behavioral adaptations in
                  addition to alterations in relative heart location.},
  url          = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=19968564&retmode=ref&cmd=prlinks}
}

@ARTICLE{Hurlbert1984-fn,
  title        = {Pseudoreplication and the design of ecological field
                  experiments},
  author       = {Hurlbert, Stuart},
  journaltitle = {Ecol. Monogr.},
  volume       = {54},
  issue        = {2},
  pages        = {187--211},
  date         = {1984},
  issn         = {0012-9615},
  abstract     = {Pseudoreplication is defined as the use of inferential
                  statistics to test for treatment effects with data from
                  experiments where either treatments are not replicated (though
                  samples may be) or replicates are not statistically
                  independent. In ANOVA terminology, it is the testing for
                  treatment effects with an error term inappropriate to the
                  hypothesis being considered. Scrutiny of 176 experimental
                  studies published between 1960 and the present revealed that
                  pseudoreplication occurred in 27\% of them, or 48\% of all
                  such studies that applied inferential statistics. The
                  incidence of pseudoreplication is especially high in studies
                  of marine benthos and small mammals. The critical features of
                  controlled experimentation are reviewed. Nondemonic intrusion
                  is defined as the impingement of chance events on an
                  experiment in progress. As a safeguard against both it and
                  preexisting gradients, interspersion of treatments is argued
                  to be an obligatory feature of good design. Especially in
                  small experiments, adequate interspersion can sometimes be
                  assured only by dispensing with strict randomization
                  procedures. Comprehension of this conflict between
                  interspersion and randomization is aided by distinguishing
                  pre-layout (or conventional) and layout-specific alpha
                  (probability of type I error). Suggestions are offered to
                  statisticians and editors of ecological journals as to how
                  ecologists' understanding of experimental design and
                  statistics might be improved.},
  url          = {http://www.jstor.org/stable/1942661}
}

@BOOK{Zuur2007-qp,
  title     = {Analysing Ecological Data},
  author    = {Zuur, Alain F and Ieno, Elena N and Smith, Graham M},
  publisher = {Springer},
  location  = {New York},
  date      = {2007},
  pagetotal = {1}
}

@INBOOK{Zuur2007-ls,
  title     = {Introduction to mixed modelling},
  author    = {Zuur, Alain F and Ieno, Elena N and Smith, Graham M},
  booktitle = {Analysing Ecological Data},
  pages     = {1--18},
  date      = {2007}
}

@ARTICLE{Friendly2007-wb,
  title        = {{HE} Plots for Multivariate Linear Models},
  author       = {Friendly, Michael},
  journaltitle = {J. Comput. Graph. Stat.},
  volume       = {16},
  issue        = {2},
  pages        = {421--444},
  date         = {2007},
  doi          = {10.1198/106186007X208407},
  issn         = {1061-8600},
  url          = {http://dx.doi.org/10.1198/106186007X208407}
}

@ARTICLE{Bolker2009-ry,
  title        = {Generalized linear mixed models: a practical guide for ecology
                  and evolution},
  author       = {Bolker, Benjamin M and Brooks, M and Clark, Connie J and
                  Geange, S and Poulsen, J and Stevens, M and White, J},
  journaltitle = {Trends Ecol. Evol.},
  volume       = {24},
  issue        = {3},
  pages        = {127--135},
  date         = {2009},
  doi          = {10.1016/j.tree.2008.10.008},
  issn         = {0169-5347},
  abstract     = {How should ecologists and evolutionary biologists analyze
                  nonnormal data that involve random effects? Nonnormal data
                  such as counts or proportions often defy classical statistical
                  procedures. Generalized linear mixed models (GLMMs) provide a
                  more flexible approach for analyzing nonnormal data when
                  random effects are present. The explosion of research on GLMMs
                  in the last decade has generated considerable uncertainty for
                  practitioners in ecology and evolution. Despite the
                  availability of accurate techniques for estimating GLMM
                  parameters in simple cases, complex GLMMs are challenging to
                  fit and statistical inference such as hypothesis testing
                  remains difficult. We review the use (and misuse) of GLMMs in
                  ecology and evolution, discuss estimation and inference and
                  summarize 'best-practice' data analysis procedures for
                  scientists facing this challenge.},
  url          = {http://dx.doi.org/10.1016/j.tree.2008.10.008}
}

@MISC{Pinheiro2006-sd,
  title  = {Model Building for Nonlinear Mixed-Effects Models},
  author = {Pinheiro, José C and Bates, Douglas M},
  pages  = {11},
  date   = {2006}
}

@MISC{Fox2002-ee,
  title  = {{CAR}: appendix-mixed-models},
  author = {Fox, John},
  pages  = {24},
  date   = {2002}
}

@ARTICLE{Revell2008-tq,
  title        = {{PCCA}: a program for phylogenetic canonical correlation
                  analysis},
  author       = {Revell, Liam J and Harrison, A},
  journaltitle = {Bioinformatics},
  volume       = {24},
  issue        = {7},
  pages        = {1018--1020},
  date         = {2008},
  issn         = {1367-4803},
  abstract     = {PCCA (phylogenetic canonical correlation analysis) is a new
                  program for canonical correlation analysis of multivariate,
                  continuously valued data from biological species. Canonical
                  correlation analysis is a technique in which derived variables
                  are obtained from two sets of original variables whereby the
                  correlations between corresponding derived variables are
                  maximized. It is a very useful multivariate statistical method
                  for the calculation and analysis of correlations between
                  character sets. The program controls for species
                  non-independence due to phylogenetic history and computes
                  canonical coefficients, correlations and scores; and conducts
                  hypothesis tests on the canonical correlations. It can also
                  compute a multivariate version of Pagels , which can then be
                  used in the phylogenetic transformation.},
  url          = {http://www.google.com/search?client=safari&rls=en-us&q=PCCA:+a+program+for+phylogenetic+canonical+correlation+analysis&ie=UTF-8&oe=UTF-8}
}

@BOOK{Roff1997-ub,
  title     = {Evolutionary Quantitative Genetics},
  author    = {Roff, Derek A},
  publisher = {Chapman \& Hall},
  date      = {1997},
  pagetotal = {499}
}

@ARTICLE{Sinha1969-mp,
  title        = {Canonical correlation between groups of acarine, fungal and
                  environmental variables in bulk grain ecosystems},
  author       = {Sinha, R N and Wallace, H A H and Chebib, F S},
  journaltitle = {Research in Population Ecology},
  volume       = {11},
  pages        = {92--104},
  date         = {1969}
}

@MISC{Goldstein1999-hi,
  title  = {Multilevel Statistical Models},
  author = {Goldstein, Harvey},
  pages  = {163},
  date   = {1999}
}

@ARTICLE{Hoenig2001-hz,
  title        = {The Abuse of Power: The Pervasive Fallacy of Power
                  Calculations for Data Analysis},
  author       = {Hoenig, John M and Heisey, Dennis M},
  journaltitle = {Am. Stat.},
  publisher    = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  volume       = {55},
  issue        = {1},
  pages        = {19--24},
  date         = {2001},
  issn         = {0003-1305},
  abstract     = {It is well known that statistical power calculations can be
                  valuable in planning an experiment. There is also a large
                  literature advocating that power calculations be made whenever
                  one performs a statistical test of a hypothesis and one
                  obtains a statistically nonsignificant result. Advocates of
                  such post-experiment power calculations claim the calculations
                  should be used to aid in the interpretation of the
                  experimental results. This approach, which appears in various
                  forms, is fundamentally flawed. We document that the problem
                  is extensive and present arguments to demonstrate the flaw in
                  the logic.},
  url          = {http://www.jstor.org/stable/2685525}
}

@ARTICLE{Landsheer2005-hx,
  title        = {Additive and multiplicative effects in a fixed 2 x 2 design
                  using {ANOVA} can be difficult to differentiate: demonstration
                  and mathematical reasons},
  author       = {Landsheer, J A and Vandenwittenboer, G and Maassen, G},
  journaltitle = {Soc. Sci. Res.},
  volume       = {35},
  pages        = {279--294},
  date         = {2005},
  doi          = {10.1016/j.ssresearch.2004.10.004},
  issn         = {0049-089X},
  url          = {http://dx.doi.org/10.1016/j.ssresearch.2004.10.004}
}

@ARTICLE{Landsheer2004-pl,
  title        = {Main effects as a by-product in a fixed effect 2 x 2 design,
                  analyzed with {ANOVA}},
  author       = {Landsheer, J A and Van den Wittenboer, G},
  journaltitle = {Qual. Quant.},
  volume       = {38},
  pages        = {653--673},
  date         = {2004},
  issn         = {0033-5177},
  abstract     = {To study interaction effects, two sets of data are created for
                  fixed effect ANOVA, both with combinatory effects of the two
                  factors. In the first, both factors and their interaction
                  contribute independently and directly to the dependent
                  variable. In the second, each factor contributes indirectly to
                  the dependent score. Data created with the first model can be
                  analyzed flawlessly. The second often show relatively large
                  main effects and relatively small interaction effects, and as
                  a consequence the interaction effect may be rejected. Even
                  when the dependent variable results solely from the
                  multiplication of both factor scores, highly significant main
                  effects can be obtained, while the interaction effect remains
                  insignificant. Although mathematically correct, the relative
                  contributions of the main effects are in that case difficult
                  to interpret.}
}

@ARTICLE{Qian2007-fa,
  title        = {Ecological applications of multilevel analysis of variance},
  author       = {Qian, Song S and Shen, Zehao},
  journaltitle = {Ecology},
  volume       = {88},
  issue        = {10},
  pages        = {2489--2495},
  date         = {2007},
  issn         = {0012-9658},
  abstract     = {A Bayesian representation of the analysis of variance by A.
                  Gelman is introduced with ecological examples. These examples
                  demonstrate typical situations encountered in ecological
                  studies. Compared to conventional methods, the multilevel
                  approach is more flexible in model formulation, easier to set
                  up, and easier to present. Because the emphasis is on
                  estimation, multilevel models are more informative than the
                  results from a significance test. The improved capacity is
                  largely due to the changed computation methods. In our
                  examples, we show that (1) the multilevel model is able to
                  discern a treatment effect that is smaller than the
                  conventional approach can detect, (2) the graphical
                  presentation associated with the multilevel method is more
                  informative, and (3) the multilevel model can incorporate all
                  sources of uncertainty to accurately describe the true
                  relationship between the outcome and potential predictors.}
}

@ARTICLE{Uhlenbeck1930-xx,
  title        = {On the theory of the Brownian motion},
  author       = {Uhlenbeck, G E and Ornstein, L S},
  journaltitle = {Physical Review},
  volume       = {36},
  pages        = {823--841},
  date         = {1930}
}

@ARTICLE{Smith1984-gp,
  title        = {Allometric scaling in comparative biology: problems of concept
                  and method},
  author       = {Smith, Richard J},
  journaltitle = {Am. J. Phys. Anthropol.},
  volume       = {246},
  issue        = {2 Pt 2},
  pages        = {R152--60},
  date         = {1984},
  issn         = {0002-9483},
  abstract     = {Allometric scaling, a widely used comparative approach for
                  studying the relationship between size, shape, and function in
                  organisms, is examined in both concept and application. The
                  general adoption of an "allometric method" with several
                  standardized conventions has inhibited the creative study of
                  size-correlated phenomena and has falsely simplified a complex
                  area of research. Discussed here are some of the consequences
                  of using a power function (and the resulting logarithmic
                  transformation of data) to describe allometric trends, the
                  dependence on correlation coefficients as a measure of
                  strength of association, and the assumptions underlying use of
                  empirical data to determine the relative size of structures.
                  Several alternative methods for data analysis are suggested.}
}

@ARTICLE{Slinker1985-ji,
  title        = {Multiple regression for physiological data analysis: the
                  problem of multicollinearity},
  author       = {Slinker, Bryan K and Glantz, Stanton A},
  journaltitle = {Am. J. Physiol. Regul. Integr. Comp. Physiol.},
  volume       = {249},
  pages        = {R1--R12},
  date         = {1985},
  issn         = {0363-6119}
}

@ARTICLE{Welham2004-ci,
  title        = {Prediction in linear mixed models},
  author       = {Welham, Sue and Cullis, Brian and Gogel, Beverley and Gilmour,
                  Arthur and Thompson, Arthur},
  journaltitle = {Aust NZ J Stat},
  volume       = {46},
  issue        = {3},
  pages        = {325--347},
  date         = {2004}
}

@ARTICLE{White2003-kh,
  title        = {Allometric analysis beyond heterogenous regression slopes: use
                  of the Johnson-Neyman technique in comparative biology},
  author       = {White, Craig R},
  journaltitle = {Physiol. Biochem. Zool.},
  volume       = {76},
  issue        = {1},
  pages        = {135--140},
  date         = {2003},
  issn         = {1522-2152}
}

@ARTICLE{Schluter1997-pd,
  title        = {Likelihood of ancestor states in adaptive radiation},
  author       = {Schluter, Dolph and Price, Trevor and Mooers, Arne and Ludwig,
                  Donald},
  journaltitle = {Evolution},
  volume       = {51},
  issue        = {6},
  pages        = {1699--1711},
  date         = {1997},
  issn         = {0014-3820}
}

@ARTICLE{Pagel1994-hu,
  title        = {Detecting correlated evolution on phylogenies: a general
                  method for the comparative analysis of discrete characters},
  author       = {Pagel, Mark},
  journaltitle = {Proc Roy Soc B},
  volume       = {255},
  pages        = {37--45},
  date         = {1994}
}

@ARTICLE{Pagel1992-jz,
  title        = {A method for the analysis of comparative data},
  author       = {Pagel, Mark},
  journaltitle = {J. Theor. Biol.},
  volume       = {156},
  pages        = {431--442},
  date         = {1992},
  issn         = {0022-5193},
  abstract     = {Felsenstein (1985) developed a method for analyzing
                  comparative data that calculates a set of mutually independent
                  comparisons among the species. The method was designed to be
                  used with phylogenies for which the true dichotomous branching
                  pattern is known. However, available phylogenies often contain
                  many incompletely resolved nodes, or nodes from which three or
                  more branches emanate. This paper reports a generalization of
                  Felsenstein's method that permits the analysis of incompletely
                  resolved phylogenies. The method is general to any sort of
                  phylogeny and, like Felsenstein's model can accommodate more
                  than one model of evolutionary change. The method is
                  implemented in a computer program which can make use of
                  information on branch lengths, or, if branch length
                  information is not available, an algorithm is used to
                  calculate a set of branch lengths. The wider implications of
                  the method are that it makes explicit the assumptions about
                  unknown branching patterns and branch lengths that all
                  comparative methods that are applied to incompletely resolved
                  phylogenies must make.}
}

@ARTICLE{Quinn2004-lk,
  title        = {Bayesian factor analysis for mixed ordinal and continuous
                  reponses},
  author       = {Quinn, Kevin M},
  journaltitle = {Polit. Anal.},
  volume       = {12},
  pages        = {338--353},
  date         = {2004},
  issn         = {1047-1987}
}

@ARTICLE{Pagel1999-sl,
  title        = {Inferring the historical patterns of biological evolution},
  author       = {Pagel, Mark},
  journaltitle = {Nature},
  volume       = {401},
  issue        = {6756},
  pages        = {877--884},
  date         = {1999},
  doi          = {10.1038/44766},
  issn         = {0028-0836},
  abstract     = {... This is true whether the traits under investigation are
                  time or some morphological , life-history ... Theories of the
                  evolution of mammalian brain size link brain volume to body
                  mass ... Before calculating a correlation , the
                  maximum-likelihood values of the path-length scaling parameter
                  ...},
  url          = {http://www.nature.com/nature/journal/v401/n6756/abs/401877a0.html}
}

@ARTICLE{Maddison1994-zw,
  title        = {Phylogenetic methods for inferring the evolutionary history
                  and processes of change in discreetly valued characters},
  author       = {Maddison, David},
  journaltitle = {Annu. Rev. Entomol.},
  volume       = {39},
  pages        = {267--292},
  date         = {1994},
  issn         = {0066-4170}
}

@ARTICLE{Organ2007-zv,
  title        = {Origin of avian genome size and structure in non-avian
                  dinosaurs},
  author       = {Organ, Chris L and Shedlock, Andrew M and Meade, Andrew and
                  Pagel, Mark and Edwards, Scott V},
  journaltitle = {Nature},
  volume       = {446},
  issue        = {7132},
  pages        = {180--184},
  date         = {2007},
  doi          = {10.1038/nature05621},
  issn         = {0028-0836},
  url          = {http://www.nature.com/doifinder/10.1038/nature05621}
}

@ARTICLE{Martins1997-yv,
  title        = {Phylogenies and the comparative method: A general approach to
                  incorporating phylogenetic information into the analysis of
                  interspecific data},
  author       = {Martins, Emília and Hansen, Thomas F},
  journaltitle = {Am. Nat.},
  volume       = {149},
  issue        = {4},
  pages        = {646--667},
  date         = {1997},
  issn         = {0003-0147}
}

@ARTICLE{Martins1991-yb,
  title        = {Phylogenetic analyses of the correlated evolution of
                  continuous characters: A simulation study},
  author       = {Martins, Emília and Garland, Jr, Theodore},
  journaltitle = {Evolution},
  volume       = {45},
  issue        = {3},
  pages        = {534--557},
  date         = {1991},
  issn         = {0014-3820}
}

@BOOK{Judge1985-gl,
  title     = {The Classical Inference Approach for the General Linear Model},
  author    = {Judge, George G and Griffiths, W E and Hill, R Carter and
               Lütkepohl, Helmut and Lee, Tsoung-Chao},
  publisher = {John Wiley \& Sons},
  location  = {New York, NY},
  edition   = {2nd edition},
  date      = {1985},
  pagetotal = {1019}
}

@ARTICLE{Hansen1996-ad,
  title        = {Translating between microevolutionary process and
                  macroevolutionary patterns: The correlation structure of
                  interspecific data},
  author       = {Hansen, Thomas F and Martins, Emília},
  journaltitle = {Evolution},
  volume       = {50},
  issue        = {4},
  pages        = {1404--1417},
  date         = {1996},
  issn         = {0014-3820},
  abstract     = {As species evolve along a phylogenetic tree, we expect closely
                  related species to retain some phenotypic similarities due to
                  their shared evolutionary histories. The amount of expected
                  similarity depends both on the hierarchical phylogenetic
                  structure, and on the specific magnitude and types of
                  evolutionary changes that accumulate during each generation.
                  In this study, we show how models of microevolutionary change
                  can be translated into the resulting macroevolutionary
                  patterns. We illustrate how the structure of phenotypic
                  covariances expected in interspecific measurements can be
                  derived, and how this structure depends on the
                  microevolutionary forces guiding phenotypic change at each
                  generation. We then explore the covariance structure expected
                  from several simple microevolutionary models of phenotypic
                  evolution, including various combinations of random genetic
                  drift, directional selection, stabilizing selection, and
                  environmental change, as well as models of punctuated or
                  burst-like evolution. We find that stabilizing selection leads
                  to patterns of exponential decrease of between species
                  covariance with phylogenetic distance. This is different from
                  the usual linear patterns of decrease assumed in most
                  comparative and systematic methods. Nevertheless, linear
                  patterns of decrease can result from many processes in
                  addition to random genetic drift, such as directional and
                  fluctuating selection as well as modes of punctuated change.
                  Our framework can be used to develop methods for (1)
                  phylogenetic reconstruction; (2) inference of the evolutionary
                  process from comparative data; and (3) conducting or
                  evaluating statistical analyses of comparative data while
                  taking phylogenetic history into account.},
  url          = {http://www.google.com/search?client=safari&rls=en&q=Translating+between+microevolutionary+process+and+macroevolutionary+patterns:+The+correlation+structure+of+interspecific+data&ie=UTF-8&oe=UTF-8}
}

@ARTICLE{Ives2007-wc,
  title        = {Within-species variation and measurement error in phylogenetic
                  comparative methods},
  author       = {Ives, Anthony R and Midford, Peter E and Garland, Jr, Theodore},
  journaltitle = {Syst. Biol.},
  volume       = {56},
  issue        = {2},
  pages        = {252--270},
  date         = {2007},
  issn         = {1063-5157}
}

@ARTICLE{Hutcheon2004-hu,
  title        = {Are megabats big?},
  author       = {Hutcheon, James and Garland, Jr, Theodore},
  journaltitle = {J. Mamm. Evol.},
  volume       = {11},
  issue        = {3/4},
  pages        = {257--277},
  date         = {2004},
  issn         = {1064-7554}
}

@ARTICLE{Garland2005-qz,
  title        = {Phylogenetic approaches in comparative physiology},
  author       = {Garland, Jr, Theodore and Bennett, Albert F and Rezende,
                  Enrico L},
  journaltitle = {J. Exp. Biol.},
  volume       = {208},
  pages        = {3015--3035},
  date         = {2005},
  issn         = {0022-0949}
}

@ARTICLE{Garland1994-vk,
  title        = {Why not to do two-species comparative studies: limitations on
                  inferring adaptation},
  author       = {Garland, Jr, Theodore and Adolph, Stephen C},
  journaltitle = {Physiol. Zool.},
  volume       = {67},
  issue        = {4},
  pages        = {797--828},
  date         = {1994},
  issn         = {0031-935X},
  url          = {http://www.google.com/search?client=safari&rls=en-us&q=Why+not+to+do+two-species+comparative+studies:+Limitations+on+inferring+adaptation&ie=UTF-8&oe=UTF-8}
}

@ARTICLE{Garland1992-bf,
  title        = {Procedures for the analysis of comparative data using
                  phylogenetically independent contrasts},
  author       = {Garland, Jr, Theodore and Harvey, Paul H and Ives, Anthony R},
  journaltitle = {Syst. Biol.},
  volume       = {41},
  issue        = {1},
  pages        = {18--32},
  date         = {1992},
  issn         = {1063-5157}
}

@ARTICLE{Felsenstein1988-gf,
  title        = {Phylogenies and quantative characters},
  author       = {Felsenstein, Joseph},
  journaltitle = {Annu. Rev. Ecol. Syst.},
  volume       = {19},
  pages        = {445--471},
  date         = {1988},
  issn         = {0066-4162}
}

@ARTICLE{Felsenstein1973-ca,
  title        = {Maximum likelihood and minimum-steps methods for estimating
                  evolutionary trees from data on discrete characters},
  author       = {Felsenstein, Joseph},
  journaltitle = {Syst. Zool.},
  volume       = {22},
  issue        = {3},
  pages        = {240--249},
  date         = {1973},
  issn         = {0039-7989}
}

@ARTICLE{Diaz-Uriarte1998-kk,
  title        = {Effects of branch length errors on the performance of
                  phylogenetically independent contrasts},
  author       = {Díaz-Uriarte, Ramón and Garland, Jr, Theodore},
  journaltitle = {Syst. Biol.},
  volume       = {47},
  issue        = {4},
  pages        = {654--672},
  date         = {1998},
  issn         = {1063-5157}
}

@ARTICLE{Diaz-Uriarte1996-fe,
  title        = {Testing hypotheses of correlated evolution using
                  phylogenetically independent contrasts: Sensitivity to
                  deviations from Brownian motion},
  author       = {Díaz-Uriarte, Ramón and Garland, Jr, Theodore},
  journaltitle = {Syst. Biol.},
  volume       = {45},
  issue        = {1},
  pages        = {27--47},
  date         = {1996},
  issn         = {1063-5157}
}

@ARTICLE{Butler2004-ey,
  title        = {Phylogenetic comparative analysis: a modeling approach for
                  adaptive evolution},
  author       = {Butler, Marguerite and King, Aaron},
  journaltitle = {Am. Nat.},
  volume       = {164},
  issue        = {6},
  pages        = {683--695},
  date         = {2004},
  issn         = {0003-0147}
}

@ARTICLE{Blomberg2002-nn,
  title        = {Tempo and mode in evolution: phylogenetic inertia, adaptation
                  and comparative methods},
  author       = {Blomberg, Simon P and Garland, Jr, Theodore},
  journaltitle = {J. Evol. Biol.},
  volume       = {15},
  pages        = {899--910},
  date         = {2002},
  issn         = {1010-061X}
}

@ARTICLE{Maddison2007-ov,
  title        = {Estimating a binary character's effect on speciation and
                  extinction},
  author       = {Maddison, Wayne P and Midford, Peter E and Otto, Sarah P},
  journaltitle = {Syst. Biol.},
  volume       = {56},
  issue        = {5},
  pages        = {701--710},
  date         = {2007},
  doi          = {10.1080/10635150701607033},
  pmid         = {17849325},
  issn         = {1063-5157},
  abstract     = {Determining whether speciation and extinction rates depend on
                  the state of a particular character has been of long-standing
                  interest to evolutionary biologists. To assess the effect of a
                  character on diversification rates using likelihood methods
                  requires that we be able to calculate the probability that a
                  group of extant species would have evolved as observed, given
                  a particular model of the character's effect. Here we describe
                  how to calculate this probability for a phylogenetic tree and
                  a two-state (binary) character under a simple model of
                  evolution (the "BiSSE" model, binary-state speciation and
                  extinction). The model involves six parameters, specifying two
                  speciation rates (rate when the lineage is in state 0; rate
                  when in state 1), two extinction rates (when in state 0; when
                  in state 1), and two rates of character state change (from 0
                  to 1, and from 1 to 0). Using these probability calculations,
                  we can do maximum likelihood inference to estimate the model's
                  parameters and perform hypothesis tests (e.g., is the rate of
                  speciation elevated for one character state over the other?).
                  We demonstrate the application of the method using simulated
                  data with known parameter values.},
  url          = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=17849325&retmode=ref&cmd=prlinks}
}

@ARTICLE{Curran-Everett2013-im,
  title        = {Post-hoc data analysis: benefits and limitations},
  author       = {Curran-Everett, Douglas and Milgrom, Henry},
  journaltitle = {Curr. Opin. Allergy Clin. Immunol.},
  volume       = {13},
  issue        = {3},
  pages        = {223--224},
  date         = {2013-06},
  doi          = {10.1097/ACI.0b013e3283609831},
  pmid         = {23571411},
  issn         = {1528-4050,1473-6322},
  url          = {http://dx.doi.org/10.1097/ACI.0b013e3283609831},
  language     = {en}
}

@ARTICLE{Curran-Everett2013-wt,
  title        = {Letter to the editor. Sides of the story},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Clin. Exp. Pharmacol. Physiol.},
  volume       = {40},
  issue        = {8},
  pages        = {593},
  date         = {2013},
  doi          = {10.1111/1440-1681.12122},
  issn         = {0305-1870},
  url          = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=23701108&retmode=ref&cmd=prlinks}
}

@ARTICLE{FitzJohn2012-jk,
  title        = {Diversitree: comparative phylogenetic analyses of
                  diversification in {R}},
  author       = {FitzJohn, Richard G},
  journaltitle = {Methods Ecol. Evol.},
  volume       = {3},
  issue        = {6},
  pages        = {1084--1092},
  date         = {2012},
  doi          = {10.1111/j.2041-210X.2012.00234.x},
  url          = {http://doi.wiley.com/10.1111/j.2041-210X.2012.00234.x}
}

@ARTICLE{Nunn2001-oq,
  title        = {Comparative methods for studying primate adaptation and
                  allometry},
  author       = {Nunn, Charles L and Barton, Robert A},
  journaltitle = {Evol. Anthropol.},
  volume       = {10},
  issue        = {3},
  pages        = {81--98},
  date         = {2001},
  doi          = {10.1002/evan.1019},
  issn         = {1060-1538},
  abstract     = {In this article, we review developments in comparative
                  methodology that have emerged in the last fifteen years, with
                  particular emphasis on the importance of incorporating
                  phylogeny into comparative studies. We define “ comparative
                  study” as meaning analysis of trait ...},
  url          = {http://doi.wiley.com/10.1002/evan.1019}
}

@BOOK{Paradis2006-tr,
  title     = {Analysis of Phylogenetics and Evolution with {R}},
  author    = {Paradis, Emmanuel},
  publisher = {Springer},
  location  = {New York},
  date      = {2006},
  pagetotal = {386},
  isbn      = {9781461417422},
  url       = {http://books.google.com/books?id=FsScWggkW_cC&printsec=frontcover&dq=intitle:Analysis+of+Phylogenetics+and+Evolution+with+R&hl=&cd=1&source=gbs_api}
}

@ARTICLE{Stephens2016-if,
  title        = {False Discovery Rates: A New Deal},
  shorttitle   = {False Discovery Rates},
  author       = {Stephens, Matthew},
  journaltitle = {bioRxiv},
  pages        = {038216},
  date         = {2016-01-29},
  doi          = {10.1101/038216},
  abstract     = {We introduce a novel Empirical Bayes approach for large-scale
                  hypothesis testing, including estimating False Discovery Rates
                  (FDRs), and estimating effect sizes. Compared with existing
                  approaches to FDR analysis, the method has two key
                  differences. First, it assumes that the distribution of the
                  actual (unobserved) effects being tested is unimodal, with a
                  mode at 0. This "unimodal assumption" (UA), although natural
                  in many contexts, is very different from assumptions usually
                  made in FDR analyses, and yields more accurate inferences than
                  existing methods provided that it holds. The UA also
                  facilitates efficient and robust computation because
                  estimating the unimodal distribution involves solving a simple
                  convex optimization problem. Second, the method takes as its
                  input two numbers for each test (an effect size estimate, and
                  corresponding standard error), rather than the one number
                  usually used (p value, or z score). When available, using two
                  numbers instead of one helps account for variation in
                  measurement precision across tests. It also facilitates the
                  estimation of actual effect sizes, and our approach provides
                  interval estimates (credible regions) for each effect in
                  addition to measures of significance. To provide a bridge
                  between interval estimates and significance measures we
                  introduce the term "local false sign rate" to refer to the
                  probability of getting the sign of an effect wrong, and argue
                  that it is a superior measure of significance than the local
                  FDR because it is both more generally applicable, and can be
                  more robustly estimated. Our methods are implemented in an R
                  package ashr available from
                  http://github.com/stephens999/ashr.},
  url          = {http://biorxiv.org/content/early/2016/01/29/038216},
  urldate      = {2017-03-12},
  language     = {en}
}

@BOOK{Leek2016-cc,
  title     = {How to be a Modern Scientist},
  author    = {Leek, Jeffrey},
  publisher = {Leanpub},
  date      = {2016}
}

@ARTICLE{North2002-nu,
  title        = {A note on the calculation of empirical {P} values from Monte
                  Carlo procedures},
  author       = {North, B V and Curtis, D and Sham, P C},
  journaltitle = {Am. J. Hum. Genet.},
  volume       = {71},
  issue        = {2},
  pages        = {439--441},
  date         = {2002-08},
  doi          = {10.1086/341527},
  pmc          = {PMC379178},
  pmid         = {12111669},
  issn         = {0002-9297},
  url          = {http://dx.doi.org/10.1086/341527},
  language     = {en}
}

@ARTICLE{Nester1996-bn,
  title        = {An Applied Statistician's Creed},
  author       = {Nester, Marks R},
  journaltitle = {J. R. Stat. Soc. Ser. C Appl. Stat.},
  publisher    = {[Wiley, Royal Statistical Society]},
  volume       = {45},
  issue        = {4},
  pages        = {401--410},
  date         = {1996},
  doi          = {10.2307/2986064},
  issn         = {0035-9254,1467-9876},
  abstract     = {Hypothesis testing, as performed in the applied sciences, is
                  criticized. Then assumptions that the author believes should
                  be axiomatic in all statistical analyses are listed. These
                  assumptions render many hypothesis tests superfluous. The
                  author argues that the image of statisticians will not improve
                  until the nexus between hypothesis testing and statistics is
                  broken.},
  url          = {http://www.jstor.org/stable/2986064}
}

@ARTICLE{Lesaffre2007-gi,
  title        = {The logistic transform for bounded outcome scores},
  author       = {Lesaffre, Emmanuel and Rizopoulos, Dimitris and Tsonaka, Roula},
  journaltitle = {Biostatistics},
  volume       = {8},
  issue        = {1},
  pages        = {72--85},
  date         = {2007-01},
  doi          = {10.1093/biostatistics/kxj034},
  pmid         = {16597671},
  issn         = {1465-4644},
  abstract     = {The logistic transformation, originally suggested by Johnson
                  (1949), is applied to analyze responses that are restricted to
                  a finite interval (e.g. (0,1)), so-called bounded outcome
                  scores. Bounded outcome scores often have a non-standard
                  distribution, e.g. J- or U-shaped, precluding classical
                  parametric statistical approaches for analysis. Applying the
                  logistic transformation on a normally distributed random
                  variable, gives rise to a logit-normal (LN) distribution. This
                  distribution can take a variety of shapes on (0,1). Further,
                  the model can be extended to correct for (baseline)
                  covariates. Therefore, the method could be useful for
                  comparative clinical trials. Bounded outcomes can be found in
                  many research areas, e.g. drug compliance research,
                  quality-of-life studies, and pain (and pain relief) studies
                  using visual analog scores, but all these scores can attain
                  the boundary values 0 or 1. A natural extension of the above
                  approach is therefore to assume a latent score on 0,1) having
                  a LN distribution. Two cases are considered: (a) the bounded
                  outcome score is a proportion where the true probabilities
                  have a LN distribution on (0,1) and (b) the bounded outcome
                  score on [0,1] is a coarsened version of a latent score with a
                  LN distribution on (0,1). We also allow the variance (on the
                  transformed scale) to depend on treatment. The usefulness of
                  our approach for comparative clinical trials will be assessed
                  in this paper. It turns out to be important to distinguish the
                  case of equal and unequal variances. For a bounded outcome
                  score of the second type and with equal variances, our
                  approach comes close to ordinal probit (OP) regression.
                  However, ignoring the inequality of variances can lead to
                  highly biased parameter estimates. A simulation study compares
                  the performance of our approach with the two-sample Wilcoxon
                  test and with OP regression. Finally, the different methods
                  are illustrated on two data sets.},
  url          = {http://dx.doi.org/10.1093/biostatistics/kxj034},
  language     = {en}
}

@ARTICLE{Felsenstein1993-on,
  title        = {Is There Something Wrong with the Bootstrap on Phylogenies? A
                  Reply to Hillis and Bull},
  author       = {Felsenstein, Joseph and Kishino, Hirohisa},
  journaltitle = {Syst. Biol.},
  publisher    = {[Oxford University Press, Society of Systematic Biologists]},
  volume       = {42},
  issue        = {2},
  pages        = {193--200},
  date         = {1993},
  doi          = {10.2307/2992541},
  issn         = {1063-5157,1076-836X},
  url          = {http://www.jstor.org/stable/2992541}
}

@ARTICLE{Roff1994-gz,
  title        = {The estimation of the genetic correlation: the use of the
                  jackknife},
  author       = {Roff, Derek A and Preziozi, Richard},
  journaltitle = {Heredity},
  volume       = {73},
  pages        = {544--548},
  date         = {1994},
  issn         = {0018-067X},
  abstract     = {To understand fully the process of evolution of quantitative
                  traits it is necessary to be able to estimate the genetic
                  correlation and its associated standard error. At present,
                  estimation methods are available only for relatively simple
                  designs. An alternative procedure is to use the correlation of
                  family means as an estimate of the genetic correlation. We
                  evaluate the utility of the family mean method and that of the
                  more general procedure, the jackknife. The family mean method
                  is shown to be potentially very biased unless family sizes are
                  very large ( 20), and therefore its general utility is
                  questionable. However, the jackknife method does provide valid
                  estimates of both the correlations (phenotypic and genetic)
                  and their standard errors.Keywords: bias, confidence limits,
                  genetic correlation, heritability, jackknife, phenotypic
                  correlation},
  url          = {http://www.nature.com/hdy/journal/v73/n5/abs/hdy1994153a.html},
  urldate      = {2017-03-19}
}

@ARTICLE{Roff2008-on,
  title        = {Comparing sire and dam estimates of heritability: jackknife
                  and likelihood approaches},
  author       = {Roff, Derek A},
  journaltitle = {Heredity},
  volume       = {100},
  issue        = {1},
  pages        = {32--38},
  date         = {2008-01},
  doi          = {10.1038/sj.hdy.6801048},
  pmid         = {17786161},
  issn         = {0018-067X,1365-2540},
  abstract     = {Three estimates of heritability are available from the
                  half-sib pedigree design: the sire, dam and genotypic
                  estimates. Because of its significantly smaller standard
                  error, the genotypic estimate is preferred provided that there
                  are no non-additive effects that inflate the estimate. I
                  present two methods to test for such effects: these are a
                  t-test of the paired sire and dam pseudovalues from the
                  jackknife procedure and the likelihood ratio test from the
                  animal model. Both methods are shown to be valid tests for
                  significant dominance and/or maternal effects. SPLUS coding
                  for the implementation of the jackknife method is provided.
                  Unless sample sizes are very large, the power of the tests is
                  low and hence caution is advised in the use of the genotypic
                  estimate following a nonsignificant test. An approximate power
                  analysis can be done using the data from the jackknife method
                  but the estimated power is typically a substantial
                  underestimate of the true power and its use is not
                  recommended.},
  url          = {http://dx.doi.org/10.1038/sj.hdy.6801048},
  language     = {en}
}

@ARTICLE{Churchill1994-us,
  title        = {Empirical threshold values for quantitative trait mapping},
  author       = {Churchill, G A and Doerge, R W},
  journaltitle = {Genetics},
  publisher    = {Genetics Soc America},
  volume       = {138},
  issue        = {3},
  pages        = {963--971},
  date         = {1994-11},
  pmc          = {PMC1206241},
  pmid         = {7851788},
  issn         = {0016-6731},
  abstract     = {The detection of genes that control quantitative characters is
                  a problem of great interest to the genetic mapping community.
                  Methods for locating these quantitative trait loci (QTL)
                  relative to maps of genetic markers are now widely used. This
                  paper addresses an issue common to all QTL mapping methods,
                  that of determining an appropriate threshold value for
                  declaring significant QTL effects. An empirical method is
                  described, based on the concept of a permutation test, for
                  estimating threshold values that are tailored to the
                  experimental data at hand. The method is demonstrated using
                  two real data sets derived from F(2) and recombinant inbred
                  plant populations. An example using simulated data from a
                  backcross design illustrates the effect of marker density on
                  threshold values.},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/7851788},
  language     = {en}
}

@ARTICLE{Yang2014-cz,
  title        = {Advantages and pitfalls in the application of mixed-model
                  association methods},
  author       = {Yang, Jian and Zaitlen, Noah A and Goddard, Michael E and
                  Visscher, Peter M and Price, Alkes L},
  journaltitle = {Nat. Genet.},
  volume       = {46},
  issue        = {2},
  pages        = {100--106},
  date         = {2014-02},
  doi          = {10.1038/ng.2876},
  pmc          = {PMC3989144},
  pmid         = {24473328},
  issn         = {1061-4036,1546-1718},
  abstract     = {Mixed linear models are emerging as a method of choice for
                  conducting genetic association studies in humans and other
                  organisms. The advantages of the mixed-linear-model
                  association (MLMA) method include the prevention of false
                  positive associations due to population or relatedness
                  structure and an increase in power obtained through the
                  application of a correction that is specific to this
                  structure. An underappreciated point is that MLMA can also
                  increase power in studies without sample structure by
                  implicitly conditioning on associated loci other than the
                  candidate locus. Numerous variations on the standard MLMA
                  approach have recently been published, with a focus on
                  reducing computational cost. These advances provide
                  researchers applying MLMA methods with many options to choose
                  from, but we caution that MLMA methods are still subject to
                  potential pitfalls. Here we describe and quantify the
                  advantages and pitfalls of MLMA methods as a function of study
                  design and provide recommendations for the application of
                  these methods in practical settings.},
  url          = {http://dx.doi.org/10.1038/ng.2876},
  language     = {en}
}

@BOOK{Lynch1998-qq,
  title     = {Genetics and Analysis of Quantitative Traits},
  author    = {Lynch, Michael and Walsh, Bruce},
  publisher = {Sinauer Associates},
  date      = {1998}
}

@BOOK{Falconer1996-yv,
  title     = {Introduction to Quantitative Genetics},
  author    = {Falconer, Douglas S and Mackay, Trudy F C},
  publisher = {Pearson},
  edition   = {4th},
  date      = {1996}
}

@ARTICLE{Smaldino2016-yg,
  title        = {The natural selection of bad science},
  author       = {Smaldino, Paul E and McElreath, Richard},
  journaltitle = {R Soc Open Sci},
  volume       = {3},
  issue        = {9},
  pages        = {160384},
  date         = {2016-09},
  doi          = {10.1098/rsos.160384},
  pmc          = {PMC5043322},
  pmid         = {27703703},
  issn         = {2054-5703},
  abstract     = {Poor research design and data analysis encourage
                  false-positive findings. Such poor methods persist despite
                  perennial calls for improvement, suggesting that they result
                  from something more than just misunderstanding. The
                  persistence of poor methods results partly from incentives
                  that favour them, leading to the natural selection of bad
                  science. This dynamic requires no conscious strategizing-no
                  deliberate cheating nor loafing-by scientists, only that
                  publication is a principal factor for career advancement. Some
                  normative methods of analysis have almost certainly been
                  selected to further publication instead of discovery. In order
                  to improve the culture of science, a shift must be made away
                  from correcting misunderstandings and towards rewarding
                  understanding. We support this argument with empirical
                  evidence and computational modelling. We first present a
                  60-year meta-analysis of statistical power in the behavioural
                  sciences and show that power has not improved despite repeated
                  demonstrations of the necessity of increasing power. To
                  demonstrate the logical consequences of structural incentives,
                  we then present a dynamic model of scientific communities in
                  which competing laboratories investigate novel or previously
                  published hypotheses using culturally transmitted research
                  methods. As in the real world, successful labs produce more
                  'progeny,' such that their methods are more often copied and
                  their students are more likely to start labs of their own.
                  Selection for high output leads to poorer methods and
                  increasingly high false discovery rates. We additionally show
                  that replication slows but does not stop the process of
                  methodological deterioration. Improving the quality of
                  research requires change at the institutional level.},
  url          = {http://dx.doi.org/10.1098/rsos.160384},
  keywords     = {Campbell’s Law; cultural evolution; incentives; metascience;
                  replication; statistical power},
  language     = {en}
}

@ARTICLE{Friendly2006-zz,
  title        = {Data Ellipses, {HE} Plots and Reduced-Rank Displays for
                  Multivariate Linear Models: {SAS} Software and Examples},
  author       = {Friendly, Michael},
  journaltitle = {Journal of Statistical Software},
  volume       = {17},
  issue        = {6},
  pages        = {1--43},
  date         = {2006}
}

@ARTICLE{Wellek2017-vh,
  title        = {A critical evaluation of the current "p-value controversy"},
  author       = {Wellek, Stefan},
  journaltitle = {Biom. J.},
  volume       = {59},
  issue        = {5},
  pages        = {854--872},
  date         = {2017-09},
  doi          = {10.1002/bimj.201700001},
  pmid         = {28504870},
  issn         = {0323-3847,1521-4036},
  abstract     = {This article has been triggered by the initiative launched in
                  March 2016 by the Board of Directors of the American
                  Statistical Association (ASA) to counteract the current
                  p-value focus of statistical research practices that allegedly
                  "have contributed to a reproducibility crisis in science." It
                  is pointed out that in the very wide field of statistics
                  applied to medicine, many of the problems raised in the ASA
                  statement are not as severe as in the areas the authors may
                  have primarily in mind, although several of them are
                  well-known experts in biostatistics and epidemiology. This is
                  mainly due to the fact that a large proportion of medical
                  research falls under the realm of a well developed body of
                  regulatory rules banning the most frequently occurring misuses
                  of p-values. Furthermore, it is argued that reducing the
                  statistical hypotheses tests nowadays available to the class
                  of procedures based on p-values calculated under a traditional
                  one-point null hypothesis amounts to ignoring important
                  developments having taken place and going on within the
                  statistical sciences. Although hypotheses testing is still an
                  indispensable part of the statistical methodology required in
                  medical and other areas of empirical research, there is a
                  large repertoire of methods based on different paradigms of
                  inference that provide ample options for supplementing and
                  enhancing the methods of data analysis blamed in the ASA
                  statement for causing a crisis.},
  url          = {http://dx.doi.org/10.1002/bimj.201700001},
  keywords     = {Bayesian inference; Data mining; Measures of evidence;
                  Multiplicity correction; Prediction; Reproducibility of
                  experiments},
  language     = {en}
}

@ARTICLE{Wilson2010-ix,
  title        = {An ecologist’s guide to the animal model},
  author       = {Wilson, Alastair J and Réale, Denis and Clements, Michelle N
                  and Morrissey, Michael M and Postma, Erik and Walling, Craig A
                  and Kruuk, Loeske E B and Nussey, Daniel H},
  journaltitle = {J. Anim. Ecol.},
  volume       = {79},
  issue        = {1},
  pages        = {13--26},
  date         = {2010},
  doi          = {10.1111/j.1365-2656.2009.01639.x},
  issn         = {0021-8790},
  url          = {http://dx.doi.org/10.1111/j.1365-2656.2009.01639.x}
}

@ARTICLE{Hadfield2010-pp,
  title        = {{MCMC} Methods for Multi-response Generalized Linear Mixed
                  Models: The {MCMCglmm} {R} Package},
  author       = {Hadfield, Jarrod D},
  journaltitle = {J. Stat. Softw.},
  volume       = {33},
  issue        = {2},
  pages        = {1--22},
  date         = {2010}
}

@MISC{Hadfield2009-ug,
  title  = {{MCMCglmm}: Markov chain Monte Carlo methods for Generalised Linear
            Mixed Models},
  author = {Hadfield, Jarrod D},
  pages  = {1--25},
  date   = {2009},
  issn   = {1356-689X}
}

@ARTICLE{Bailleul2016-tk,
  title        = {Fusion Patterns in the Skulls of Modern Archosaurs Reveal That
                  Sutures Are Ambiguous Maturity Indicators for the Dinosauria},
  author       = {Bailleul, Alida M and Scannella, John B and Horner, John R and
                  Evans, David C},
  journaltitle = {PLoS One},
  volume       = {11},
  issue        = {2},
  pages        = {e0147687},
  date         = {2016},
  doi          = {10.1371/journal.pone.0147687},
  abstract     = {The sutures of the skulls of vertebrates are generally open
                  early in life and slowly close as maturity is attained. The
                  assumption that all vertebrates follow this pattern of
                  progressive sutural closure has been used to assess maturity
                  in the fossil remains of non-avian dinosaurs. Here, we test
                  this assumption in two members of the Extant Phylogenetic
                  Bracket of the Dinosauria, the emu, Dromaius novaehollandiae
                  and the American alligator, Alligator mississippiensis, by
                  investigating the sequence and timing of sutural fusion in
                  their skulls. As expected, almost all the sutures in the emu
                  skull progressively close (i.e., they get narrower) and then
                  obliterate during ontogeny. However, in the American
                  alligator, only two sutures out of 36 obliterate completely
                  and they do so during embryonic development. Surprisingly, as
                  maturity progresses, many sutures of alligators become wider
                  in large individuals compared to younger, smaller individuals.
                  Histological and histomorphometric analyses on two sutures and
                  one synchondrosis in an ontogenetic series of American
                  alligator confirmed our morphological observations. This
                  pattern of sutural widening might reflect feeding biomechanics
                  and dietary changes through ontogeny. Our findings show that
                  progressive sutural closure is not always observed in extant
                  archosaurs, and therefore suggest that cranial sutural fusion
                  is an ambiguous proxy for assessing maturity in non-avian
                  dinosaurs.},
  url          = {http://dx.doi.org/10.1371/journal.pone.0147687},
  urldate      = {2016-02-11}
}

@ARTICLE{Grafen1989-xz,
  title        = {The phylogenetic regression},
  author       = {Grafen, Alan},
  journaltitle = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
  volume       = {326},
  issue        = {1233},
  pages        = {119--157},
  date         = {1989},
  issn         = {0962-8436},
  url          = {http://www.jstor.org/stable/2396904},
  urldate      = {2016-05-18}
}

@ARTICLE{Zanno2011-sm,
  title        = {Herbivorous ecomorphology and specialization patterns in
                  theropod dinosaur evolution},
  author       = {Zanno, Lindsay E and Makovicky, Peter J},
  journaltitle = {Proc. Natl. Acad. Sci. U. S. A.},
  volume       = {108},
  issue        = {1},
  pages        = {232--237},
  date         = {2011-01-04},
  doi          = {10.1073/pnas.1011924108},
  pmc          = {PMC3017133},
  pmid         = {21173263},
  issn         = {0027-8424,1091-6490},
  abstract     = {Interpreting key ecological parameters, such as diet, of
                  extinct organisms without the benefit of direct observation or
                  explicit fossil evidence poses a formidable challenge for
                  paleobiological studies. To date, dietary categorizations of
                  extinct taxa are largely generated by means of modern analogs;
                  however, for many species the method is subject to
                  considerable ambiguity. Here we present a refined approach for
                  assessing trophic habits in fossil taxa and apply the method
                  to coelurosaurian dinosaurs--a clade for which diet is
                  particularly controversial. Our findings detect 21
                  morphological features that exhibit statistically significant
                  correlations with extrinsic fossil evidence of coelurosaurian
                  herbivory, such as stomach contents and a gastric mill. These
                  traits represent quantitative, extrinsically founded proxies
                  for identifying herbivorous ecomorphology in fossils and are
                  robust despite uncertainty in phylogenetic relationships among
                  major coelurosaurian subclades. The distribution of these
                  features suggests that herbivory was widespread among
                  coelurosaurians, with six major subclades displaying
                  morphological evidence of the diet, and that contrary to
                  previous thought, hypercarnivory was relatively rare and
                  potentially secondarily derived. Given the potential for
                  repeated, independent evolution of herbivory in Coelurosauria,
                  we also test for repetitive patterns in the appearance of
                  herbivorous traits within sublineages using rank concordance
                  analysis. We find evidence for a common succession of
                  increasing specialization to herbivory in the subclades
                  Ornithomimosauria and Oviraptorosauria, perhaps underlain by
                  intrinsic functional and/or developmental constraints, as well
                  as evidence indicating that the early evolution of a beak in
                  coelurosaurians correlates with an herbivorous diet.},
  url          = {http://dx.doi.org/10.1073/pnas.1011924108},
  language     = {en}
}

@ARTICLE{Eastman2011-li,
  title        = {A novel comparative method for identifying shifts in the rate
                  of character evolution on trees},
  author       = {Eastman, Jonathan M and Alfaro, Michael E and Joyce, Paul and
                  Hipp, Andrew L and Harmon, Luke J},
  journaltitle = {Evolution},
  volume       = {65},
  issue        = {12},
  pages        = {3578--3589},
  date         = {2011-12},
  doi          = {10.1111/j.1558-5646.2011.01401.x},
  pmid         = {22133227},
  issn         = {0014-3820,1558-5646},
  abstract     = {Evolutionary biologists since Darwin have been fascinated by
                  differences in the rate of trait-evolutionary change across
                  lineages. Despite this continued interest, we still lack
                  methods for identifying shifts in evolutionary rates on the
                  growing tree of life while accommodating uncertainty in the
                  evolutionary process. Here we introduce a Bayesian approach
                  for identifying complex patterns in the evolution of
                  continuous traits. The method (auteur) uses reversible-jump
                  Markov chain Monte Carlo sampling to more fully characterize
                  the complexity of trait evolution, considering models that
                  range in complexity from those with a single global rate to
                  potentially ones in which each branch in the tree has its own
                  independent rate. This newly introduced approach performs well
                  in recovering simulated rate shifts and simulated rates for
                  datasets nearing the size typical for comparative phylogenetic
                  study (i.e., ≥64 tips). Analysis of two large empirical
                  datasets of vertebrate body size reveal overwhelming support
                  for multiple-rate models of evolution, and we observe
                  exceptionally high rates of body-size evolution in a group of
                  emydid turtles relative to their evolutionary background.
                  auteur will facilitate identification of exceptional
                  evolutionary dynamics, essential to the study of both adaptive
                  radiation and stasis.},
  url          = {http://dx.doi.org/10.1111/j.1558-5646.2011.01401.x},
  language     = {en}
}

@ARTICLE{Maddison1991-fz,
  title        = {Squared-Change Parsimony Reconstructions of Ancestral States
                  for Continuous-Valued Characters on a Phylogenetic Tree},
  author       = {Maddison, Wayne P},
  journaltitle = {Syst. Biol.},
  publisher    = {Oxford University Press},
  volume       = {40},
  issue        = {3},
  pages        = {304--314},
  date         = {1991-09-01},
  doi          = {10.1093/sysbio/40.3.304},
  issn         = {1063-5157},
  abstract     = {A direct algorithm is described to reconstruct on a
                  phylogenetic tree the ancestral states of a continuous-valued
                  character, using a parsimony criterion that minimizes the sum
                  of squared changes along the branches. It is shown that when
                  the squared changes are inversely weighted by the lengths of
                  the branches, the squared-change parsimony reconstruction is
                  that which has maximum posterior probability under a Brownian
                  motion model of evolution. The squared-change parsimony
                  estimates are also closely related to the contrasts in
                  Felsenstein's test of character correlation.},
  url          = {http://sysbio.oxfordjournals.org/content/40/3/304.short},
  urldate      = {2017-02-08}
}

@ARTICLE{Mooers1999-wt,
  title        = {Reconstructing Ancestor States with Maximum Likelihood:
                  Support for One-and Two-Rate Models},
  author       = {Mooers, Arne and Schluter, Dolph},
  journaltitle = {Syst. Biol.},
  publisher    = {[Oxford University Press, Society of Systematic Biologists]},
  volume       = {48},
  issue        = {3},
  pages        = {623--633},
  date         = {1999},
  issn         = {1063-5157},
  url          = {http://www.jstor.org/stable/2585329}
}

@ARTICLE{Maddison1990-sl,
  title        = {A Method for Testing the Correlated Evolution of Two Binary
                  Characters: Are Gains or Losses Concentrated on Certain
                  Branches of a Phylogenetic Tree?},
  author       = {Maddison, Wayne P},
  journaltitle = {Evolution},
  publisher    = {[Society for the Study of Evolution, Wiley]},
  volume       = {44},
  issue        = {3},
  pages        = {539--557},
  date         = {1990},
  doi          = {10.2307/2409434},
  issn         = {0014-3820},
  abstract     = {A method is presented for assessing whether changes in a
                  binary character are more concentrated than expected by chance
                  on certain branches of a phylogenetic tree. It can be used to
                  test for correlated evolution of two characters by asking
                  whether changes in the first character are significantly
                  concentrated on those branches on which the second character
                  has a specified state. Thus, one could test whether this
                  specified state is associated with, and thus might enable or
                  select, gains or losses in the first character. The
                  probability of achieving a concentration as or more extreme
                  than that observed under the null hypotheses that changes are
                  distributed randomly on the cladogram is obtained by
                  calculating (a) the number of ways that n gains and m losses
                  can be distributed on the cladogram and (b) the number of ways
                  that p gains q losses can be distributed on the branches of
                  interest given n gains and m losses in the cladogram overall.
                  Summing (b) for appropriate p and q then dividing by (a)
                  yields the desired probability. Simulations suggest that
                  biases resulting from errors in parsimony reconstructions of
                  ancestral states are not extreme.},
  url          = {http://www.jstor.org/stable/2409434}
}

@ARTICLE{Slater2012-as,
  title        = {Fitting models of continuous trait evolution to incompletely
                  sampled comparative data using approximate Bayesian
                  computation},
  author       = {Slater, Graham J and Harmon, Luke J and Wegmann, Daniel and
                  Joyce, Paul and Revell, Liam J and Alfaro, Michael E},
  journaltitle = {Evolution},
  volume       = {66},
  issue        = {3},
  pages        = {752--762},
  date         = {2012-03},
  doi          = {10.1111/j.1558-5646.2011.01474.x},
  pmid         = {22380438},
  issn         = {0014-3820,1558-5646},
  abstract     = {In recent years, a suite of methods has been developed to fit
                  multiple rate models to phylogenetic comparative data.
                  However, most methods have limited utility at broad
                  phylogenetic scales because they typically require complete
                  sampling of both the tree and the associated phenotypic data.
                  Here, we develop and implement a new, tree-based method called
                  MECCA (Modeling Evolution of Continuous Characters using ABC)
                  that uses a hybrid likelihood/approximate Bayesian computation
                  (ABC)-Markov-Chain Monte Carlo approach to simultaneously
                  infer rates of diversification and trait evolution from
                  incompletely sampled phylogenies and trait data. We
                  demonstrate via simulation that MECCA has considerable power
                  to choose among single versus multiple evolutionary rate
                  models, and thus can be used to test hypotheses about changes
                  in the rate of trait evolution across an incomplete tree of
                  life. We finally apply MECCA to an empirical example of body
                  size evolution in carnivores, and show that there is no
                  evidence for an elevated rate of body size evolution in the
                  pinnipeds relative to terrestrial carnivores. ABC approaches
                  can provide a useful alternative set of tools for future
                  macroevolutionary studies where likelihood-dependent
                  approaches are lacking.},
  url          = {http://dx.doi.org/10.1111/j.1558-5646.2011.01474.x},
  language     = {en}
}

@ARTICLE{Huelsenbeck2001-sm,
  title        = {Empirical and hierarchical Bayesian estimation of ancestral
                  states},
  author       = {Huelsenbeck, J P and Bollback, J P},
  journaltitle = {Syst. Biol.},
  volume       = {50},
  issue        = {3},
  pages        = {351--366},
  date         = {2001-06},
  pmid         = {12116580},
  issn         = {1063-5157},
  abstract     = {Several methods have been proposed to infer the states at the
                  ancestral nodes on a phylogeny. These methods assume a
                  specific tree and set of branch lengths when estimating the
                  ancestral character state. Inferences of the ancestral states,
                  then, are conditioned on the tree and branch lengths being
                  true. We develop a hierarchical Bayes method for inferring the
                  ancestral states on a tree. The method integrates over
                  uncertainty in the tree, branch lengths, and substitution
                  model parameters by using Markov chain Monte Carlo. We compare
                  the hierarchical Bayes inferences of ancestral states with
                  inferences of ancestral states made under the assumption that
                  a specific tree is correct. We find that the methods are
                  correlated, but that accommodating uncertainty in parameters
                  of the phylogenetic model can make inferences of ancestral
                  states even more uncertain than they would be in an empirical
                  Bayes analysis.},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/12116580},
  language     = {en}
}

@ARTICLE{Blomberg2003-jk,
  title        = {Testing for phylogenetic signal in comparative data:
                  Behavioral traits are more labile},
  author       = {Blomberg, Simon P and Garland, Jr, Theodore and Ives, Anthony
                  R},
  journaltitle = {Evolution},
  volume       = {57},
  issue        = {4},
  pages        = {717--745},
  date         = {2003},
  issn         = {0014-3820}
}

@ARTICLE{Garland1993-qj,
  title        = {Phylogenetic analysis of covariance by computer simulation},
  author       = {Garland, Jr, Theodore and Dickerman, Allan and Janis,
                  Christine M and Jones, Jason},
  journaltitle = {Syst. Biol.},
  volume       = {42},
  issue        = {3},
  pages        = {265--292},
  date         = {1993},
  issn         = {1063-5157}
}

@ARTICLE{lavin_morphometrics_2008,
  title        = {Morphometrics of the avian small intestine compared with that
                  of nonflying mammals: a phylogenetic approach},
  author       = {Lavin, Shana R and Karasov, William H and Ives, Anthony R and
                  Middleton, Kevin M and Garland, Jr, Theodore},
  journaltitle = {Physiol. Biochem. Zool.},
  volume       = {81},
  issue        = {5},
  pages        = {526--550},
  date         = {2008},
  doi          = {10.1086/522641},
  issn         = {1522-2152,1537-5293},
  url          = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=18754728&retmode=ref&cmd=prlinks}
}

@ARTICLE{Leek2010-gx,
  title        = {Tackling the widespread and critical impact of batch effects
                  in high-throughput data},
  author       = {Leek, Jeffrey T and Scharpf, Robert B and Bravo, Héctor
                  Corrada and Simcha, David and Langmead, Benjamin and Johnson,
                  W Evan and Geman, Donald and Baggerly, Keith and Irizarry,
                  Rafael A},
  journaltitle = {Nat. Rev. Genet.},
  volume       = {11},
  issue        = {10},
  pages        = {733--739},
  date         = {2010-10},
  doi          = {10.1038/nrg2825},
  pmc          = {PMC3880143},
  pmid         = {20838408},
  issn         = {1471-0056,1471-0064},
  abstract     = {High-throughput technologies are widely used, for example to
                  assay genetic variants, gene and protein expression, and
                  epigenetic modifications. One often overlooked complication
                  with such studies is batch effects, which occur because
                  measurements are affected by laboratory conditions, reagent
                  lots and personnel differences. This becomes a major problem
                  when batch effects are correlated with an outcome of interest
                  and lead to incorrect conclusions. Using both published
                  studies and our own analyses, we argue that batch effects (as
                  well as other technical and biological artefacts) are
                  widespread and critical to address. We review experimental and
                  computational approaches for doing so.},
  url          = {http://dx.doi.org/10.1038/nrg2825},
  language     = {en}
}

@ARTICLE{Curran-Everett2000-qv,
  title        = {Multiple comparisons: philosophies and illustrations},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Am. J. Physiol. Regul. Integr. Comp. Physiol.},
  volume       = {279},
  issue        = {1},
  pages        = {R1--8},
  date         = {2000-07},
  issn         = {0363-6119},
  abstract     = {Statistical procedures underpin the process of scientific
                  discovery. As researchers, one way we use these procedures is
                  to test the validity of a null hypothesis. Often, we test the
                  validity of more than one null hypothesis. If we fail to use
                  an appropriate procedure to account for this multiplicity,
                  then we are more likely to reach a wrong scientific
                  conclusion[---]we are more likely to make a mistake. In
                  physiology, experiments that involve multiple comparisons are
                  common: of the original articles published in 1997 by the
                  American Physiological Society, ~40\% cite a multiple
                  comparison procedure. In this review, I demonstrate the
                  statistical issue embedded in multiple comparisons, and I
                  summarize the philosophies of handling this issue. I also
                  illustrate the three procedures[---]Newman-Keuls, Bonferroni,
                  least significant difference[---]cited most often in my
                  literature review; each of these procedures is of limited
                  practical value. Last, I demonstrate the false discovery rate
                  procedure, a promising development in multiple comparisons.
                  The false discovery rate procedure may be the best practical
                  solution to the problems of multiple comparisons that exist
                  within physiology and other scientific disciplines.},
  url          = {http://ajpregu.physiology.org/content/279/1/R1}
}

@BOOK{Hochberg1987-em,
  title     = {Multiple comparison procedures},
  author    = {Hochberg, Yosef and Tamhane, Ajit C},
  publisher = {Wiley},
  location  = {New York},
  date      = {1987},
  isbn      = {9780471822226,9780471822226},
  abstract  = {Offering a balanced, up-to-date view of multiple comparison
               procedures, this book refutes the belief held by some
               statisticians that such procedures have no place in data
               analysis. With equal emphasis on theory and applications, it
               establishes the advantages of multiple comparison techniques in
               reducing error rates and in ensuring the validity of statistical
               inferences. Provides detailed descriptions of the derivation and
               implementation of a variety of procedures, paying particular
               attention to classical approaches and confidence estimation
               procedures. Also discusses the benefits and drawbacks of other
               methods. Numerous examples and tables for implementing procedures
               are included, making this work both practical and informative.},
  language  = {English}
}

@ARTICLE{Benjamini2010-dp,
  title        = {Simultaneous and selective inference: Current successes and
                  future challenges},
  shorttitle   = {Simultaneous and selective inference},
  author       = {Benjamini, Yoav},
  journaltitle = {Biom. J.},
  volume       = {52},
  issue        = {6},
  pages        = {708--721},
  date         = {2010-12},
  doi          = {10.1002/bimj.200900299},
  pmid         = {21154895},
  issn         = {0323-3847,1521-4036},
  abstract     = {The previous decade can be viewed as a second golden for era
                  Multiple Comparisons research. I argue that much of the
                  success stems from our being able to address real current
                  needs. At the same time, this success generated a plethora of
                  concepts for error rate and power, as well as multiplicity of
                  methods for addressing them. These confuse the users of our
                  methodology and pose a threat. To avoid the threat, it is our
                  responsibility to match our theoretical goals to the goals of
                  the users of statistics. Only then should we match the methods
                  to the theoretical goals. Considerations related to such needs
                  are discussed: simultaneous inference or selective inference,
                  testing or estimation, decision making or scientific
                  reporting. I then further argue that the vitality of our field
                  in the future - as a research area - depends upon our ability
                  to continue and address the real needs of statistical analyses
                  in current problems. Two application areas offering new
                  challenges have received less attention in our community to
                  date are discussed. Safety analysis in clinical trials, where
                  I offer an aggregated safety assessment methodology and
                  functional Magnetic Resonance Imaging.},
  url          = {http://dx.doi.org/10.1002/bimj.200900299},
  language     = {en}
}

@BOOK{Bretz2010-cy,
  title     = {Multiple Comparisons Using {R}},
  author    = {Bretz, Frank and Hothorn, Torsten and Westfall, Peter},
  publisher = {Taylor \& Francis},
  location  = {Boca Raton, FL},
  date      = {2010-07-27},
  pagetotal = {205},
  isbn      = {9781584885740,9781584885740},
  abstract  = {Adopting a unifying theme based on maximum statistics, Multiple
               Comparisons Using R describes the common underlying theory of
               multiple comparison procedures through numerous examples. It also
               presents a detailed description of available software
               implementations in R. The R packages and source code for the
               analyses are available at http://CRAN.R-project.org After giving
               examples of multiplicity problems, the book covers general
               concepts and basic multiple comparisons procedures, including the
               Bonferroni method and Simes’ test. It then shows how to perform
               parametric multiple comparisons in standard linear models and
               general parametric models. It also introduces the multcomp
               package in R, which offers a convenient interface to perform
               multiple comparisons in a general context. Following this
               theoretical framework, the book explores applications involving
               the Dunnett test, Tukey’s all pairwise comparisons, and general
               multiple contrast tests for standard regression models,
               mixed-effects models, and parametric survival models. The last
               chapter reviews other multiple comparison procedures, such as
               resampling-based procedures, methods for group sequential or
               adaptive designs, and the combination of multiple comparison
               procedures with modeling techniques. Controlling multiplicity in
               experiments ensures better decision making and safeguards against
               false claims. A self-contained introduction to multiple
               comparison procedures, this book offers strategies for
               constructing the procedures and illustrates the framework for
               multiple hypotheses testing in general parametric models. It is
               suitable for readers with R experience but limited knowledge of
               multiple comparison procedures and vice versa. See Dr. Bretz
               discuss the book.},
  language  = {en}
}

@BOOK{Dudoit2008-tx,
  title     = {Multiple Testing Procedures with Applications to Genomics},
  author    = {Dudoit, Sandrine and van der Laan, M J},
  publisher = {Springer},
  location  = {New York},
  date      = {2008},
  isbn      = {9780387493169,9780387493169},
  language  = {English}
}

@INBOOK{Harter1980-gb,
  title     = {Early history of multiple comparison tests},
  author    = {Harter, H Leon},
  editor    = {Krishnaiah, P R},
  booktitle = {Handbook of Statistics},
  publisher = {Elsevier},
  location  = {Amsterdam},
  volume    = {1},
  pages     = {617--622},
  date      = {1980},
  doi       = {10.1016/S0169-7161(80)80049-6},
  abstract  = {Publisher Summary The problem of multiple comparisons is that of
               comparing statistical measures (means, proportions, etc.) of the
               properties or effects of the pairs of the levels of a factor
               (varieties, treatments, locations, etc.). If there are only two
               levels of the factor, a comparison of the values of the measure
               of interest for the two levels is quite simple and
               straightforward and statistical tests of the significance of the
               difference between two means, two proportions, two variances,
               etc., are well known. Then the question arises as to the way to
               take an account of the number of levels and the rank in the group
               of the two levels singled out for attention with regard to the
               measure of interest. The relevance of this ranking in testing the
               significance of the difference between two levels or between one
               level and the average for all of the levels has long been
               recognized. The ten years immediately following the close of
               World War II saw a great increase in interest in multiple
               comparisons, especially in the United States. The chapter
               discusses the early history of multiple comparison tests.},
  chapter   = {19},
  url       = {http://dx.doi.org/10.1016/S0169-7161(80)80049-6}
}

@BOOK{Westfall1993-ye,
  title      = {Resampling-Based Multiple Testing: Examples and Methods for
                {P}-Value Adjustment},
  shorttitle = {Resampling-based multiple testing},
  author     = {Westfall, Peter H and Stanley Young, S},
  publisher  = {John Wiley \& Sons},
  location   = {New York},
  date       = {1993-01-05},
  pagetotal  = {340},
  isbn       = {9780471557616},
  abstract   = {Combines recent developments in resampling technology (including
                the bootstrap) with new methods for multiple testing that are
                easy to use, convenient to report and widely applicable.
                Software from SAS Institute is available to execute many of the
                methods and programming is straightforward for other
                applications. Explains how to summarize results using adjusted
                p-values which do not necessitate cumbersome table look-ups.
                Demonstrates how to incorporate logical constraints among
                hypotheses, further improving power.},
  url        = {https://market.android.com/details?id=book-nuQXORVGI1QC},
  language   = {en}
}

@THESIS{Duncan1947-xp,
  title       = {Significance tests for differences between ranked variates
                 drawn from normal populations},
  author      = {Duncan, David B},
  institution = {Iowa State College},
  location    = {Ames, IA},
  date        = {1947}
}

@BOOK{Duncan1951-wo,
  title     = {A significance test for differences between ranked treatments in
               an analysis of variance},
  author    = {Duncan, David B},
  publisher = {Virginia Polytechnic Institute},
  volume    = {2},
  pages     = {171--189},
  date      = {1951},
  issn      = {0042-658X}
}

@BOOK{Duncan1951-hv,
  title     = {On the properties of the multiple comparisons test},
  author    = {Duncan, David B},
  publisher = {Virginia Polytechnic Institute},
  volume    = {3},
  pages     = {49--67},
  date      = {1951},
  issn      = {0042-658X}
}

@ARTICLE{Duncan1955-ry,
  title        = {Multiple Range and Multiple {F} Tests},
  author       = {Duncan, David B},
  journaltitle = {Biometrics},
  publisher    = {[Wiley, International Biometric Society]},
  volume       = {11},
  issue        = {1},
  pages        = {1--42},
  date         = {1955},
  doi          = {10.2307/3001478},
  issn         = {0006-341X,1541-0420},
  url          = {http://www.jstor.org/stable/3001478},
  urldate      = {2015-02-24}
}

@ARTICLE{Tukey1949-ge,
  title        = {Comparing individual means in the analysis of variance},
  author       = {Tukey, John W},
  journaltitle = {Biometrics},
  volume       = {5},
  issue        = {2},
  pages        = {99--114},
  date         = {1949-06},
  doi          = {10.2307/3001913},
  pmid         = {18151955},
  issn         = {0006-341X},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/18151955},
  urldate      = {2015-02-24},
  language     = {en}
}

@ARTICLE{Duncan1957-dc,
  title        = {Multiple Range Tests for Correlated and Heteroscedastic Means},
  author       = {Duncan, David B},
  journaltitle = {Biometrics},
  publisher    = {[Wiley, International Biometric Society]},
  volume       = {13},
  issue        = {2},
  pages        = {164--176},
  date         = {1957},
  doi          = {10.2307/2527799},
  issn         = {0006-341X,1541-0420},
  url          = {http://www.jstor.org/stable/2527799},
  urldate      = {2015-02-24}
}

@ARTICLE{Scheffe1953-bx,
  title        = {A Method for Judging all Contrasts in the Analysis of Variance},
  author       = {Scheffé, Henry},
  journaltitle = {Biometrika},
  publisher    = {[Oxford University Press, Biometrika Trust]},
  volume       = {40},
  issue        = {1/2},
  pages        = {87--104},
  date         = {1953},
  doi          = {10.2307/2333100},
  issn         = {0006-3444},
  abstract     = {A simple answer is found for the following question which has
                  plagued the practice of the analysis of variance: Under the
                  usual assumptions, if the conventional F-test of the
                  hypothesis H: μ1 = μ2 = ... = μk at the α level of
                  significance rejects H, what further inferences are valid
                  about the contrasts among the μi (beyond the inference that
                  the values of the contrasts are not all zero)? Suppose the
                  F-test has k - 1 and ν degrees of freedom. For any c1, ..., ck
                  with ∑k 1 ci = 0 write θ for the contrast ∑k 1 ciμi, and write
                  $\hat\theta$ and $\hat\sigma^2_\hat\theta$ for the usual
                  estimates of θ and the variance of $\hat\theta$. Then for the
                  totality of contrasts, no matter what the true values of the
                  θ's, the probability is 1 - α that they all satisfy
                  $\hat\theta - S\hat\sigma_\hat\theta \leqslant \theta
                  \leqslant \hat\theta + S\hat\sigma_\hat\theta,$ where S2 is (k
                  - 1) times the upper α point of the F-distribution with k - 1
                  and ν degrees of freedom. Suppose we say that the estimated
                  contrast $\hat\theta$ is `significantly different from zero'
                  if $|\hat\theta| > S\hat\sigma_\hat\theta$. Then the F-test
                  rejects H if and only if some $\hat\theta$ are significantly
                  different from zero, and if it does, we can say just which
                  $\hat\theta$. More generally, the above inequality can be
                  employed for all the contrasts with the obvious frequency
                  interpretation about the proportion of experiments in which
                  all statements are correct. Relations are considered to an
                  earlier method of Tukey using the Studentized range tables and
                  valid in the special case where the $\hat\mu_i$ all have the
                  same variance and all pairs $\hat\mu_i, \hat\mu_j (i \neq j)$
                  have the same covariance. Some results are obtained for the
                  operating characteristic of the new method. The paper is
                  organized so that the reader who wishes to learn the method
                  and avoid the proofs may skip §§ 2 and 5.},
  url          = {http://www.jstor.org/stable/2333100},
  urldate      = {2015-02-24}
}

@BOOK{Fisher1935-hw,
  title     = {The Design of Experiments},
  author    = {Fisher, Ronald Aylmer},
  publisher = {Oliver \& Boyd},
  location  = {Edinburgh and London},
  date      = {1935},
  language  = {English}
}

@ARTICLE{Newman1939-we,
  title        = {The Distribution of Range in Samples from a Normal Population,
                  Expressed in Terms of an Independent Estimate of Standard
                  Deviation},
  author       = {Newman, D},
  journaltitle = {Biometrika},
  publisher    = {[Oxford University Press, Biometrika Trust]},
  volume       = {31},
  issue        = {1/2},
  pages        = {20--30},
  date         = {1939},
  doi          = {10.2307/2334973},
  issn         = {0006-3444},
  url          = {http://www.jstor.org/stable/2334973},
  urldate      = {2015-02-24}
}

@ARTICLE{Working1929-cw,
  title        = {Applications of the Theory of Error to the Interpretation of
                  Trends},
  author       = {Working, Holbrook and Hotelling, Harold},
  journaltitle = {J. Am. Stat. Assoc.},
  publisher    = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  volume       = {24},
  issue        = {165},
  pages        = {73--85},
  date         = {1929},
  doi          = {10.2307/2277011},
  issn         = {0162-1459},
  url          = {http://www.jstor.org/stable/2277011},
  urldate      = {2015-02-24}
}

@ARTICLE{Irwin1925-ip,
  title        = {The Further Theory of Francis Galton's Individual Difference
                  Problem},
  author       = {Irwin, J O},
  journaltitle = {Biometrika},
  publisher    = {[Oxford University Press, Biometrika Trust]},
  volume       = {17},
  issue        = {1/2},
  pages        = {100--128},
  date         = {1925},
  doi          = {10.2307/2332028},
  issn         = {0006-3444},
  url          = {http://www.jstor.org/stable/2332028},
  urldate      = {2015-02-24}
}

@ARTICLE{Irwin1925-fz,
  title        = {On a Criterion for the Rejection of Outlying Observations},
  author       = {Irwin, J O},
  journaltitle = {Biometrika},
  publisher    = {[Oxford University Press, Biometrika Trust]},
  volume       = {17},
  issue        = {3/4},
  pages        = {238--250},
  date         = {1925},
  doi          = {10.2307/2332079},
  issn         = {0006-3444},
  url          = {http://www.jstor.org/stable/2332079},
  urldate      = {2015-02-24}
}

@ARTICLE{Student1927-nh,
  title        = {Errors of Routine Analysis},
  author       = {{Student}},
  journaltitle = {Biometrika},
  publisher    = {[Oxford University Press, Biometrika Trust]},
  volume       = {19},
  issue        = {1/2},
  pages        = {151--164},
  date         = {1927},
  doi          = {10.2307/2332181},
  issn         = {0006-3444},
  url          = {http://www.jstor.org/stable/2332181},
  urldate      = {2015-02-11}
}

@BOOK{Miller1981-jp,
  title     = {Simultaneous Statistical Inference},
  author    = {Miller, Rupert G},
  publisher = {Springer-Verlag},
  location  = {New York},
  edition   = {2nd},
  date      = {1981-03-18},
  pagetotal = {299},
  isbn      = {9780387905488,9783540905486},
  series    = {Springer Series in Statistics},
  url       = {https://market.android.com/details?id=book-kBPvAAAAMAAJ},
  language  = {en}
}

@ARTICLE{Pearson1902-vz,
  title        = {Note on Francis Galton's problem},
  author       = {Pearson, Karl},
  journaltitle = {Biometrika},
  volume       = {1},
  issue        = {4},
  pages        = {390--399},
  date         = {1902},
  issn         = {0006-3444},
  urldate      = {2015-02-11}
}

@ARTICLE{Galton1902-qc,
  title        = {The Most Suitable Proportion Between the Value of First and
                  Second Prizes},
  author       = {Galton, Francis},
  journaltitle = {Biometrika},
  publisher    = {[Oxford University Press, Biometrika Trust]},
  volume       = {1},
  issue        = {4},
  pages        = {385--399},
  date         = {1902},
  doi          = {10.2307/2331627},
  issn         = {0006-3444},
  url          = {http://www.jstor.org/stable/2331627},
  urldate      = {2015-02-11}
}

@ARTICLE{Dunnett1964-am,
  title        = {New Tables for Multiple Comparisons with a Control},
  author       = {Dunnett, C W},
  journaltitle = {Biometrics},
  publisher    = {[Wiley, International Biometric Society]},
  volume       = {20},
  issue        = {3},
  pages        = {482--491},
  date         = {1964},
  doi          = {10.2307/2528490},
  issn         = {0006-341X,1541-0420},
  url          = {http://www.jstor.org/stable/2528490},
  urldate      = {2014-10-11}
}

@ARTICLE{Dunnett1955-hg,
  title        = {A Multiple Comparison Procedure for Comparing Several
                  Treatments with a Control},
  author       = {Dunnett, Charles W},
  journaltitle = {J. Am. Stat. Assoc.},
  volume       = {50},
  issue        = {272},
  pages        = {1096--1121},
  date         = {1955},
  eprint       = {http://www.tandfonline.com/doi/pdf/10.1080/01621459.1955.10501294},
  doi          = {10.1080/01621459.1955.10501294},
  issn         = {0162-1459},
  url          = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1955.10501294},
  urldate      = {2014-10-11}
}

@ARTICLE{Hothorn2008-bj,
  title        = {Simultaneous inference in general parametric models},
  author       = {Hothorn, Torsten and Bretz, Frank and Westfall, Peter},
  journaltitle = {Biom. J.},
  volume       = {50},
  issue        = {3},
  pages        = {346--363},
  date         = {2008-06},
  doi          = {10.1002/bimj.200810425},
  pmid         = {18481363},
  issn         = {0323-3847,1521-4036},
  abstract     = {Simultaneous inference is a common problem in many areas of
                  application. If multiple null hypotheses are tested
                  simultaneously, the probability of rejecting erroneously at
                  least one of them increases beyond the pre-specified
                  significance level. Simultaneous inference procedures have to
                  be used which adjust for multiplicity and thus control the
                  overall type I error rate. In this paper we describe
                  simultaneous inference procedures in general parametric
                  models, where the experimental questions are specified through
                  a linear combination of elemental model parameters. The
                  framework described here is quite general and extends the
                  canonical theory of multiple comparison procedures in ANOVA
                  models to linear regression problems, generalized linear
                  models, linear mixed effects models, the Cox model, robust
                  linear models, etc. Several examples using a variety of
                  different statistical models illustrate the breadth of the
                  results. For the analyses we use the R add-on package
                  multcomp, which provides a convenient interface to the general
                  approach adopted here.},
  url          = {http://dx.doi.org/10.1002/bimj.200810425},
  language     = {en}
}

@ARTICLE{Curran-Everett2004-jm,
  title        = {Guidelines for reporting statistics in journals published by
                  the \textit{American Physiological Society}},
  author       = {Curran-Everett, Douglas and Benos, Dale J},
  journaltitle = {Am. J. Physiol. Regul. Integr. Comp. Physiol.},
  volume       = {287},
  issue        = {2},
  pages        = {R247--9},
  date         = {2004-08},
  pmid         = {15789454},
  issn         = {0363-6119},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/15789454},
  language     = {en}
}

@ARTICLE{Curran-Everett2009-tt,
  title        = {Statistics, authors, and reviewers: the heart of the matter},
  author       = {Curran-Everett, Douglas and Benos, Dale J},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {33},
  issue        = {1},
  pages        = {80},
  date         = {2009-03},
  doi          = {10.1152/advan.90216.2008},
  pmid         = {19261765},
  issn         = {1043-4046,1522-1229},
  url          = {http://dx.doi.org/10.1152/advan.90216.2008},
  language     = {en}
}

@ARTICLE{Curran-Everett2010-eb,
  title        = {Explorations in statistics: power},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {34},
  issue        = {2},
  pages        = {41--43},
  date         = {2010-06},
  doi          = {10.1152/advan.00001.2010},
  pmid         = {20522895},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This fifth installment of Explorations in Statistics
                  revisits power, a concept fundamental to the test of a null
                  hypothesis. Power is the probability that we reject the null
                  hypothesis when it is false. Four things affect power: the
                  probability with which we are willing to reject-by mistake-a
                  true null hypothesis, the magnitude of the difference we want
                  to be able to detect, the variability of the underlying
                  population, and the number of observations in our sample. In
                  an application to an Institutional Animal Care and Use
                  Committee or to the National Institutes of Health, we define
                  power to justify the sample size we propose.},
  url          = {http://dx.doi.org/10.1152/advan.00001.2010},
  language     = {en}
}

@ARTICLE{Curran-Everett2000-ng,
  title        = {The process of scientific discovery: How certain can we be?},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Am. Biol. Teach.},
  volume       = {62},
  issue        = {4},
  pages        = {266--275},
  date         = {2000},
  issn         = {0002-7685}
}

@ARTICLE{Curran-Everett2010-il,
  title        = {Explorations in statistics: correlation},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {34},
  issue        = {4},
  pages        = {186--191},
  date         = {2010-12},
  doi          = {10.1152/advan.00068.2010},
  pmid         = {21098385},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This sixth installment of Explorations in Statistics
                  explores correlation, a familiar technique that estimates the
                  magnitude of a straight-line relationship between two
                  variables. Correlation is meaningful only when the two
                  variables are true random variables: for example, if we
                  restrict in some way the variability of one variable, then the
                  magnitude of the correlation will decrease. Correlation cannot
                  help us decide if changes in one variable result in changes in
                  the second variable, if changes in the second variable result
                  in changes in the first variable, or if changes in a third
                  variable result in concurrent changes in the first two
                  variables. Correlation can help provide us with evidence that
                  study of the nature of the relationship between x and y may be
                  warranted in an actual experiment in which one of them is
                  controlled.},
  url          = {http://dx.doi.org/10.1152/advan.00068.2010},
  language     = {en}
}

@BOOK{Anderson2008-ik,
  title     = {Model based inference in the life sciences: a primer on evidence},
  author    = {Anderson, David R},
  publisher = {Springer},
  location  = {New York, NY},
  date      = {2008}
}

@ARTICLE{Benjamini1995-cw,
  title        = {Controlling the False Discovery Rate: A Practical and Powerful
                  Approach to Multiple Testing},
  author       = {Benjamini, Yoav and Hochberg, Yosef},
  journaltitle = {J. R. Stat. Soc. Series B Stat. Methodol.},
  volume       = {57},
  issue        = {1},
  pages        = {289--300},
  date         = {1995},
  issn         = {1369-7412,0035-9246},
  abstract     = {The common approach to the multiplicity problem calls for
                  controlling the familywise error rate (FWER). This approach,
                  though, has faults, and we point out a few. A different
                  approach to problems of multiple significance testing is
                  presented. It calls for controlling the expected proportion of
                  falsely rejected hypotheses-the false discovery rate. This
                  error rate is equivalent to the FWER when all hypotheses are
                  true but is smaller otherwise. Therefore, in problems where
                  the control of the false discovery rate rather than that of
                  the FWER is desired, there is potential for a gain in power. A
                  simple sequential Bonferroni-type procedure is proved to
                  control the false discovery rate for independent test
                  statistics, and a simulation study shows that the gain in
                  power is substantial. The use of the new procedure and the
                  appropriateness of the criterion are illustrated with
                  examples.},
  url          = {http://www.jstor.org/stable/2346101}
}

@ARTICLE{Holm1979-ip,
  title        = {A Simple Sequentially Rejective Multiple Test Procedure},
  author       = {Holm, Sture},
  journaltitle = {Scand. Stat. Theory Appl.},
  publisher    = {[Board of the Foundation of the Scandinavian Journal of
                  Statistics, Wiley]},
  volume       = {6},
  issue        = {2},
  pages        = {65--70},
  date         = {1979},
  issn         = {0303-6898,1467-9469},
  abstract     = {This paper presents a simple and widely applicable multiple
                  test procedure of the sequentially rejective type, i.e.
                  hypotheses are rejected one at a time until no further
                  rejections can be done. It is shown that the test has a
                  prescribed level of significance protection against error of
                  the first kind for any combination of true hypotheses. The
                  power properties of the test and a number of possible
                  applications are also discussed.},
  url          = {http://www.jstor.org/stable/4615733}
}

@ARTICLE{Anderson2002-cf,
  title        = {Avoiding Pitfalls When Using Information-Theoretic Methods},
  author       = {Anderson, David R and Burnham, Kenneth P},
  journaltitle = {J. Wildl. Manage.},
  volume       = {66},
  issue        = {3},
  pages        = {912--918},
  date         = {2002},
  doi          = {10.2307/3803155},
  issn         = {0022-541X,1937-2817},
  abstract     = {We offer suggestions to avoid misuse of information-theoretic
                  methods in wildlife laboratory and field studies. Our
                  suggestions relate to basic science issues and the need to ask
                  deeper questions (4 problems are noted), errors in the way
                  that analytical methods are used (7 problems), and outright
                  mistakes seen commonly in the published literature (5
                  problems). We assume that readers are familiar with the
                  information-theoretic approaches and provide several examples
                  of misuse. Any method can be misused-our purpose here is to
                  suggest constructive ways to avoid misuse.},
  url          = {http://www.jstor.org/stable/3803155}
}

@ARTICLE{Curran-Everett2011-jw,
  title        = {Explorations in statistics: regression},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {35},
  issue        = {4},
  pages        = {347--352},
  date         = {2011-12},
  doi          = {10.1152/advan.00051.2011},
  pmid         = {22139769},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This seventh installment of Explorations in
                  Statistics explores regression, a technique that estimates the
                  nature of the relationship between two things for which we may
                  only surmise a mechanistic or predictive connection.
                  Regression helps us answer three questions: does some variable
                  Y depend on another variable X; if so, what is the nature of
                  the relationship between Y and X; and for some value of X,
                  what value of Y do we predict? Residual plots are an essential
                  component of a thorough regression analysis: they help us
                  decide if our statistical regression model of the relationship
                  between Y and X is appropriate.},
  url          = {http://dx.doi.org/10.1152/advan.00051.2011},
  language     = {en}
}

@ARTICLE{Curran-Everett2012-ga,
  title        = {Explorations in statistics: permutation methods},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {36},
  issue        = {3},
  pages        = {181--187},
  date         = {2012-09},
  doi          = {10.1152/advan.00072.2012},
  pmid         = {22952255},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This eighth installment of Explorations in Statistics
                  explores permutation methods, empiric procedures we can use to
                  assess an experimental result-to test a null hypothesis-when
                  we are reluctant to trust statistical theory alone.
                  Permutation methods operate on the observations-the data-we
                  get from an experiment. A permutation procedure answers this
                  question: out of all the possible ways we can rearrange the
                  observations we got, in what proportion of those arrangements
                  is the sample statistic we care about at least as extreme as
                  the one we got? The answer to that question is the P value.},
  url          = {http://dx.doi.org/10.1152/advan.00072.2012},
  language     = {en}
}

@ARTICLE{Gelman2006-xj,
  title        = {The Difference Between “Significant” and “Not Significant” is
                  not Itself Statistically Significant},
  author       = {Gelman, Andrew and Stern, Hal},
  journaltitle = {Am. Stat.},
  volume       = {60},
  issue        = {4},
  pages        = {328--331},
  date         = {2006-11},
  doi          = {10.1198/000313006X152649},
  issn         = {0003-1305,1537-2731},
  abstract     = {It is common to summarize statistical comparisons by
                  declarations of statistical significance or non significance.
                  Here we discuss one problem with such declarations, namely
                  that changes in statistical significance are often not
                  themselves statistically significant. By this, we are not
                  merely making the commonplace observation that any particular
                  threshold is arbitrary-for example, only a small change is
                  required to move an estimate from a 5.1\% significance level
                  to 4.9\%, thus moving it into statistical significance.
                  Rather, we are pointing out that even large changes in
                  significance levels can correspond to small, nonsignificant
                  changes in the underlying quantities.The error we describe is
                  conceptually different from other oft-cited problems-that
                  statistical significance is not the same as practical
                  importance, that dichotomization into significant and
                  nonsignificant results encourages the dismissal of observed
                  differences in favor of the usually less interesting null
                  hypothesis of no difference, and that any particular threshold
                  for declaring significance is arbitrary. We are troubled by
                  all of these concerns and do not intend to minimize their
                  importance. Rather, our goal is to bring attention to this
                  additional error of interpretation. We illustrate with a
                  theoretical example and two applied examples. The ubiquity of
                  this statistical error leads us to suggest that Students and
                  practitioners be made more aware that the difference between
                  "significant" and "not significant" is not itself
                  statistically significant.},
  url          = {http://www.tandfonline.com/doi/abs/10.1198/000313006X152649}
}

@ARTICLE{Storey2003-mz,
  title        = {Statistical significance for genomewide studies},
  author       = {Storey, John D and Tibshirani, Robert},
  journaltitle = {Proc. Natl. Acad. Sci. U. S. A.},
  volume       = {100},
  issue        = {16},
  pages        = {9440--9445},
  date         = {2003-08-05},
  doi          = {10.1073/pnas.1530509100},
  pmc          = {PMC170937},
  pmid         = {12883005},
  issn         = {0027-8424},
  abstract     = {With the increase in genomewide experiments and the sequencing
                  of multiple genomes, the analysis of large data sets has
                  become commonplace in biology. It is often the case that
                  thousands of features in a genomewide data set are tested
                  against some null hypothesis, where a number of features are
                  expected to be significant. Here we propose an approach to
                  measuring statistical significance in these genomewide studies
                  based on the concept of the false discovery rate. This
                  approach offers a sensible balance between the number of true
                  and false positives that is automatically calibrated and
                  easily interpreted. In doing so, a measure of statistical
                  significance called the q value is associated with each tested
                  feature. The q value is similar to the well known p value,
                  except it is a measure of significance in terms of the false
                  discovery rate rather than the false positive rate. Our
                  approach avoids a flood of false positive results, while
                  offering a more liberal criterion than what has been used in
                  genome scans for linkage.},
  url          = {http://dx.doi.org/10.1073/pnas.1530509100},
  language     = {en}
}

@ARTICLE{Rice1989-wz,
  title        = {Analyzing Tables of Statistical Tests},
  author       = {Rice, William R},
  journaltitle = {Evolution},
  publisher    = {[Society for the Study of Evolution, Wiley]},
  volume       = {43},
  issue        = {1},
  pages        = {223--225},
  date         = {1989},
  doi          = {10.2307/2409177},
  issn         = {0014-3820,1558-5646},
  url          = {http://www.jstor.org/stable/2409177}
}

@ARTICLE{Storey2002-mz,
  title        = {A direct approach to false discovery rates},
  author       = {Storey, John D},
  journaltitle = {J. R. Stat. Soc. Series B Stat. Methodol.},
  volume       = {64},
  issue        = {3},
  pages        = {479--498},
  date         = {2002-08-01},
  doi          = {10.1111/1467-9868.00346},
  issn         = {1369-7412,1467-9868},
  abstract     = {Summary. Multiple-hypothesis testing involves guarding against
                  much more complicated errors than single-hypothesis testing.
                  Whereas we typically control the type I error rate for a
                  single-hypothesis test, a compound error rate is controlled
                  for multiple-hypothesis tests. For example, controlling the
                  false discovery rate FDR traditionally involves intricate
                  sequential p-value rejection methods based on the observed
                  data. Whereas a sequential p-value method fixes the error rate
                  and estimates its corresponding rejection region, we propose
                  the opposite approach—we fix the rejection region and then
                  estimate its corresponding error rate. This new approach
                  offers increased applicability, accuracy and power. We apply
                  the methodology to both the positive false discovery rate pFDR
                  and FDR, and provide evidence for its benefits. It is shown
                  that pFDR is probably the quantity of interest over FDR. Also
                  discussed is the calculation of the q-value, the pFDR analogue
                  of the p-value, which eliminates the need to set the error
                  rate beforehand as is traditionally done. Some simple
                  numerical examples are presented that show that this new
                  approach can yield an increase of over eight times in power
                  compared with the Benjamini–Hochberg FDR method.},
  url          = {http://dx.doi.org/10.1111/1467-9868.00346},
  keywords     = {False discovery rate; Multiple comparisons; Positive false
                  discovery rate; p-values; q-values; Sequential p-value
                  methods; Simultaneous inference}
}

@ARTICLE{Storey2003-yc,
  title        = {The Positive False Discovery Rate: A Bayesian Interpretation
                  and the q-Value},
  author       = {Storey, John D},
  journaltitle = {Ann. Stat.},
  volume       = {31},
  issue        = {6},
  pages        = {2013--2035},
  date         = {2003},
  issn         = {0090-5364},
  abstract     = {Multiple hypothesis testing is concerned with controlling the
                  rate of false positives when testing several hypotheses
                  simultaneously. One multiple hypothesis testing error measure
                  is the false discovery rate (FDR), which is loosely defined to
                  be the expected proportion of false positives among all
                  significant hypotheses. The FDR is especially appropriate for
                  exploratory analyses in which one is interested in finding
                  several significant results among many tests. In this work, we
                  introduce a modified version of the FDR called the "positive
                  false discovery rate" (pFDR). We discuss the advantages and
                  disadvantages of the pFDR and investigate its statistical
                  properties. When assuming the test statistics follow a mixture
                  distribution, we show that the pFDR can be written as a
                  Bayesian posterior probability and can be connected to
                  classification theory. These properties remain asymptotically
                  true under fairly general conditions, even under certain forms
                  of dependence. Also, a new quantity called the "q -value" is
                  introduced and investigated, which is a natural "Bayesian
                  posterior p-value," or rather the pFDR analogue of the
                  p-value.},
  url          = {http://www.jstor.org/stable/3448445}
}

@ARTICLE{Curran-Everett2005-cg,
  title        = {The proof is not in the {P} value - Reply},
  author       = {Curran-Everett, Douglas and Benos, Dale},
  journaltitle = {Am. J. Physiol. Regul. Integr. Comp. Physiol.},
  volume       = {288},
  issue        = {3},
  pages        = {R777--R778},
  date         = {2005},
  issn         = {0363-6119}
}

@ARTICLE{Button2013-vg,
  title        = {Power failure: why small sample size undermines the
                  reliability of neuroscience},
  author       = {Button, Katherine S and Ioannidis, John P A and Mokrysz,
                  Claire and Nosek, Brian A and Flint, Jonathan and Robinson,
                  Emma S J and Munafò, Marcus R},
  journaltitle = {Nat. Rev. Neurosci.},
  volume       = {14},
  issue        = {5},
  pages        = {365--376},
  date         = {2013-05},
  doi          = {10.1038/nrn3475},
  pmid         = {23571845},
  issn         = {1471-003X,1471-0048},
  abstract     = {A study with low statistical power has a reduced chance of
                  detecting a true effect, but it is less well appreciated that
                  low power also reduces the likelihood that a statistically
                  significant result reflects a true effect. Here, we show that
                  the average statistical power of studies in the neurosciences
                  is very low. The consequences of this include overestimates of
                  effect size and low reproducibility of results. There are also
                  ethical dimensions to this problem, as unreliable research is
                  inefficient and wasteful. Improving reproducibility in
                  neuroscience is a key priority and requires attention to
                  well-established but often ignored methodological principles.},
  url          = {http://dx.doi.org/10.1038/nrn3475},
  language     = {en}
}

@ARTICLE{Curran-Everett2013-kx,
  title        = {Explorations in statistics: the analysis of ratios and
                  normalized data},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {37},
  issue        = {3},
  pages        = {213--219},
  date         = {2013-09},
  doi          = {10.1152/advan.00053.2013},
  pmid         = {24022766},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This ninth installment of Explorations in Statistics
                  explores the analysis of ratios and normalized-or
                  standardized-data. As researchers, we compute a ratio-a
                  numerator divided by a denominator-to compute a proportion for
                  some biological response or to derive some standardized
                  variable. In each situation, we want to control for
                  differences in the denominator when the thing we really care
                  about is the numerator. But there is peril lurking in a ratio:
                  only if the relationship between numerator and denominator is
                  a straight line through the origin will the ratio be
                  meaningful. If not, the ratio will misrepresent the true
                  relationship between numerator and denominator. In contrast,
                  regression techniques-these include analysis of covariance-are
                  versatile: they can accommodate an analysis of the
                  relationship between numerator and denominator when a ratio is
                  useless.},
  url          = {http://dx.doi.org/10.1152/advan.00053.2013},
  keywords     = {analysis of covariance; model II regression; ordinary
                  least-squares regression},
  language     = {en}
}

@ARTICLE{Gelman2012-xe,
  title        = {Why We (Usually) Don't Have to Worry About Multiple
                  Comparisons},
  author       = {Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
  journaltitle = {J. Res. Educ. Eff.},
  volume       = {5},
  issue        = {2},
  pages        = {189--211},
  date         = {2012},
  eprint       = {http://dx.doi.org/10.1080/19345747.2011.618213},
  doi          = {10.1080/19345747.2011.618213},
  issn         = {1934-5747},
  abstract     = {Abstract Applied researchers often find themselves making
                  statistical inferences in settings that would seem to require
                  multiple comparisons adjustments. We challenge the Type I
                  error paradigm that underlies these corrections. Moreover we
                  posit that the problem of multiple comparisons can disappear
                  entirely when viewed from a hierarchical Bayesian perspective.
                  We propose building multilevel models in the settings where
                  multiple comparisons arise. Multilevel models perform partial
                  pooling (shifting estimates toward each other), whereas
                  classical procedures typically keep the centers of intervals
                  stationary, adjusting for multiple comparisons by making the
                  intervals wider (or, equivalently, adjusting the p values
                  corresponding to intervals of fixed width). Thus, multilevel
                  models address the multiple comparisons problem and also yield
                  more efficient estimates, especially in settings with low
                  group-level variation, which is where multiple comparisons are
                  a particular concern.},
  url          = {http://dx.doi.org/10.1080/19345747.2011.618213}
}

@ARTICLE{Jager2014-lw,
  title        = {An estimate of the science-wise false discovery rate and
                  application to the top medical literature},
  author       = {Jager, Leah R and Leek, Jeffrey T},
  journaltitle = {Biostatistics},
  volume       = {15},
  issue        = {1},
  pages        = {1--12},
  date         = {2014-01},
  doi          = {10.1093/biostatistics/kxt007},
  pmid         = {24068246},
  issn         = {1465-4644,1468-4357},
  abstract     = {The accuracy of published medical research is critical for
                  scientists, physicians and patients who rely on these results.
                  However, the fundamental belief in the medical literature was
                  called into serious question by a paper suggesting that most
                  published medical research is false. Here we adapt estimation
                  methods from the genomics community to the problem of
                  estimating the rate of false discoveries in the medical
                  literature using reported $P$-values as the data. We then
                  collect $P$-values from the abstracts of all 77 430 papers
                  published in The Lancet, The Journal of the American Medical
                  Association, The New England Journal of Medicine, The British
                  Medical Journal, and The American Journal of Epidemiology
                  between 2000 and 2010. Among these papers, we found 5322
                  reported $P$-values. We estimate that the overall rate of
                  false discoveries among reported results is 14\% (s.d. 1\%),
                  contrary to previous claims. We also found that there is no a
                  significant increase in the estimated rate of reported false
                  discovery results over time (0.5\% more false positives (FP)
                  per year, $P = 0.18$) or with respect to journal submissions
                  (0.5\% more FP per 100 submissions, $P = 0.12$). Statistical
                  analysis must allow for false discoveries in order to make
                  claims on the basis of noisy data. But our analysis suggests
                  that the medical literature remains a reliable record of
                  scientific progress.},
  url          = {http://dx.doi.org/10.1093/biostatistics/kxt007},
  keywords     = {False discovery rate; Genomics; Meta-analysis; Multiple
                  testing; Science-wise false discovery rate; Two-group model},
  language     = {en}
}

@ARTICLE{Benjamini2014-rp,
  title        = {Discussion: An estimate of the science-wise false discovery
                  rate and applications to top medical journals by Jager and
                  Leek},
  author       = {Benjamini, Yoav and Hechtlinger, Yotam},
  journaltitle = {Biostatistics},
  volume       = {15},
  issue        = {1},
  pages        = {13--6; discussion 39--45},
  date         = {2014-01},
  doi          = {10.1093/biostatistics/kxt032},
  pmid         = {24068247},
  issn         = {1465-4644,1468-4357},
  url          = {http://dx.doi.org/10.1093/biostatistics/kxt032},
  language     = {en}
}

@ARTICLE{Young2008-gy,
  title        = {Why current publication practices may distort science},
  author       = {Young, Neal S and Ioannidis, John P A and Al-Ubaydli, Omar},
  journaltitle = {PLoS Med.},
  volume       = {5},
  issue        = {10},
  pages        = {e201},
  date         = {2008-10-07},
  doi          = {10.1371/journal.pmed.0050201},
  pmc          = {PMC2561077},
  pmid         = {18844432},
  issn         = {1549-1277,1549-1676},
  url          = {http://dx.doi.org/10.1371/journal.pmed.0050201},
  language     = {en}
}

@ARTICLE{Ludbrook1998-zg,
  title        = {Why Permutation Tests Are Superior to t and {F} Tests in
                  Biomedical Research},
  author       = {Ludbrook, John and Dudley, Hugh},
  journaltitle = {Am. Stat.},
  publisher    = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  volume       = {52},
  issue        = {2},
  pages        = {127--132},
  date         = {1998},
  doi          = {10.2307/2685470},
  issn         = {0003-1305},
  abstract     = {A survey of 252 prospective, comparative studies reported in
                  five, frequently cited biomedical journals revealed that
                  experimental groups were constructed by randomization in 96\%
                  of cases and by random sampling in only 4\%. The median group
                  sizes ranged from 4 to 12. In the randomized studies in which
                  measurements were made on a continuous scale, comparisons of
                  location were made by t or F tests in 84\% of cases, and by
                  nonparametric, rank-order, tests in the remainder. Because
                  randomization rather than random sampling is the norm in
                  biomedical research and because group sizes are usually small,
                  exact permutation or randomization tests for differences in
                  location should be preferred to t or F tests.},
  url          = {http://www.jstor.org/stable/2685470}
}

@ARTICLE{Garland1984-gf,
  title        = {Physiological correlates of locomotory performance in a
                  lizard: an allometric approach},
  author       = {Garland, Jr, T},
  journaltitle = {Am. J. Physiol.},
  volume       = {247},
  issue        = {5 Pt 2},
  pages        = {R806--15},
  date         = {1984-11},
  pmid         = {6238543},
  issn         = {0002-9513},
  abstract     = {Three measures of locomotory performance and a series of
                  variables thought to affect performance were measured in the
                  iguanid lizard Ctenosaura similis. Burst speed is mass
                  independent; however, endurance time at 1 km/h (EN-DUR) and
                  maximal distance run (MAX DIS) scale as M0.3. Standard and
                  maximal rates of O2 consumption (VO2max) scale as M0.9; VO2max
                  averages 10-fold greater than standard metabolic rate (SMR).
                  Three of ten enzyme activities measured exhibit significant
                  scaling. After statistically removing the effects of body
                  mass, multiple-regression analysis indicates that 1) 89\% of
                  the residual variation in ENDUR is correlated with variation
                  among individuals in thigh muscle mass, VO2max, heart mass,
                  and liver citrate synthase (CS) activity; 2) maximal CO2
                  consumption (VCO2max) and thigh pyruvate kinase activity
                  statistically explain 64\% of the variation in MAX DIS; 3)
                  heart and liver masses together predict 35\% of the variation
                  in SMR; 4) thigh and liver CS activity, heart lactate
                  dehydrogenase (LDH) activity, and hematocrit account for 67\%
                  of the variation in VO2max;5) 97\% of the variation in VCO2max
                  is statistically related to variation in liver CS activity,
                  thigh and heart masses, and heart LDH activity.},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/6238543},
  language     = {en}
}

@MISC{Anderson2006-rn,
  title  = {{AIC} myths and misunderstandings},
  author = {Anderson, David and Burnham, Kenneth},
  pages  = {8},
  date   = {2006}
}

@ARTICLE{Burnham2004-zr,
  title        = {Multimodel Inference: Understanding {AIC} and {BIC} in Model
                  Selection},
  author       = {Burnham, Kenneth P and Anderson, David R},
  journaltitle = {Sociol. Methods Res.},
  volume       = {33},
  issue        = {2},
  pages        = {261--304},
  date         = {2004-11},
  doi          = {10.1177/0049124104268644},
  issn         = {0049-1241,1552-8294},
  url          = {http://journals.sagepub.com/doi/10.1177/0049124104268644}
}

@ARTICLE{Curran-Everett2007-ts,
  title        = {Last Word on Perspectives "Guidelines for reporting statistics
                  in journals published by the American Physiological Society:
                  the sequel"},
  author       = {Curran-Everett, Douglas and Benos, Dale},
  journaltitle = {Adv. Physiol. Educ.},
  date         = {2007},
  issn         = {1043-4046},
  url          = {http://advan.physiology.org/cgi/content/full/31/4/306}
}

@ARTICLE{Burnham2001-wq,
  title        = {Kullback-Leibler information as a basis for strong inference
                  in ecological studies},
  author       = {Burnham, Kenneth P and Anderson, David R},
  journaltitle = {Wildl. Res.},
  volume       = {28},
  issue        = {2},
  pages        = {111--119},
  date         = {2001-05-24},
  doi          = {10.1071/WR99107},
  issn         = {1035-3712},
  abstract     = {We describe an information-theoretic paradigm for analysis of
                  ecological data, based on Kullback–Leibler information, that
                  is an extension of likelihood theory and avoids the pitfalls
                  of null hypothesis testing. Information-theoretic approaches
                  emphasise a deliberate focus on the a priori science in
                  developing a set of multiple working hypotheses or models.
                  Simple methods then allow these hypotheses (models) to be
                  ranked from best to worst and scaled to reflect a strength of
                  evidence using the likelihood of each model (gi), given the
                  data and the models in the set (i.e. L(gi | data)). In
                  addition, a variance component due to model-selection
                  uncertainty is included in estimates of precision. There are
                  many cases where formal inference can be based on all the
                  models in the a priori set and this multi-model inference
                  represents a powerful, new approach to valid inference.
                  Finally, we strongly recommend inferences based on a priori
                  considerations be carefully separated from those resulting
                  from some form of data dredging. An example is given for
                  questions related to age- and sex-dependent rates of tag loss
                  in elephant seals (Mirounga leonina).},
  url          = {http://dx.doi.org/10.1071/WR99107}
}

@ARTICLE{Curran-Everett1998-xz,
  title        = {Fundamental concepts in statistics: elucidation and
                  illustration},
  author       = {Curran-Everett, D and Taylor, S and Kafadar, K},
  journaltitle = {J. Appl. Physiol.},
  volume       = {85},
  issue        = {3},
  pages        = {775--786},
  date         = {1998-09},
  pmid         = {9729547},
  issn         = {0021-8987},
  abstract     = {Fundamental concepts in statistics form the cornerstone of
                  scientific inquiry. If we fail to understand fully these
                  fundamental concepts, then the scientific conclusions we reach
                  are more likely to be wrong. This is more than supposition:
                  for 60 years, statisticians have warned that the scientific
                  literature harbors misunderstandings about basic statistical
                  concepts. Original articles published in 1996 by the American
                  Physiological Society's journals fared no better in their
                  handling of basic statistical concepts. In this review, we
                  summarize the two main scientific uses of statistics:
                  hypothesis testing and estimation. Most scientists use
                  statistics solely for hypothesis testing; often, however,
                  estimation is more useful. We also illustrate the concepts of
                  variability and uncertainty, and we demonstrate the essential
                  distinction between statistical significance and scientific
                  importance. An understanding of concepts such as variability,
                  uncertainty, and significance is necessary, but it is not
                  sufficient; we show also that the numerical results of
                  statistical analyses have limitations.},
  url          = {https://www.ncbi.nlm.nih.gov/pubmed/9729547},
  language     = {en}
}

@ARTICLE{Curran-Everett2009-lq,
  title        = {Explorations in statistics: hypothesis tests and {P} values},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {33},
  issue        = {2},
  pages        = {81--86},
  date         = {2009-06},
  doi          = {10.1152/advan.90218.2008},
  pmid         = {19509391},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This second installment of Explorations in Statistics
                  delves into test statistics and P values, two concepts
                  fundamental to the test of a scientific null hypothesis. The
                  essence of a test statistic is that it compares what we
                  observe in the experiment to what we expect to see if the null
                  hypothesis is true. The P value associated with the magnitude
                  of that test statistic answers this question: if the null
                  hypothesis is true, what proportion of possible values of the
                  test statistic are at least as extreme as the one I got?
                  Although statisticians continue to stress the limitations of
                  hypothesis tests, there are two realities we must acknowledge:
                  hypothesis tests are ingrained within science, and the simple
                  test of a null hypothesis can be useful. As a result, it
                  behooves us to explore the notions of hypothesis tests, test
                  statistics, and P values.},
  url          = {http://dx.doi.org/10.1152/advan.90218.2008},
  language     = {en}
}

@ARTICLE{Curran-Everett2008-aa,
  title        = {Explorations in statistics: standard deviations and standard
                  errors},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {32},
  issue        = {3},
  pages        = {203--208},
  date         = {2008-09},
  doi          = {10.1152/advan.90123.2008},
  pmid         = {18794241},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This series in Advances in Physiology Education
                  provides an opportunity to do just that: we will investigate
                  basic concepts in statistics using the free software package
                  R. Because this series uses R solely as a vehicle with which
                  to explore basic concepts in statistics, I provide the
                  requisite R commands. In this inaugural paper we explore the
                  essential distinction between standard deviation and standard
                  error: a standard deviation estimates the variability among
                  sample observations whereas a standard error of the mean
                  estimates the variability among theoretical sample means. If
                  we fail to report the standard deviation, then we fail to
                  fully report our data. Because it incorporates information
                  about sample size, the standard error of the mean is a
                  misguided estimate of variability among observations. Instead,
                  the standard error of the mean provides an estimate of the
                  uncertainty of the true value of the population mean.},
  url          = {http://dx.doi.org/10.1152/advan.90123.2008},
  language     = {en}
}

@ARTICLE{Curran-Everett2009-zz,
  title        = {Explorations in statistics: confidence intervals},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {33},
  issue        = {2},
  pages        = {87--90},
  date         = {2009-06},
  doi          = {10.1152/advan.00006.2009},
  pmid         = {19509392},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This third installment of Explorations in Statistics
                  investigates confidence intervals. A confidence interval is a
                  range that we expect, with some level of confidence, to
                  include the true value of a population parameter such as the
                  mean. A confidence interval provides the same statistical
                  information as the P value from a hypothesis test, but it
                  circumvents the drawbacks of that hypothesis test. Even more
                  important, a confidence interval focuses our attention on the
                  scientific importance of some experimental result.},
  url          = {http://dx.doi.org/10.1152/advan.00006.2009},
  language     = {en}
}

@ARTICLE{Curran-Everett2009-hh,
  title        = {Explorations in statistics: the bootstrap},
  author       = {Curran-Everett, Douglas},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {33},
  issue        = {4},
  pages        = {286--292},
  date         = {2009-12},
  doi          = {10.1152/advan.00062.2009},
  pmid         = {19948676},
  issn         = {1043-4046,1522-1229},
  abstract     = {Learning about statistics is a lot like learning about
                  science: the learning is more meaningful if you can actively
                  explore. This fourth installment of Explorations in Statistics
                  explores the bootstrap. The bootstrap gives us an empirical
                  approach to estimate the theoretical variability among
                  possible values of a sample statistic such as the sample mean.
                  The appeal of the bootstrap is that we can use it to make an
                  inference about some experimental result when the statistical
                  theory is uncertain or even unknown. We can also use the
                  bootstrap to assess how well the statistical theory holds:
                  that is, whether an inference we make from a hypothesis test
                  or confidence interval is justified.},
  url          = {http://dx.doi.org/10.1152/advan.00062.2009},
  language     = {en}
}

@ARTICLE{Storey2004-fr,
  title        = {Strong control, conservative point estimation and simultaneous
                  conservative consistency of false discovery rates: a unified
                  approach},
  author       = {Storey, John D and Taylor, Jonathan E and Siegmund, David},
  journaltitle = {J. R. Stat. Soc. Series B Stat. Methodol.},
  volume       = {66},
  issue        = {1},
  pages        = {187--205},
  date         = {2004-02-01},
  doi          = {10.1111/j.1467-9868.2004.00439.x},
  issn         = {1369-7412,1467-9868},
  abstract     = {Summary. The false discovery rate (FDR) is a multiple
                  hypothesis testing quantity that describes the expected
                  proportion of false positive results among all rejected null
                  hypotheses. Benjamini and Hochberg introduced this quantity
                  and proved that a particular step-up p-value method controls
                  the FDR. Storey introduced a point estimate of the FDR for
                  fixed significance regions. The former approach conservatively
                  controls the FDR at a fixed predetermined level, and the
                  latter provides a conservatively biased estimate of the FDR
                  for a fixed predetermined significance region. In this work,
                  we show in both finite sample and asymptotic settings that the
                  goals of the two approaches are essentially equivalent. In
                  particular, the FDR point estimates can be used to define
                  valid FDR controlling procedures. In the asymptotic setting,
                  we also show that the point estimates can be used to estimate
                  the FDR conservatively over all significance regions
                  simultaneously, which is equivalent to controlling the FDR at
                  all levels simultaneously. The main tool that we use is to
                  translate existing FDR methods into procedures involving
                  empirical processes. This simplifies finite sample proofs,
                  provides a framework for asymptotic results and proves that
                  these procedures are valid even under certain forms of
                  dependence.},
  url          = {http://dx.doi.org/10.1111/j.1467-9868.2004.00439.x},
  keywords     = {Multiple comparisons; Positive false discovery rate; P-values;
                  Q-values; Simultaneous inference}
}

@ARTICLE{Ioannidis2005-od,
  title        = {Why most published research findings are false},
  author       = {Ioannidis, John P A},
  journaltitle = {PLoS Med.},
  volume       = {2},
  issue        = {8},
  pages        = {e124},
  date         = {2005-08},
  doi          = {10.1371/journal.pmed.0020124},
  pmc          = {PMC1182327},
  pmid         = {16060722},
  issn         = {1549-1277,1549-1676},
  abstract     = {There is increasing concern that most current published
                  research findings are false. The probability that a research
                  claim is true may depend on study power and bias, the number
                  of other studies on the same question, and, importantly, the
                  ratio of true to no relationships among the relationships
                  probed in each scientific field. In this framework, a research
                  finding is less likely to be true when the studies conducted
                  in a field are smaller; when effect sizes are smaller; when
                  there is a greater number and lesser preselection of tested
                  relationships; where there is greater flexibility in designs,
                  definitions, outcomes, and analytical modes; when there is
                  greater financial and other interest and prejudice; and when
                  more teams are involved in a scientific field in chase of
                  statistical significance. Simulations show that for most study
                  designs and settings, it is more likely for a research claim
                  to be false than true. Moreover, for many current scientific
                  fields, claimed research findings may often be simply accurate
                  measures of the prevailing bias. In this essay, I discuss the
                  implications of these problems for the conduct and
                  interpretation of research.},
  url          = {http://dx.doi.org/10.1371/journal.pmed.0020124},
  language     = {en}
}

@ARTICLE{Storey2007-es,
  title        = {The optimal discovery procedure: a new approach to
                  simultaneous significance testing},
  author       = {Storey, John D},
  journaltitle = {J. R. Stat. Soc. Series B Stat. Methodol.},
  volume       = {69},
  issue        = {3},
  pages        = {347--368},
  date         = {2007-06-01},
  doi          = {10.1111/j.1467-9868.2007.005592.x},
  issn         = {1369-7412,1467-9868},
  abstract     = {Summary. The Neyman–Pearson lemma provides a simple procedure
                  for optimally testing a single hypothesis when the null and
                  alternative distributions are known. This result has played a
                  major role in the development of significance testing
                  strategies that are used in practice. Most of the work
                  extending single-testing strategies to multiple tests has
                  focused on formulating and estimating new types of
                  significance measures, such as the false discovery rate. These
                  methods tend to be based on p-values that are calculated from
                  each test individually, ignoring information from the other
                  tests. I show here that one can improve the overall
                  performance of multiple significance tests by borrowing
                  information across all the tests when assessing the relative
                  significance of each one, rather than calculating p-values for
                  each test individually. The ‘optimal discovery procedure’ is
                  introduced, which shows how to maximize the number of expected
                  true positive results for each fixed number of expected false
                  positive results. The optimality that is achieved by this
                  procedure is shown to be closely related to optimality in
                  terms of the false discovery rate. The optimal discovery
                  procedure motivates a new approach to testing multiple
                  hypotheses, especially when the tests are related. As a simple
                  example, a new simultaneous procedure for testing several
                  normal means is defined; this is surprisingly demonstrated to
                  outperform the optimal single-test procedure, showing that a
                  method which is optimal for single tests may no longer be
                  optimal for multiple tests. Connections to other concepts in
                  statistics are discussed, including Stein's paradox, shrinkage
                  estimation and the Bayesian approach to hypothesis testing.},
  url          = {http://dx.doi.org/10.1111/j.1467-9868.2007.005592.x},
  keywords     = {Classification; False discovery rate; Multiple-hypothesis
                  testing; Optimal discovery procedure; q-value;
                  Single-thresholding procedure}
}

@ARTICLE{Storey2010-yi,
  title        = {False Discovery Rates},
  author       = {Storey, John D},
  journaltitle = {International Encyclopedia of Statistical Science},
  pages        = {1--7},
  date         = {2010}
}

@ARTICLE{Curran-Everett2007-nk,
  title        = {Guidelines for reporting statistics in journals published by
                  the \textit{American Physiological Society}: the sequel},
  author       = {Curran-Everett, Douglas and Benos, Dale J},
  journaltitle = {Adv. Physiol. Educ.},
  volume       = {31},
  issue        = {4},
  pages        = {295--298},
  date         = {2007-12},
  doi          = {10.1152/advan.00022.2007},
  pmid         = {18057394},
  issn         = {1043-4046,1522-1229},
  url          = {http://dx.doi.org/10.1152/advan.00022.2007},
  language     = {en}
}

@ARTICLE{Bates2015-al,
  title        = {Fitting linear mixed-effects models using {lme4}},
  author       = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker,
                  Steve},
  journaltitle = {J. Stat. Softw.},
  volume       = {67},
  issue        = {1},
  date         = {2015},
  doi          = {10.18637/jss.v067.i01},
  issn         = {1548-7660},
  url          = {http://www.jstatsoft.org/v67/i01/},
  urldate      = {2016-01-19},
  language     = {en}
}

@BOOK{Pinheiro2000-sg,
  title     = {{Mixed-effects Models in S and S-{PLUS}}},
  author    = {Pinheiro, José C and Bates, Douglas M},
  publisher = {Springer},
  date      = {2000},
  pagetotal = {1}
}

@ARTICLE{Warton2006-ka,
  title        = {Bivariate line-fitting methods from allometry},
  author       = {Warton, David and Wright, Ian and Falster, Daniel and Westoby,
                  Mark},
  journaltitle = {Biol Rev},
  volume       = {81},
  pages        = {259--291},
  date         = {2006}
}

@BOOK{Roff2006-lz,
  title     = {{Introduction to Computer-Intensive Methods of Data Analysis in
               Biology}},
  author    = {Roff, Derek A},
  publisher = {Cambridge University Press},
  date      = {2006},
  pagetotal = {376},
  url       = {http://www.google.com/search?client=safari&rls=10_7_4&q=Introduction+to+Computer+intensive+Methods+of+Data+Analysis+in+Biology&ie=UTF-8&oe=UTF-8}
}

@ARTICLE{LaBarbera1989-hn,
  title        = {Analyzing body size as a factor in ecology and evolution},
  author       = {LaBarbera, Michael C},
  journaltitle = {Annu. Rev. Ecol. Syst.},
  volume       = {20},
  pages        = {97--117},
  date         = {1989},
  issn         = {0066-4162},
  abstract     = {... it is appropriate in the majority of cases (85) where the
                  focus is "broad allometry " (103). ... of nonlinear or
                  iterative least squares techniques to fit data directly to the
                  allometric equation and to ... For simplicity, bivariate
                  techniques and multivariate techniques are discussed
                  separately. ...},
  url          = {http://www.jstor.org/stable/10.2307/2097086}
}

@ARTICLE{Akaike1974-iw,
  title        = {A new look at the statistical model identification},
  author       = {Akaike, Hirotugu},
  journaltitle = {IEEE Trans. Automat. Contr.},
  volume       = {AC-19},
  issue        = {6},
  pages        = {716--723},
  date         = {1974},
  issn         = {0018-9286}
}

@BOOK{Burnham2002-xt,
  title     = {{Model Selection and Multi-model Inference: a Practical
               Information Theoretic Approach}},
  author    = {Burnham, Kenneth P and Anderson, David R},
  publisher = {Springer},
  location  = {New York},
  date      = {2002},
  pagetotal = {19}
}

@ARTICLE{swartz_biomechanics_2008,
  title        = {Biomechanics of the bat limb skeleton: scaling, material
                  properties and mechanics},
  author       = {Swartz, Sharon M and Middleton, Kevin M},
  journaltitle = {Cells Tissues Organs},
  volume       = {187},
  issue        = {1},
  pages        = {59--84},
  date         = {2008},
  doi          = {10.1159/000109964},
  pmid         = {18160803},
  issn         = {1422-6405,1422-6421},
  abstract     = {BACKGROUND/AIMS: Wing skeletons of bats are uniquely
                  specialized for flight, reflecting both evolutionary history
                  and the need to maintain structural integrity while generating
                  aerodynamic forces. METHODS: We analyzed the anatomical
                  structure of bat wing skeletons in the context of scaling
                  patterns relative to other mammals, material properties and
                  the mechanical function of the wing bones during flight.
                  RESULTS: Compared with nonvolant mammals, the bones of the bat
                  forelimb are elongated, even after correcting for shared
                  phylogenetic history. Bats have consistently larger-diameter
                  bones in the forelimb than do nonvolant mammals but
                  significantly narrower hindlimb bones. Mineralization in the
                  cortical bone of wings is lower than in the long bones of
                  other adult mammals, with a proximodistal gradient of
                  decreasing mineralization. The distal phalanges have only a
                  small amount of mineralized tissue underlying the articular
                  cartilage. Loads required to elicit a 10\% length deflection
                  in the wing bones of Glossophaga soricina varied approximately
                  50-fold along the wing and flexural stiffness nearly 200-fold.
                  Commensurate with low mineralization and flexural stiffness,
                  bat bones experience extraordinarily high bending strains
                  during flight. CONCLUSION: Bat limb skeletons share features
                  with other mammals and possess specialized characteristics,
                  mostly related to the mechanical demands of flight.},
  url          = {http://dx.doi.org/10.1159/000109964}
}

@ARTICLE{Pericchi1981-wm,
  title        = {A Bayesian approach to transformation to normality},
  author       = {Pericchi, L R},
  journaltitle = {Biometrika},
  volume       = {68},
  issue        = {1},
  pages        = {35--43},
  date         = {1981},
  issn         = {0006-3444}
}

@ARTICLE{VanderPlas2014-km,
  title        = {Frequentism and Bayesianism: A Python-driven Primer},
  shorttitle   = {Frequentism and Bayesianism},
  author       = {VanderPlas, Jake},
  journaltitle = {arXiv [astro-ph.IM]},
  date         = {2014-11-18},
  eprint       = {1411.5018},
  eprinttype   = {arXiv},
  eprintclass  = {astro-ph.IM},
  abstract     = {This paper presents a brief, semi-technical comparison of the
                  essential features of the frequentist and Bayesian approaches
                  to statistical inference, with several illustrative examples
                  implemented in Python. The differences between frequentism and
                  Bayesianism fundamentally stem from differing definitions of
                  probability, a philosophical divide which leads to distinct
                  approaches to the solution of statistical problems as well as
                  contrasting ways of asking and answering questions about
                  unknown parameters. After an example-driven discussion of
                  these differences, we briefly compare several leading Python
                  statistical packages which implement frequentist inference
                  using classical methods and Bayesian inference using Markov
                  Chain Monte Carlo.},
  url          = {http://arxiv.org/abs/1411.5018},
  urldate      = {2016-05-14},
  note         = {<p>Comment: 9 pages; 1 figure</p>}
}

@ARTICLE{De_Villemereuil2012-js,
  title        = {Bayesian models for comparative analysis integrating
                  phylogenetic uncertainty},
  author       = {de Villemereuil, Pierre and Wells, Jessie A and Edwards,
                  Robert D and Blomberg, Simon P},
  journaltitle = {BMC Evol. Biol.},
  volume       = {12},
  pages        = {102},
  date         = {2012-06-28},
  doi          = {10.1186/1471-2148-12-102},
  pmc          = {PMC3582467},
  pmid         = {22741602},
  issn         = {1471-2148},
  abstract     = {BACKGROUND: Uncertainty in comparative analyses can come from
                  at least two sources: a) phylogenetic uncertainty in the tree
                  topology or branch lengths, and b) uncertainty due to
                  intraspecific variation in trait values, either due to
                  measurement error or natural individual variation. Most
                  phylogenetic comparative methods do not account for such
                  uncertainties. Not accounting for these sources of uncertainty
                  leads to false perceptions of precision (confidence intervals
                  will be too narrow) and inflated significance in hypothesis
                  testing (e.g. p-values will be too small). Although there is
                  some application-specific software for fitting Bayesian models
                  accounting for phylogenetic error, more general and flexible
                  software is desirable. METHODS: We developed models to
                  directly incorporate phylogenetic uncertainty into a range of
                  analyses that biologists commonly perform, using a Bayesian
                  framework and Markov Chain Monte Carlo analyses. RESULTS: We
                  demonstrate applications in linear regression, quantification
                  of phylogenetic signal, and measurement error models.
                  Phylogenetic uncertainty was incorporated by applying a prior
                  distribution for the phylogeny, where this distribution
                  consisted of the posterior tree sets from Bayesian
                  phylogenetic tree estimation programs. The models were
                  analysed using simulated data sets, and applied to a real data
                  set on plant traits, from rainforest plant species in Northern
                  Australia. Analyses were performed using the free and open
                  source software OpenBUGS and JAGS. CONCLUSIONS: Incorporating
                  phylogenetic uncertainty through an empirical prior
                  distribution of trees leads to more precise estimation of
                  regression model parameters than using a single consensus tree
                  and enables a more realistic estimation of confidence
                  intervals. In addition, models incorporating measurement
                  errors and/or individual variation, in one or both variables,
                  are easily formulated in the Bayesian framework. We show that
                  BUGS is a useful, flexible general purpose tool for
                  phylogenetic comparative analyses, particularly for modelling
                  in the face of phylogenetic uncertainty and accounting for
                  measurement error or individual variation in explanatory
                  variables. Code for all models is provided in the BUGS model
                  description language.},
  url          = {http://dx.doi.org/10.1186/1471-2148-12-102},
  urldate      = {2016-03-11},
  note         = {Pages 1-16 in PDF},
  language     = {en}
}

@ARTICLE{Gelman2014-jh,
  title        = {Understanding predictive information criteria for Bayesian
                  models},
  author       = {Gelman, Andrew and Hwang, Jessica and Vehtari, Aki},
  journaltitle = {Stat. Comput.},
  publisher    = {Springer US},
  volume       = {24},
  issue        = {6},
  pages        = {997--1016},
  date         = {2014-11-01},
  doi          = {10.1007/s11222-013-9416-2},
  issn         = {0960-3174,1573-1375},
  abstract     = {We review the Akaike, deviance, and Watanabe-Akaike
                  information criteria from a Bayesian perspective, where the
                  goal is to estimate expected out-of-sample-prediction error
                  using a bias-corrected adjustment of within-sample error. We
                  focus on the choices involved in setting up these measures,
                  and we compare them in three simple examples, one theoretical
                  and two applied. The contribution of this paper is to put all
                  these information criteria into a Bayesian predictive context
                  and to better understand, through small examples, how these
                  methods can apply in practice.},
  url          = {https://link.springer.com/article/10.1007/s11222-013-9416-2},
  urldate      = {2016-03-01},
  language     = {en}
}

@ARTICLE{Vehtari2017-we,
  title        = {Practical Bayesian model evaluation using leave-one-out
                  cross-validation and {WAIC}},
  author       = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  journaltitle = {Stat. Comput.},
  volume       = {27},
  issue        = {5},
  pages        = {1413--1432},
  date         = {2017-09-01},
  doi          = {10.1007/s11222-016-9696-4},
  issn         = {0960-3174},
  abstract     = {Leave-one-out cross-validation (LOO) and the widely applicable
                  information criterion (WAIC) are methods for estimating
                  pointwise out-of-sample prediction accuracy from a fitted
                  Bayesian model using the log-likelihood evaluated at the
                  posterior simulations of the parameter values. LOO and WAIC
                  have various advantages over simpler estimates of predictive
                  error such as AIC and DIC but are less used in practice
                  because they involve additional computational steps. Here we
                  lay out fast and stable computations for LOO and WAIC that can
                  be performed using existing simulation draws. We introduce an
                  efficient computation of LOO using Pareto-smoothed importance
                  sampling (PSIS), a new procedure for regularizing importance
                  weights. Although WAIC is asymptotically equal to LOO, we
                  demonstrate that PSIS-LOO is more robust in the finite case
                  with weak priors or influential observations. As a byproduct
                  of our calculations, we also obtain approximate standard
                  errors for estimated predictive errors and for comparison of
                  predictive errors between two models. We implement the
                  computations in an R package called loo and demonstrate using
                  models fit with the Bayesian inference package Stan.},
  url          = {https://doi.org/10.1007/s11222-016-9696-4}
}

@ARTICLE{Mayer2010-ns,
  title        = {Drawing an elephant with four complex parameters},
  author       = {Mayer, Jürgen and Khairy, Khaled and Howard, Jonathon},
  journaltitle = {Am. J. Phys.},
  volume       = {78},
  issue        = {6},
  pages        = {648--649},
  date         = {2010-06-01},
  doi          = {10.1119/1.3254017},
  issn         = {0002-9505,1943-2909},
  abstract     = {We define four complex numbers representing the parameters
                  needed to specify an elephantine shape. The real and imaginary
                  parts of these complex numbers are the coefficients of a
                  Fourier coordinate expansion, a powerful tool for reducing the
                  data required to define shapes.},
  url          = {http://scitation.aip.org/content/aapt/journal/ajp/78/6/10.1119/1.3254017},
  urldate      = {2016-02-13}
}

@BOOK{McElreath2015-no,
  title      = {{Statistical Rethinking: A Bayesian Course with Examples in R
                and Stan}},
  shorttitle = {Statistical Rethinking},
  author     = {McElreath, Richard},
  publisher  = {Chapman and Hall/CRC},
  location   = {Boca Raton, FL},
  date       = {2015},
  pagetotal  = {487},
  isbn       = {9781482253443},
  language   = {English}
}

@BOOK{Robinson2017-uv,
  title     = {Introduction to Empirical Bayes},
  author    = {Robinson, David},
  publisher = {Gumroad},
  date      = {2017}
}

@BOOK{Kruschke2015-rp,
  title      = {{Doing Bayesian Data Analysis: a Tutorial with R, JAGS, and
                Stan}},
  shorttitle = {Doing Bayesian Data Analysis},
  author     = {Kruschke, John K},
  publisher  = {Academic Press},
  location   = {Boston, MA},
  edition    = {2nd},
  date       = {2015},
  doi        = {10.1016/B978-0-12-405888-0.09999-2},
  isbn       = {9780124058880,9780124058880},
  abstract   = {Provides an accessible approach to Bayesian data analysis, as
                material is explained clearly with concrete examples. The book
                begins with the basics, including essential concepts of
                probability and random sampling, and gradually progresses to
                advanced hierarchical modeling methods for realistic data.},
  url        = {http://www.sciencedirect.com/science/article/pii/B9780124058880099992},
  language   = {English}
}

@ARTICLE{Puga2015-aq,
  title        = {Points of significance: Bayesian statistics},
  author       = {Puga, Jorge López and Krzywinski, Martin and Altman, Naomi},
  journaltitle = {Nat. Methods},
  publisher    = {Nature Research},
  volume       = {12},
  issue        = {5},
  pages        = {377--378},
  date         = {2015-04-29},
  doi          = {10.1038/nmeth.3368},
  issn         = {1548-7091,1548-7105},
  abstract     = {Today's predictions are tomorrow's priors.},
  url          = {http://dx.doi.org/10.1038/nmeth.3368},
  urldate      = {2017-03-09},
  language     = {en}
}

@ARTICLE{Chib1995-ok,
  title        = {Understanding the Metropolis-Hastings Algorithm},
  author       = {Chib, Siddhartha and Greenberg, Edward},
  journaltitle = {Am. Stat.},
  publisher    = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  volume       = {49},
  issue        = {4},
  pages        = {327--335},
  date         = {1995},
  doi          = {10.2307/2684568},
  issn         = {0003-1305},
  abstract     = {We provide a detailed, introductory exposition of the
                  Metropolis-Hastings algorithm, a powerful Markov chain method
                  to simulate multivariate distributions. A simple, intuitive
                  derivation of this method is given along with guidance on
                  implementation. Also discussed are two applications of the
                  algorithm, one for implementing acceptance-rejection sampling
                  when a blanketing function is not available and the other for
                  implementing the algorithm with block-at-a-time scans. In the
                  latter situation, many different algorithms, including the
                  Gibbs sampler, are shown to be special cases of the
                  Metropolis-Hastings algorithm. The methods are illustrated
                  with examples.},
  url          = {http://www.jstor.org/stable/2684568}
}
