---
title: "Unit 6: Making Decisions"
subtitle: "Tail probabilities, hypothesis testing, and null models"
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
format:
  clean-revealjs:
    self-contained: true
    chalkboard: false
    standalone: true
    slide-number: true
    show-slide-number: print
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

```{r}
#| label: setup
#| echo: false

library(tidyverse)
library(patchwork)
library(cowplot)
library(latex2exp)
library(magick)
library(ggpubr)
library(effectsize)
options(es.use_symbols = TRUE)

options(pillar.sigfig = 4)

theme_set(theme_classic(base_size = 20))

source("https://raw.githubusercontent.com/QM-Life-Sci/QMLS_1/refs/heads/main/Lectures/QMLS_functions.R")


```


# Housekeeping {background-color="#40666e"}

- Problem sets: Try to answer all the questions
- Progress check: Grading in progress
- Be thinking about / looking for a data set
    - Let me know if you want to discuss


# What is the process for making decisions through science? {background-color="#40666e"}


# Distributions and tail probabilities {background-color="#40666e"}


## Random normal values

- Generate 100,000 values from a normal distribution with a mean of 5 and a standard deviation of 1
- Generate 100,000 values from a normal distribution with a mean of 5 and a standard deviation of 5

```{r}
#| echo: true

set.seed(832476)
sd1 <- tibble(y = rnorm(100000, 5, 1))
sd5 <- tibble(y = rnorm(100000, 5, 5))
```


## Histograms of random normal values

```{r echo=FALSE}
p1 <- sd1 |> ggplot(aes(y)) +
  geom_histogram(bins = 50, fill = "forestgreen") +
  labs(y = "Count")
p2 <- sd5 |> ggplot(aes(y)) +
  geom_histogram(bins = 50, fill = "forestgreen") +
  labs(y = "Count")

plot_grid(p1, p2, ncol = 2)
```


## What proportion of values are above 7?

Count the values > 7:

```{r}
#| echo: true

sum(sd1$y > 7)
sum(sd1$y > 7) / 100000
mean(sd1$y > 7)
```

. . .

```{r}
#| echo: true

sum(sd5$y > 7)
sum(sd5$y > 7) / 100000
mean(sd5$y > 7)
```


## Using `pnorm()`: Probability for a normal distribution

- Uses a normal distribution defined by an equation (not samples)
    - Exact, not by counting
- `lower.tail = FALSE` returns the probability > 7

```{r}
#| echo: true

pnorm(7, mean = 5, sd = 1, lower.tail = FALSE)
pnorm(7, mean = 5, sd = 5, lower.tail = FALSE)
```

Compare the values returned by `pnorm()` to the proportions on the previous slide.


## Tail probabilities

```{r}
#| echo: true
#| fig-align: center

shade_normal(p = 0.025, tail = "both", mean = 5, sd = 1)
qnorm(0.025, mean = 5, sd = 1)
```


# $t$ Distribution and Exact confidence intervals {background-color="#40666e"}


## *t* Distribution

```{r}
#| echo: true
#| fig-align: center

shade_t(0.025, df = 5)
qt(0.025, df = 5)
```


## Calculating exact confidence intervals

Multiply the *SEM* by the *t*-value encompassing 95% for a *t* distribution with a given degrees of freedom (e.g., *n*-1).

```{r}
#| echo: false
#| warning: false
#| fig-height: 5
#| fig-align: center

x <- seq(-4, 4, by = 0.01)

sim <- tibble(df = c(2, 5, 20)) |>
  group_by(df) |>
  do(tibble(x = x, y = dt(x, .$df))) |>
  mutate(Parameters = paste0("df = ", df)) |>
  ungroup() |>
  mutate(Parameters = factor(Parameters, levels = unique(Parameters)))

norm <- tibble(
  x = x,
  y = dnorm(x, 0, 1))

pal <- palette()[2:4]

ggplot() +
  geom_line(data = norm, aes(x, y), linewidth = 3) +
  geom_line(data = sim, aes(x, y, color = Parameters), linewidth = 1.5) +
  scale_color_manual(values = pal, name = "Degrees of\nFreedom") +
  labs(x = "t", y = "Relative Likelihood") +
  theme(legend.position = "inside",
        legend.position.inside = c(0.85, 0.75))
```


## *t* Distribution approaches a normal as *df* increases

```{r}
#| echo: true

qt(0.975, 10 - 1)

qt(0.975, 100 - 1)

qt(0.975, 1000000000 - 1)

qnorm(0.975, 0, 1)
```


## Calculating exact confidence intervals

```{r}
#| echo: false

shade_t(0.025, 5) +
  ggtitle(TeX("$t$-distribution with df = 5"))
```

Need the critical value that marks the 2.5% cutoff at each tail.


## Example CI calculation

```{r}
#| echo: true

undulation_rate <- c(0.9, 1.2, 1.2, 1.3, 1.4, 1.4, 1.6, 2.0)

undulation_mean <- mean(undulation_rate)
undulation_SEM <- sd(undulation_rate) / sqrt(length(undulation_rate))
```

. . .

```{r}
#| echo: true
lower_approx <- undulation_mean - 2 * undulation_SEM
upper_approx <- undulation_mean + 2 * undulation_SEM

c(lower_approx, undulation_mean, upper_approx)
```

. . .

```{r}
#| echo: true

crit <- qt(0.025, df = 8 - 1, lower.tail = FALSE)

lower <- undulation_mean - crit * undulation_SEM
upper <- undulation_mean + crit * undulation_SEM

c(lower, undulation_mean, upper)
```


# What do confidence intervals represent {background-color="#40666e"}


## Repeated experiments

> A confidence interval is a range that we expect, with some level of conÔ¨Ådence, to include the true value of a population parameter such as the mean. [@Curran-Everett2009-zz]

Our calculation is based on our expectation from sampling the true population distribution *repeatedly.*

- Same sample size, same experimental conditions
- Same procedures, same analysis
- [UBC CI Simulator](https://www.zoology.ubc.ca/~whitlock/Kingfisher/CIMean.htm)


# Other distributions we will encounter {background-color="#40666e"}


## *F* Distribution

```{r}
#| echo: true
#| fig-align: center

shade_F(0.05, df1 = 2, df2 = 10)
qf(0.05, df1 = 2, df2 = 10, lower.tail = FALSE)
```


## $\chi^2$ Distribution

```{r fig.height = 3}
#| echo: true
#| fig-align: center

shade_chisq(0.05, df = 2)
qchisq(0.05, df = 2, lower.tail = FALSE)
```


## Why do we always seem to use 0.05 or 0.025?

5% is a "special" number - the arbitrary threshold for statistical significance

:::: {.columns}

::: {.column width="50%"}

```{r}
#| fig-height: 7

shade_normal(0.025, tail = "both") +
  theme(text = element_text(size = 24))
```

:::

::: {.column width="50%"}

```{r}
#| fig-height: 7

shade_normal(0.05, tail = "upper") +
  theme(text = element_text(size = 24))
```

:::

::::


## We could choose any probability for any distribution

```{r}
#| echo: true
#| fig-align: center

shade_normal(0.34, tail = "upper", mean = -10, sd = 2)
```


## The `r`, `d`, `p`, and `q` functions for distributions {.smaller}

Example for a normal distribution (Specify `mean` and `sd` or defaults is standard normal: $\mu = 0$, $\sigma = 1$):

1. `rnorm(n, ...)`: `n` random draws
1. `dnorm(x, ...)`: Relative likelihood (density) at `x` values
1. `pnorm(q, ...)`: (Lower) tail probability for a quantile `q` 
1. `qnorm(p, ...)`: Quantile for a given (lower) tail probability `p`

- `lower.tail = FALSE` for the upper tail
- `log = TRUE` for log-probability


## `rnorm(n = 50, mean = 0, sd = 1)`


```{r}
#| echo: true

set.seed(387493)
RR <- tibble("values" = rnorm(50,0,1))

```


:::: {.columns}

::: {.column width="40%"}

```{r}

shade_normal(0, tail = "both")

```

:::

::: {.column width="20%"}

```{r}

RR

```

:::

::: {.column width="40%"}

```{r}

ggplot(RR, aes(values)) + 
  geom_dotplot() +
  scale_y_continuous(NULL, breaks = NULL) +
  xlim(c(-4, 4))

```

:::

::::


## `dnorm(x = 1, mean = 0, sd = 1)`

```{r}
#| echo: true

dnorm(x = 1, mean = 0, sd = 1)
```

```{r}
M <- tibble(x = seq(-4, 4, length = 200),
            y = dnorm(x))

p <- ggplot(M, aes(x, y)) +
  geom_line() +
  geom_hline(yintercept = dnorm(1), linetype = "dashed") +
  geom_vline(xintercept = 1) +
  annotate("text", x = 4, y = dnorm(1) + 0.02, label = round(dnorm(1),4)) +
  labs(x = "Value", y = "Relative Likelihood") +
  scale_x_continuous(breaks = -4:4)

p

```


## `pnorm(q=1, mean=0, sd=1)`

```{r}
#| echo: true

pnorm(q = 1, mean = 0, sd = 1)

```

```{r}
#| echo: false

shade_normal(0.8413447, tail = "lower")

```


## `qnorm(p=0.841, mean=0, sd=1)`


```{r}
#| echo: true

qnorm(p = 0.841, mean = 0, sd = 1)

```

```{r}
#| echo: false

pp <- shade_normal(0.8413447, tail = "lower") +
  geom_vline(xintercept = 1) +
  scale_x_continuous(breaks = -4:4)
pp
  
```


## Goals of statistical inference

```{r}
set.seed(3575575)

Alive <- rnorm(n = 150, mean = 24.5, sd = 2.6)
Dead <- rnorm(n = 30, mean = 22.0, sd = 2.7)
Group <- c(rep("Alive", 150),
           rep("Dead", 30))

HL <- tibble(Horn_Length = c(Alive, Dead),
             Group = factor(Group))

liz <- image_read("https://tpwd.texas.gov/huntwild/wild/images/reptiles/horned_lizardlarge.jpg")

img <- ggplot() + background_image(liz) 


P_HL <- HL |>
  ggplot(aes(Group, Horn_Length)) +
  geom_point(position = position_jitter(width = 0.2, seed = 423479),
             alpha = 0.5, size = 3) +
  theme(text = element_text(size = 20)) +
  labs(y = "Horn Length (mm)")

P_HL +
  inset_element(img, left = 0.8, bottom = 0.7, right = 1, top = 1)

```


## What is the effect of group on horn length? 

```{r}
mu.a <- mean(HL$Horn_Length[HL$Group == "Alive"])
mu.d <- mean(HL$Horn_Length[HL$Group == "Dead"])

P_HL + 
  geom_segment(x = 0.6, y = mu.a, xend = 1.4, yend = mu.a,
               color = "steelblue", linewidth = 2) +
  geom_segment(x = 1.6, y = mu.d, xend = 2.4, yend = mu.d,
               color = "steelblue", linewidth = 2) +
  theme(text = element_text(size = 20)) +
  labs(y = "Horn Length (mm)")
 
```


## What is the effect of group on horn length? 

```{r}
P_HL + 
  geom_segment(x = 0.6, y = mu.a, xend = 1.4, yend = mu.a,
               color = "steelblue", linewidth = 2) +
  geom_segment(x = 1.6, y = mu.d, xend = 2.4, yend = mu.d,
               color = "steelblue", linewidth = 2) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.1,
               color = "red", linewidth = 2) + 
  theme(text = element_text(size = 20)) +
  labs(y = "Horn Length (mm)")

```


## What is the effect of group on horn length? 

```{r}
dd <- mu.a - mu.d
P_HL + 
  geom_segment(x = 0, y = mu.a, xend = 3, yend = mu.a,
               color = "steelblue", linewidth = 2) +
  geom_segment(x = 0, y = mu.d, xend = 3, yend = mu.d,
               color = "steelblue", linewidth = 2) +
  theme(text = element_text(size = 20)) +
  annotate("text", x = 1.5, y = mu.d + 0.5 * dd,
           label = paste0("Effect Size = ", round(dd, 2)),
           size = 6)

```


## How certain are we of the effect of group?

```{r}
ttt <- t.test(Horn_Length ~ Group, data = HL)
g_mu <- mean(c(mu.a, mu.d))
ll <- ttt$conf.int[1]
uu <- ttt$conf.int[2]

HL |>
  ggplot(aes(Group, Horn_Length)) +
  geom_rect(xmin = 0, xmax = 2.2,
            ymin = g_mu - 0.5 * uu, ymax = g_mu + 0.5 * uu,
            fill = "lightblue") +
  geom_rect(xmin = 0, xmax = 2.2, ymin = mu.d,
            ymax = mu.a, fill = "steelblue") +
  geom_rect(xmin = 0, xmax = 2.2,
            ymin = g_mu - 0.5 * ll, ymax = g_mu + 0.5 * ll,
            fill = "navy") +
  geom_segment(y = g_mu - 0.5 * ll, yend = g_mu + 0.5 * ll,
               x = 2.23, xend = 2.23, color = "navy", linewidth = 2) +
  annotate("text", x = 2.33, y = mu.d + 0.5 * dd,
           label = paste0("Lower \n", round(ll, 2)),
           size = 4) +
  geom_segment(y = mu.d, yend = mu.a,
               x = 2.43, xend = 2.43, color = "steelblue", linewidth = 2) +
  annotate("text", x = 2.53, y = mu.d + 0.5 * dd,
           label = paste0("Effect\nSize\n", round(dd, 2)),
           size = 4) +
  geom_segment(y = g_mu - 0.5 * uu, yend = g_mu + 0.5 * uu,
               x = 2.63, xend = 2.63, color = "lightblue", linewidth = 2) +
  annotate("text", x = 2.73, y = mu.d + 0.5 * dd,
           label = paste0("Upper \n", round(uu, 2)),
           size = 4) +
  geom_point(position = position_jitter(width = 0.2, seed = 423479),
             alpha = 1/2, size = 3) +
  expand_limits(x = c(0, 3)) +
  theme(text = element_text(size = 20)) +
  labs(y = "Horn Length (mm)")

```


## Standardized effect size

- "Raw" effect size = 2.22 mm
    - Specific to this analysis (original scale)
- Standardize for comparing analyses
    - Pearson's correlation (*r*), Cohen's *d*, etc. (more on planning experiments later this semester)

$$d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$$


## Standardized effect size

Calculate Cohen's $d$ using the `effectsize` package:

```{r}
#| echo: true

library(effectsize)
cohens_d(Horn_Length ~ Group, data = HL)
```

- Uses "pooled" standard deviation: sd weighted by the sample size


## How is the mean different in alive lizards compared to dead? 

- Live horned lizards: `r round(mean(HL$Horn_Length[HL$Group == "Alive"]), 1)` mm
- Dead horned lizards: `r round(mean(HL$Horn_Length[HL$Group == "Dead"]), 1)` mm

. . . 
 
Imagine collecting 180 live horned lizards and randomly assigning 150 to one group and 30 to the other.

. . .

- Do you think they would have the same mean horn length?
- How different do you think the means would be?
- How would the variability among individual horn length measurements change your intuition?


## How large of a difference do we expect from sampling error?

:::: {.columns}

::: {.column width="50%"}
![](https://i.imgur.com/EIfjPa0.jpg){fig-align="center" width=100%}
:::

::: {.column width="50%"}
- Imagine a distribution of horn lengths for a population of horned lizards (mean = 24, sd = 2.6)
- Randomly catch two groups of $n = 150$ and  $n = 30$ from this population
- How different are the groups?
:::

::::


## How large of a difference do we expect from sampling error?

```{r}
#| echo: true
#| eval: false

set.seed(883231)

mu.horn <- 24     # mean
sd.horn <- 2.6    # standard deviation
n.iter <- 100000  # number of iterations
n.samp1 <- 150    # number in first sample
n.samp2 <- 30     # number in second sample
sim.diff <- tibble(dd = numeric(length = n.iter)) # to hold output  

for (zz in 1:n.iter) {
  s1 <- rnorm(n.samp1, mu.horn, sd.horn) # sample 1
  s2 <- rnorm(n.samp2, mu.horn, sd.horn) # sample 2
  sim.diff[zz, 'dd'] <- mean(s1) - mean(s2) # difference in means
}
```

```{r}
# Do the sampling here and save to Rds file.
mu.horn <- 24     # mean
sd.horn <- 2.6    # standard deviation
n.iter <- 100000  # number of iterations
n.samp1 <- 150    # number in first sample
n.samp2 <- 30     # number in second sample

if (FALSE) {
  set.seed(883231)
  
  sim.diff <- tibble(dd = numeric(length = n.iter)) # to hold output  
  
  for (zz in 1:n.iter) {
    s1 <- rnorm(n.samp1, mu.horn, sd.horn) # sample 1
    s2 <- rnorm(n.samp2, mu.horn, sd.horn) # sample 2
    sim.diff[zz, 'dd'] <- mean(s1) - mean(s2) # difference in means
  }
  write_rds(sim.diff, file = "../data/Random_horns.rds")
}

sim.diff <- readRDS("../data/Random_horns.rds")
```


## Sampling the null distribution

```{r}
set.seed(34872394)
dots <- tibble(Horn_Length = rnorm(180, mean = mu.horn, sd = sd.horn),
               Group = factor(c(rep("Alive", 150), rep("Dead", 30))))

dots |> 
  ggplot(aes(Horn_Length)) + 
  geom_dotplot(method = "histodot", binwidth = 0.5, stackgroups = TRUE) +
  scale_fill_viridis_d() +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_x_continuous(limits = c(15, 35)) +
  labs(x = "Horn Length (mm)")
```


## Sampling the null distribution

```{r}
dots |> 
  ggplot(aes(Horn_Length, fill = Group)) + 
  geom_dotplot(method = "histodot", binwidth = 0.5, stackgroups = TRUE) +
  scale_fill_viridis_d() +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(legend.position = c(0.8, 0.8)) +
  scale_x_continuous(limits = c(15, 35)) +
  labs(x = "Horn Length (mm)")

```


## Sampling the null distribution

```{r}
set.seed(3424)
dots <- tibble(Horn_Length = rnorm(180, mean = mu.horn, sd = sd.horn),
               Group = factor(c(rep("Alive", 150), rep("Dead", 30))))

dots |> 
  ggplot(aes(Horn_Length, fill = Group)) + 
  geom_dotplot(method = "histodot", binwidth = 0.5, stackgroups = TRUE) +
  scale_fill_viridis_d() +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_x_continuous(limits = c(15, 35)) +
  theme(legend.position = c(0.8, 0.8)) +
  labs(x = "Horn Length (mm)")
```


## Sampling the null distribution

```{r}
set.seed(67566)
dots <- tibble(Horn_Length = rnorm(180, mean = mu.horn, sd = sd.horn),
               Group = factor(c(rep("Alive", 150), rep("Dead", 30))))

dots |> 
  ggplot(aes(Horn_Length, fill = Group)) + 
  geom_dotplot(method = "histodot", binwidth = 0.5, stackgroups = TRUE) +
  scale_fill_viridis_d() +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_x_continuous(limits = c(15, 35)) +
  theme(legend.position = c(0.8, 0.8)) +
  labs(x = "Horn Length (mm)")
```


## How large of a difference do we expect from sampling error?

```{r}

sim.diff <- readRDS("../data/Random_horns.rds")

ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30, fill = "gray50") +
  labs(x = "Difference of Means", y = "Count")
```


## How large of a difference do we expect from sampling error?

```{r}
p1 <- ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30, fill = "gray50") +
  labs(x = "Difference of Means", y = "Count")

HL_mean <- HL |> 
  group_by(Group) |> 
  summarize(Mean = mean(Horn_Length)) |> 
  gather(Value, x, -Group)

p2 <- HL |> 
  ggplot(aes(Horn_Length)) +
  geom_histogram(bins = 30, fill = "gray50") +
  geom_vline(data = HL_mean, aes(xintercept = x, color = Value),
             linewidth = 2, color = "firebrick4") +
  facet_grid(Group ~ .) +
  labs(x = "Horn Length (mm)", y = "Count") +
  theme(legend.position = "none")

plot_grid(p2, p1, ncol = 2)
```

<center>
Observed difference = `r round(mean(HL$Horn_Length[HL$Group == "Alive"]), 1) - round(mean(HL$Horn_Length[HL$Group == "Dead"]), 1)` mm
</center>


## Goals of Statistical Inference

::: {.incremental}

1. Parameter (i.e., effect) estimation
    - Given a model, with unknown parameters ($\theta_0$, $\theta_1$, ..., $\theta_k$), how to estimate values of those parameters?
2. Interval estimation
    - How to quantify the uncertainty associated with parameter estimates?
3. Making decisions (i.e., Hypothesis testing)
    - How to test hypotheses about parameter estimates?
    - What conclusions can we make from our analysis?

:::

    
## Hypotheses

**Hypothesis**: a statement that can be either true or false

**Statistical hypothesis**: a hypothesis about about a parameter (or parameters) of a population or process

- Many statistical analyses have the goal of performing a hypothesis test.


## How large of a difference do we expect from sampling error?

```{r}
p1 <- ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30, fill = "gray50") +
  labs(x = "Difference of Means", y = "Count")

HL_mean <- HL |> 
  group_by(Group) |> 
  summarize(Mean = mean(Horn_Length)) |> 
  gather(Value, x, -Group)

p2 <- HL |> 
  ggplot(aes(Horn_Length)) +
  geom_histogram(bins = 30, fill = "gray50") +
  geom_vline(data = HL_mean, aes(xintercept = x, color = Value),
             linewidth = 2, color = "firebrick4") +
  facet_grid(Group ~ .) +
  labs(x = "Horn Length (mm)", y = "Count") +
  theme(legend.position = "none")

plot_grid(p2, p1, ncol = 2)
```

<center>
Observed difference = `r round(mean(HL$Horn_Length[HL$Group == "Alive"]), 1) - round(mean(HL$Horn_Length[HL$Group == "Dead"]), 1)` mm
</center>


## Making Decisions {.smaller}

> What is the probability of observing a difference **as big or bigger** than the observed difference *from sampling error alone*? 

The answer to this question is called a *P*-value: *P* = 4/100000 = 0.00004


```{r}
#| fig-align: center

set_above <- sim.diff[sim.diff$dd >= dd | sim.diff$dd <= -dd,]
set_above$y <- 1

p1 <- ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30, fill = "gray50") +
  geom_vline(xintercept = c(-dd,dd), linewidth = 2, color = "firebrick4") +
  geom_point(data = set_above, aes(dd, y), size = 3, alpha = 0.8,
             color = "firebrick4") +
  labs(x = "Difference of Means", y = "Count") 
p1

```


## Obtaining *P*-values

- Calculate test statistic
- Determine *P*-value (area under tail(s))

:::: {.columns}

::: {.column width="50%"}

```{r}
#| fig-align: center
#| fig-height: 7

shade_t(0.025, 178, tail = "both") +
  theme(text = element_text(size = 30))

```

:::

::: {.column width="50%"}


```{r}
#| fig-align: center
#| fig-height: 7

shade_t(0.05, 178, tail = "upper") +
  theme(text = element_text(size = 30))

```

:::

::::


## Obtaining *P*-values

```{r}
#| echo: true

summary(lm(Horn_Length ~ Group, data = HL))

```


## One sided or two-sided tests

Data will always be on one side of H~0~ or the other.

**One-sided test** ("one-tailed"):

- Appropriate when we have an *a priori* hypothesis of the direction of change

- You need justification and to be explicit about it, when you report a one-sided test.

**Two-sided test** ("two-tailed"):

- *Appropriate at all other times.*
- Multiply the one-sided *P* by 2.


## Testing different hypotheses

$$t = \frac{\theta - \theta_{null}}{\mbox{SE}_{\theta}}$$

is a general equation that can be used to test any null hypothesized parameter estimate.

- $\theta$ is the parameter estimate
- $\theta_{null}$ is the null hypothesized value
    - often and by default $\theta_{null} = 0$


## Decision errors

|               | Reject H~0~    | Fail to reject H~0~   |
|--------------:|:--------------:|:---------------------:|
|H~0~ is true   | Type I error   | *Correct*             |
|H~0~ is false  | *Correct*      | Type II error         |

Type I error occurs when:

- You decide there is a meaningful effect when in reality there isn't one.

Type II error occurs when:

- You decide there is not a meaningful effect when in reality there is one.


## Power

- Probability that a random sample will lead to a rejection of H~0~
- Dependent on how different the truth is from the null hypothesis
- Inversely related to type II errors
    - High power $\rightarrow$ low type II errors
    - Low power $\rightarrow$ high type II errors
- Power analysis will come later in the course


## Making Decisions

```{r}
gall <- tribble(
  ~ group, ~ y, ~ x, ~ Effect, ~ P, ~ Significant,
  "g1", 1,  0.01, 0.31,  0.050, "*",
  "g1", 1,  0.31, 0.31,  0.050, "*",
  "g1", 1,  0.61, 0.31,  0.050, "*",
  
  "g2", 2,  0.08, 0.10,  0.008, "*",
  "g2", 2,  0.10, 0.10,  0.008, "*",
  "g2", 2,  0.12, 0.10,  0.008, "*",
  
  "g3", 3,  0.64, 0.72,  0.001, "*",
  "g3", 3,  0.72, 0.72,  0.001, "*",
  "g3", 3,  0.80, 0.72,  0.001, "*",

  "g4", 4,  0.00, 0.31,  0.310, "NS",
  "g4", 4,  0.31, 0.31,  0.310, "NS",
  "g4", 4,  0.62, 0.31,  0.310, "NS",
  
  "g5", 5, -0.18, 0.09,  0.700, "NS",
  "g5", 5,  0.09, 0.09,  0.700, "NS",
  "g5", 5,  0.36, 0.09,  0.700, "NS",
  
  "g6", 6,  0.32, 0.47,  0.005, "NS",
  "g6", 6,  0.32, 0.47,  0.005, "NS",
  "g6", 6,  0.32, 0.47,  0.005, "NS",
  
  "g7", 7,  0.04, 0.40,  0.020, "*",
  "g7", 7,  0.44, 0.40,  0.020, "*",
  "g7", 7,  0.84, 0.40,  0.020, "*",
  
  "g8", 8,  0.10, 0.18,  0.010, "*",
  "g8", 8,  0.18, 0.18,  0.010, "*",
  "g8", 8,  0.26, 0.18,  0.010, "*",
  
  "g9", 9, -0.05, 0.44,  0.200, "NS",
  "g9", 9,  0.44, 0.44,  0.200, "NS",
  "g9", 9,  0.93, 0.44,  0.200, "NS"
)

bks <- -log10(c(0.001, 0.01, 0.05, 0.2, 0.5))
lbs <- c(0.001, 0.01, 0.05, 0.2, 0.5)

dec.plot <- ggplot(gall, aes(x,y, group = group, color = -log10(P))) +
  geom_rect(xmin = -0.4, xmax = 0.2, ymin = 0, ymax = 12,
            fill = "lightgoldenrod", color = "lightgoldenrod") +
  geom_rect(xmin = 0.2, xmax = 0.5, ymin = 0, ymax = 12,
            fill = "grey", color = "grey") +
  geom_rect(xmin = 0.5, xmax = 1.5, ymin = 0, ymax = 12,
            fill = "thistle", color = "thistle") +
  geom_vline(xintercept = 0, linetype = "dotted", color = "grey30") +
  geom_line(linewidth = 3) +
  geom_point(data=gall, aes(Effect,y,color = -log10(P)), size = 5) +
  xlim(c(-0.2, 1)) +
  ylab("Experiment") +
  xlab("Standardized Effect Size") +
  scale_color_gradient(breaks = bks, labels = lbs,
                       low = "black", high = "red", name = "P-value") +
  annotate("text", x = 0, y = 10.5, label = "Not Biologicaly\nMeaningful",
           size = 6) +
  annotate("text", x = 0.35, y = 10.5, label = "Uncertain",
           size = 6) +
  annotate("text", x = 0.75, y = 10.5,
           label = "Clearly Biologicaly\nMeaningful",
           size = 6) +
  ylim(c(1,11)) +
  theme(axis.text.y = element_blank(), text = element_text(size = 20),
        axis.ticks.y = element_blank())

dec.plot
```

:::{.right}
Figure inspired by Ian Dworkin
:::


## Problems with All or Nothing Thinking

Null hypothesis significance testing is often used inappropriately as an all or nothing decision-making tool.

```{r}
nhst.plot <- ggplot(gall, aes(x,y, group = group, color = Significant)) +
  geom_line(linewidth = 3) +
  geom_point(data=gall, aes(Effect,y,color = Significant), size = 5) +
  geom_vline(xintercept = 0, linetype = "dotted", color = "grey30") +
  scale_color_manual(values = c("red","black"))+
  ylab("Experiment") +
  xlab("Standardized Effect Size") +
  theme(axis.text.y = element_blank())  +
  theme(axis.text.y = element_blank(), text = element_text(size = 20),
        axis.ticks.y = element_blank())

nhst.plot
```


## Controversy

Philosophical and practical problems have been raised since the 1960's.

- In 1986, the *American Journal of Public Health* it would no longer accept results based on *P*-values (and then backed down 2 years later)
- *Basic and Applied Social Psychology* banned *P*-values in 2015
- In 2016, the American Statistical Association published a "Statement on *P*-Values: Context, Process, and Purpose" which critiqued the (mis)use of *P*-values. [@Wasserstein2016-qk]


## History

- Karl Pearson: Pearson's correlation, $\chi^2$, eugenics
- Ronald Fisher: Fisher's exact test, "null hypothesis", ANOVA (*F*), eugenics
- William Gosset: *t* distribution, Student's *t*-tests, Guinness
- Jerzy Neyman and Egon Pearson: "null hypothesis" testing, confidence intervals, decision theory


## History

The modern idea is traced to these statisticians, but has been warped into something different:

- Test statistics (*F*, *t*, $\chi^2$) and Fisher's rule-of-thumb *P* = 0.05 applied to Neyman-Pearson "null hypotheses"
- H~0~ becomes a straw man hypothesis of no difference or no effect


## Problem with *P*-values

- Originally an informal concept that got co-opted for what became null hypothesis significance testing (NHST)
- Apparent objectivity but actually arbitrary and dependent on the data collected and not collected
- Experimental biases (experimenter introduced, sample size)
- Science-wide publication bias


## Science-wide publication bias {.smaller}

Corollaries proposed by Ioannidis [-@Ioannidis2005-od]:

1. The smaller the studies conducted in a scientific field, the less likely the research findings are to be true.
2. The smaller the effect sizes in a scientific field, the less likely the research findings are to be true.
3. The greater the number and the lesser the selection of tested relationships in a scientific field, the less likely the research findings are to be true.
4. The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true.
5. The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true.
6. The hotter a scientific field (with more scientific teams involved), the less likely the research findings are to be true.


## How to make decisions

::: {.incremental}

- Always consider the size of the effect on a biological scale and incorporate this into your decision about how meaningful the effect is.
    - Significance alone may not mean a biological effect is important.
- Always consider your level uncertainty in your decision and report this clearly and openly.
    - No decision is made with 100% certainty. Embrace uncertainty and discuss the grey areas.

:::


## How to make decisions

:::: {.columns}

::: {.column width="50%"}

This:

```{r, fig.height=10}

dec.plot

```

:::

::: {.column width="50%"}

Not this:

```{r, fig.height=10}

nhst.plot

```

:::

::::


## Alternative suggested approaches

Preregistration of experimental design and planned analysis

1. Report parameter estimates, confidence intervals, and effect sizes 
1. Model selection (later this semester)


# Questions {background-color="#f8c471"}


## References

::: {#refs}
:::
