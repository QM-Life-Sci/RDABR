---
title: 'Problem Set 04'
author: "Your Name Here"
date: 'Last updated: `r Sys.Date()`'
format:
  html:
    toc: true
    toc_depth: 2
    toc_float: true
    embed-resources: true
---

```{r}
#| label: setup
#| message: false
#| warning: false

library(tidyverse)
library(readxl)
library(mvtnorm)
library(ggExtra)

theme_set(theme_classic())
```


# Simulating correlations

In class we looked at a bivariate normal distribution: two variables separately generated from normal distributions: Normal(0, 1). We observed the correlation between these two variables was ~0.

Two variables can be correlated and still maintain bivariate normality (one of the assumptions of a correlation). The code below generates the same distribution that we looked at in class. It is slightly different though:

- We use the `mvtnorm` package function `rmvnorm()`, which generates multivariate normal distributions. Here we make two variables simultaneously.
- We specify the correlation `r` of the two variables (the line: r <- 0), which is included in the matrix `sigma` that specifies the relationships between the simulated values.
- We assign column names to the matrix `x` (because it has none by default).

Run the code and verify that it works. You might have to install the `mvtnorm` and `ggExtra` packages.

```{r}
library(mvtnorm)
library(ggExtra)

set.seed(43237497)

r <- 0
sigma <- matrix(c(1, r, r, 1), ncol = 2)
sigma

x <- rmvnorm(n = 1e4, mean = c(0, 0), sigma = sigma)
colnames(x) <- c("V1", "V2")
head(x)
cor(x[, "V1"], x[, "V2"])

P <- ggplot(as_tibble(x), aes(V1, V2)) +
    geom_point(alpha = 0.25, color = "firebrick") +
    coord_equal()

ggMarginal(P, type = "histogram", fill = "firebrick")
```

You should see that the correlation is close to 0 (~`r round(cor(x[, "V1"], x[, "V2"]), 3)`) and that the plot looks similar to the one from class.


## Activity

Use the code block above to explore the relationship between the correlation and the distributions of the variables.

- Gradually change the correlation `r` to 0.1, 0.2, 0.5, 0.8, 0.9, 0.99. Rerun the code each time. Also try some negative correlations. You only need to change the one line: r <- 0.

What happens to the *joint* distribution of V1 and V2 as the correlation moves away from 0 and gets closer to 1 or -1?

>


In the line `x <- rmvnorm(n = 1e4, mean = c(0, 0), sigma = sigma)`, we set the mean of the normal distribution for V1 and V2 (`mean = c(0, 0)`). Change the values for the means and see how the correlation changes.

How does the pattern change when you change the mean(s)?

>



What does this result tell you about the correlation between two variables?

>



# Simulating OLS regression

In lecture, we used a set of simulated data to learn how ordinary least squares regression minimizes the sum of the squared residuals. The code we used was

```{r}
set.seed(4)
n <- 30

X <- rnorm(n, mean = 10, sd = 1)
Y <- 2.3 * X + rnorm(n, mean = 1, sd = 1)

M <- tibble(X, Y)

ggplot(M, aes(X, Y)) +
    geom_smooth(
        formula = y ~ x,
        method = "lm",
        se = FALSE,
        color = "darkorange"
    ) +
    geom_point(color = "navy", size = 3)

fm <- lm(Y ~ X + 1, data = M)
summary(fm)
```

We have added `geom_smooth()` to add a least squares regression line through the data. Although the slope and intercept of the line is calculated by `ggplot`, it matches the line from `lm()`.

The important part of the summary to look at are these lines:

```
Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept) -0.03541    2.31743  -0.015    0.988
X            2.39525    0.22035  10.870 1.48e-11 ***
```

The `Estimate` values are the `(Intercept)` (-0.03541) and slope for `X` (2.39525). We will learn about the other values in this table as well as the other parts of the summary in the coming weeks.

We will use this code block to explore how the functional relationship between a predictor and an outcome variables, as well as the variation in each impacts the inferred relationship between them.


## Activity

In the code block above, systematically change the following aspects of the simulation (but only change one thing at a time). For each, describe how the shape of the plot changes as well as the values for intercept and slope. Using factors of 10 will usually allow you to see the patterns.

The slope of the line, by changing 2.3 to larger or smaller values

>



The range of X, by changing its standard deviation

>



The random noise parameter (`rnorm(n, mean = 1, sd = 1)`) by altering its mean and standard deviation.

>



# Going further

A pharmaceutical company is testing a new drug. They have data that shows a large effect size (difference in means) but also substantial variation in the measure in both the treatment group and the control.

If the drug is approved for use, do you expect that all patients given the drug will respond the same (show improvement) and with the same magnitude. Why or why not?

>



# Lion noses

In class we looked at the correlation between lion age and the proportion of black pigmentation in their nose (or, equally, the proportion of black pigmentation and age). We also used this as motivation for ordinary least squares regression. We will complete that analysis now.

## Activity

The file `LionAges.csv` contains the data. Read the data into an R object. It has two columns:

- `age`: Age of the lion
- `proportion.black`: Proportion of the nose that is black (between 0 and 1).

```{r}

```

Make two scatter plots:

1. Proportion black plotted against age
2. Age plotted against proportion black

Feel free to color the points, add axis titles, etc., as you wish.

```{r}

```

Use the `lm()` function to fit a regression where age is predicted by proportion black. Assign the model to a variable. Then generate the `summary()`

```{r}

```

What are the slope and the intercept for the best fit line?

>


What is you interpretation of the slope of the regression in mathematical terms?

>


Why is the slope so large?

>


When we regress age on proportion black, what we are saying is that we know the proportion and want to predict age. Does that make sense in this situation?

>


How would the interpretation differ if you regressed proportion black on age?

>



# Possum head size

Possums are Australian marsupial (pouched) mammals (not to be confused with North American opossums [also marsupial mammals]). Lindenmayer and colleagues^[Lindenmayer, DB, KL Viggers, RB Cunningham, and CF Donnelly. 1995. Morphological variation among populations of the mountain brushtail possum, *Trichosurus caninus* Ogilby (Phalangeridae, Marsupialia). *Aust. J. Zool.* 43:449.] measured body and head size for 102 animals trapped in the wild in two different areas

Here is a photograph:

![](https://collections.museumsvictoria.com.au/content/media/4/360404-small.jpg)

## Activity

Load the `possum.csv` data set.

```{r}

```

What columns does the data contain? See if you can decipher from the column names what they represent. What types are they?

>


Make two plots, with points colored by sex in each:

1. Skull length plotted against age
2. Skull width plotted against age

Feel free to add axis labels, etc. Length and width measurements are in millimeters.

```{r}

```

You will get a couple of warning messages from ggplot:

```
Warning messages:
1: Removed 2 rows containing non-finite outside the scale range
(`stat_smooth()`).
2: Removed 2 rows containing missing values or values outside the scale range
(`geom_point()`).
```

See if you can determine what these messages mean.

>


What patterns do you observe in the plot of **skull length vs. age** with respect to age and sex?

>


What patterns do you observe in the plot of **skull width vs. age** with respect to age and sex?

>


Split the data into two separate tibbles one for females and one for males, by filtering on sex. For an example, see lecture 3-1, where we filtered the NHANES data.

```{r}

```

For each sex:

1. Regress skull length on age
2. Regress skull width on age

You will have 4 regressions. You can either assign the regression to an object or simply pipe (`>|`) the `lm()` to `summary()`.

```{r}

```

How do the slopes compare between females and males for **skull length**? Does this agree with the plot you made above?

>


How do the slopes compare between females and males for **skull width**? Does this agree with the plot you made above?

>


In the coming weeks, we will learn how to test whether there is a difference in the slopes between males and females.