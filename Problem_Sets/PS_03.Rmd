---
title: 'Problem Set 03'
author: "Your Name Here"
date: 'Last updated: `r Sys.Date()`'
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r}
#| label: setup
#| message: false
#| warning: false

library(tidyverse)
library(readxl)

theme_set(theme_classic())
```


# Simulating data and visualizing distributions with histograms

One of the best ways to understand a data analysis or statistical process is to simulate data. You know the "answer" ahead, and as long as you can recover that answer, you can be certain (to the extent that you can be certain) that the analysis or process works as you expect.


## Activity

In the code chunk below, generate 100 values from a normal distribution (`rnorm()`). Choose any mean and standard deviation that you wish. Means can be positive or negative, integers or real numbers. Standard deviations must be positive, but can be integers or real numbers.

Be sure to set the seed for the random number generator, so that your analysis will be reproducible.

```{r}


```


Calculate the mean and standard deviation for your vector of random numbers.

```{r}

```

How do the mean and sd compare to the values you specified above? If they differ, why do you think that might be?

> 


Imagine that you generate two sets of 100 values, drawn from the same distribution that you specified above (i.e., both have the same mean and sd). Do you expect the means and standard deviations to be identical? Why or why not?

> 


### Considerations with histograms

Below is the most basic code to plot a histogram:

- The vector `x` is converted into a `tibble()`
- `x` is passed to `aes()`
- `geom_histogram()` adds a histogram layer

You should delete the first line and replace `x` in the plotting statement to be your vector created above.

```{r}
x <- 1:20 # Delete this line and use the vector you assigned above.

ggplot(tibble(x), aes(x)) +
  geom_histogram()
```

Run the code above. You will get a message: "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`".

Basically ggplot is saying that it has divided the data into 30 equally sized ranges ("bins") by default.

In the chunk below, copy the code above. Add the argument `bins = ` to `geom_histogram()`. Start with 5 bins and gradually increase the number of bins: 5, 10, 25, 50, 100.

```{r}

```

How does the shape of the histogram change as you add more bins? 

> 


### Density plots as an alternative

One alternative to histograms is to use a density estimate which does not require binning in the same way as a histogram. Copy the histogram code from above, and replace `geom_histogram()` with `geom_density()`.

```{r}

```

What do you observe about the density plot compared to the histogram?

> 


### Counting and quantiles

In lecture we looked at the interquartile range (difference between the 0.25 and 0.75 quantiles) as a way to describe the spread of data. In this exercise we will explore how to use quantiles to summarize distributions.

Start be generating 10000 random normal values (call it `x` for convenience). Use a mean of 0 and sd of 1 (the defaults for `rnorm()`), because you can directly interpret the values as units of standard deviation.^[If you don't understand why this is true, that's OK. Just go ahead with it.]

```{r}

```

Calculate the mean and standard deviation. Confirm that they are very close to 0 and 1, respectively.

```{r}

```

Recall that we can use inequalities to generate vectors of `TRUE` and `FALSE` values.

```{r}
z <- 1:10
z < 5
```

And if we sum those values, `TRUE` is 1, and FALSE` is 0.

```{r}
sum(z < 5)
```

We can use this behavior to verify some of our rules of thumb for a normal distribution:

- ~68% of points between -1 sd and +1 sd (±1 sd)
- ~95% of points between -2 sd and +2 sd (±2 sd)
- ~99.7% of points between -3 sd and +3 sd (±3 sd)

Start by generating two vectors:

1. `gt_1` contains all values of `x` greater than  1
2. `lt_1` contains all values of `x` less than -1

These vectors contain TRUE and FALSE values. Print out the first 10 of each to confirm.

```{r}

```

Sum each of the vectors

```{r}

```

Add the two sums together and divide by 10000. Confirm that this value matches (fairly closely) the expected percent of observations more than 1 standard deviation from the mean.

```{r}

```

What do you find?

> 


Repeat the analysis above to confirm that 95% are within 2 sd and 99.7% are within 3 sd. Feel free to combine steps if you wish.

```{r}

```

How closely do they match? If they are off, why might that be?

> 



# Univariate summaries for real data

## Adaptation to drought stress in Silver Fir

The Silver Fir (*Abies alba*) is a widespread evergreen conifer tree native to the mountainous regions of Europe. Csilléry and colleagues carried out a very large (n > 8,000 measurements) experiment to study the genetic adaptations to drought tolerance in *Abies*^[Csilléry, K., N. Buchmann, and B. Fady. 2020. Adaptation to drought is coupled with slow growth, but independent from phenology in marginal silver fir (*Abies alba* Mill.) populations. *Evol. Appl.* 13:2357–2376.].

We are going to work with a part of this data set to explore the mean, median, and standard deviation.

![](https://www.cirrusimage.com/Trees/Fir/silver_fir_12.jpg){fig-align="center"}


## Activity

### Importing data into R

The data we will work with are in the file `Silver_fir.csv`. We can read this into R using the function `read_csv()`, which is loaded as part of the tidyverse package.

The code below is a minimal example of how to read data in. The first imports directly from a web address. The second (commented code) from a local file, assumed to be in the same directory as the current file.

You can use either. Just comment the other out. If you use the second, make sure to place the file in the same folder as the Rmd. 

```{r}
SF <- read_csv("https://raw.githubusercontent.com/QM-Life-Sci/RDABR/refs/heads/main/data/Silver_fir.csv")

# SF <- read_csv("Silver_fir.csv")

```

Before we work with the data, we need to do a couple of things.

- Determine how missing data were coded in the file and pass the appropriate argument for NAs (look at the help for `read_csv()`).
- The columns `family` and `block` are numeric, but should be converted to factors. Add a pipe with `mutate(family = factor(family))` and one for `block` as well. 
- Only `select()` the columns: `family`, `block`, `population`, and `ht97mm` (height in 1997 in mm)

Go back to the code block above and add these steps, piping (` |> `) the results of one step to the next.

Examine the resulting file with `str()` or `glimpse()`. You should have only 4 columns, and 8,199 rows.

```{r}

```


### Counting

These data have several layers of nesting. Each seedling has a unique `id` and comes from one of 16 `population`s. Within each `population`, multiple plants come from each `block` within a `family`. 

Tally up (`count()`) by `population`, `family`, and `block` to determine number of observations in each subgroup. Calculate the mean number of observations per group. See lecture 3-1 for an example of counting and summarizing.

```{r}

```

About how many seedlings are at the smallest replicate `block` level of the data?

> 


We want to look at the distributions of heights (`ht97mm`), but first we need to drop all NA values.

Use `drop_na()` to drop all NA values from the data:

```{r}
SF <- SF |> 
  drop_na()
```

898 rows should remain. Verify this:

```{r}
nrow(SF)
```


### Filtering

The `filter()` function can be used to quickly filter out rows based on a set of one or more conditions. For example

```{r}
BAY <- SF |> filter(population == "BAY")
```

creates a new tibble `BAY` resulting from filtering `population == BAY`. Note the double equals `==` for equality.

Create a second tibble `Not_BAY` that is all rows not equal to (`!=`) `BAY`.

```{r}

```

Confirm that all rows are accounted for. Sum the number of rows (`nrow()`) in each and make sure it matches the number of rows in the original tibble.

```{r}

```

You can filter on multiple conditions with and `&` and or `|`:

```{r}
SF |> filter(ht97mm > 100 & population == "BAY")
SF |> filter(population == "BAY" | population == "ENT")
```

Feel free to experiment with other filtering combinations.


### Plotting

Plot the density of the distribution of `ht97mm`, colored by population.

- Add `facet_wrap("population")` to plot each population in a separate panel.
- If the x axis labs collide with each other add `theme(axis.text.x = element_text(angle = 90))` to rotate the axis labels by 90 degrees.

```{r}

```

Now summarize height by population by calculating the mean, standard deviation, and median. Put these values into a tibble and use `knitr::kable()` to print out the table. This will be similar to the `group_by() |> summarize()` code above.

```{r}

```

Compare the mean and the median across the populations. In this sample is the mean a good estimate of the central tendency?

> 


# Intuition for distributions / summaries

At the end of lecture 3-2, we used the Law of Large Numbers to show how the mean of a set of samples from a population is a good estimate of the population's mean. That code, condensed into one chunk is:

```{r}
# Generate 1000 random normal numbers with a mean of 10 and sd of 4
set.seed(423766)
x <- rnorm(n = 1000, mean = 10, sd = 4)

set.seed(12366)

# Size of the same for each iteration
sample_size <- 20

# Number of iterations
n_means <- 100

# Empty vector to hold means for each sample
sample_means <- numeric(n_means)

# Iterate through, calculating the mean for each sample
for (ii in 1:n_means) {
  s <- sample(x, size = sample_size, replace = FALSE)
  sample_means[ii] <- mean(s)
}

ggplot(tibble(sample_means), aes(sample_means)) +
  geom_histogram(bins = 30, fill = "gold") +
  labs(x = "Sample Mean", y = "Count")

mean(x)

mean(sample_means)
```


## Activity

We left off in lecture with two questions:

1. What would change with larger sample sizes (~100) but the same number of iterations (100)?
2. What would change with more iterations (1000) but the same sample size (20)?

What is your prediction for each question?

> 

Copy the code above to answer each question. For simplicity, use the same set of random values created above.

```{r}
# What would change with larger sample sizes (~100) but the same number of iterations (100)?



# What would change with more iterations (1000) but the same sample size (20)?

```

What observations do you make? Pay particular attention to the x-axis scale in the histograms.

> 

